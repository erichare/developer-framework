# /usr/bin/env python3
from random import random
from time import sleep

import pandas as pd
import xgboost as xgb

from dotenv import load_dotenv
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

load_dotenv()


# Initialize ValidMind SDK
import validmind as vm

print("* Initializing SDK...")

# For test environment use api_host="https://api.test.vm.validmind.ai/api/v1/tracking"
vm.init(
    project="cl50nn8qq000sbbmmcjvo6yzw",
)

run_cuid = vm.start_run()

# Load model_overview.md markdown file and call log_metadata with its text
print("* Logging model metadata...")
sleep(2 * random())

print("* Loading dataset...")
sleep(2 * random())

df = pd.read_csv("notebooks/datasets/bank_customer_churn.csv")


print("* Logging dataset metadata and statistics...")

targets = vm.DatasetTargets(
    target_column="Exited",
    class_labels={
        "0": "Did not exit",
        "1": "Exited",
    },
)

features = [
    {
        "id": "RowNumber",
        "type_options": {
            "primary_key": True,
        },
    }
]

vm_dataset = vm.log_dataset(
    df, "training", analyze=True, targets=targets, features=features
)


print("* Running data quality tests...")

results = vm.run_dataset_tests(
    df,
    dataset_type="training",
    vm_dataset=vm_dataset,
    send=True,
)

# Run these as part of data quality tests
df.drop(["RowNumber", "CustomerId", "Surname", "CreditScore"], axis=1, inplace=True)
genders = {"Male": 0, "Female": 1}
df.replace({"Gender": genders}, inplace=True)
df = pd.concat([df, pd.get_dummies(df["Geography"], prefix="Geography")], axis=1)
df.drop("Geography", axis=1, inplace=True)

print("* Logging model metadata and parameters...")

train_df, test_df = train_test_split(df, test_size=0.20)

# This guarantees a 60/20/20 split
train_ds, val_ds = train_test_split(train_df, test_size=0.25)

# For training
x_train = train_ds.drop("Exited", axis=1)
y_train = train_ds.loc[:, "Exited"].astype(int)
x_val = val_ds.drop("Exited", axis=1)
y_val = val_ds.loc[:, "Exited"].astype(int)

# For testing
x_test = test_df.drop("Exited", axis=1)
y_test = test_df.loc[:, "Exited"].astype(int)

xgb_model = xgb.XGBClassifier(early_stopping_rounds=10)
xgb_model.set_params(
    eval_metric=["error", "logloss", "auc"],
)
xgb_model.fit(
    x_train,
    y_train,
    eval_set=[(x_train, y_train), (x_val, y_val)],
    verbose=False,
)

vm.log_model(xgb_model)
vm.log_training_metrics(xgb_model, x_train, y_train)

print("* Running model evaluation tests...")
sleep(2 * random())

eval_results = vm.evaluate_model(xgb_model, x_test, y_test)

print("All test results have been sent to your ValidMind account.")

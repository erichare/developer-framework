{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro to Micro Model Demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to ValidMind Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "# Load API key and secret from environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv .env\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to ValidMind Project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 15:32:18,089 - INFO(validmind.api_client): Connected to ValidMind. Project: Macro-to-Micro Model - Initial Validation (clk2jf1yy0005o5y6u8a30v6l)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
    "  api_key = \"2494c3838f48efe590d531bfe225d90b\",\n",
    "  api_secret = \"4f692f8161f128414fef542cab2a4e74834c75d01b3a8e088a1834f2afcfe838\",\n",
    "  project = \"clk2jf1yy0005o5y6u8a30v6l\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Available Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b57f4 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b57f4_row0_col0, #T_b57f4_row0_col1, #T_b57f4_row0_col2, #T_b57f4_row0_col3, #T_b57f4_row0_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b57f4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b57f4_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_b57f4_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_b57f4_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_b57f4_level0_col3\" class=\"col_heading level0 col3\" >Required Context</th>\n",
       "      <th id=\"T_b57f4_level0_col4\" class=\"col_heading level0 col4\" >Tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b57f4_row0_col0\" class=\"data row0 col0\" >time_series_data_quality</td>\n",
       "      <td id=\"T_b57f4_row0_col1\" class=\"data row0 col1\" >TimeSeriesDataQuality</td>\n",
       "      <td id=\"T_b57f4_row0_col2\" class=\"data row0 col2\" >Test plan for data quality on time series datasets</td>\n",
       "      <td id=\"T_b57f4_row0_col3\" class=\"data row0 col3\" >['dataset']</td>\n",
       "      <td id=\"T_b57f4_row0_col4\" class=\"data row0 col4\" >TimeSeriesOutliers (ThresholdTest)<br>TimeSeriesMissingValues (ThresholdTest)<br>TimeSeriesFrequency (ThresholdTest)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15fd8e1a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.describe_plan(\"time_series_data_quality\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRSFRMACBS</th>\n",
       "      <th>GDPC1</th>\n",
       "      <th>CSUSHPISA</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DRSFRMACBS  GDPC1  CSUSHPISA  UNRATE  CPIAUCSL  FEDFUNDS\n",
       "DATE                                                                \n",
       "2023-03-02         NaN    NaN        NaN     NaN       NaN       NaN\n",
       "2023-03-09         NaN    NaN        NaN     NaN       NaN       NaN\n",
       "2023-03-16         NaN    NaN        NaN     NaN       NaN       NaN\n",
       "2023-03-23         NaN    NaN        NaN     NaN       NaN       NaN\n",
       "2023-03-30         NaN    NaN        NaN     NaN       NaN       NaN\n",
       "2023-04-01         NaN    NaN    299.715     NaN       NaN       NaN\n",
       "2023-04-06         NaN    NaN        NaN     NaN       NaN       NaN\n",
       "2023-04-13         NaN    NaN        NaN     NaN       NaN       NaN\n",
       "2023-04-20         NaN    NaN        NaN     NaN       NaN       NaN\n",
       "2023-04-27         NaN    NaN        NaN     NaN       NaN       NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from validmind.datasets.regression import fred as fred\n",
    "\n",
    "# Define target and feature columns\n",
    "target_column = 'DRSFRMACBS'\n",
    "feature_columns = ['GDPC1', 'CSUSHPISA', 'UNRATE', 'CPIAUCSL', 'FEDFUNDS']\n",
    "\n",
    "# Load FRED data\n",
    "df = fred.load_all_data()\n",
    "\n",
    "# Select columns for analysis\n",
    "df = df[[target_column] + feature_columns]\n",
    "\n",
    "df.tail(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 15:32:18,183 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-14 15:32:18,183 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4026a66299f4265a141ad70cff2781a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h2>Time Series Missing Values ❌</h2>\\n            <p>Test that the n…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.vm_models.test_context import TestContext\n",
    "from validmind.tests.data_validation.TimeSeriesMissingValues import TimeSeriesMissingValues\n",
    "\n",
    "vm_df = vm.init_dataset(dataset=df)\n",
    "test_context = TestContext(dataset=vm_df)\n",
    "\n",
    "params = {\"min_threshold\": 2}\n",
    "\n",
    "metric = TimeSeriesMissingValues(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d59c50d2d848fcb18217e0eb516f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h2>Time Series Outliers ❌</h2>\\n            <p>Test that find outlie…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TimeSeriesOutliers import TimeSeriesOutliers\n",
    "\n",
    "params = {\"zscore_threshold\": 3}\n",
    "\n",
    "metric = TimeSeriesOutliers(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde7290a75de473990cc7e318963d51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h2>Time Series Frequency ❌</h2>\\n            <p>Test that detect fre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TimeSeriesFrequency import TimeSeriesFrequency\n",
    "\n",
    "metric = TimeSeriesFrequency(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to quarterly data (end of October)\n",
    "df = df.resample('QS-OCT').mean()\n",
    "\n",
    "# Remove all missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Take the first difference across all variables\n",
    "df = df.diff().dropna()\n",
    "\n",
    "# Remove data from 2020 onwards\n",
    "df = df[df.index.year < 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 15:32:19,808 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-14 15:32:19,808 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e99d2a7ada743c19206e2e83f6da4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h2>Time Series Missing Values ✅</h2>\\n            <p>Test that the n…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.vm_models.test_context import TestContext\n",
    "from validmind.tests.data_validation.TimeSeriesMissingValues import TimeSeriesMissingValues\n",
    "\n",
    "vm_df = vm.init_dataset(dataset=df)\n",
    "test_context = TestContext(dataset=vm_df)\n",
    "\n",
    "params = {\"min_threshold\": 2}\n",
    "\n",
    "metric = TimeSeriesMissingValues(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17af61b7a664a6b8e11dd5f4921b071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h2>Time Series Outliers ❌</h2>\\n            <p>Test that find outlie…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TimeSeriesOutliers import TimeSeriesOutliers\n",
    "\n",
    "params = {\"zscore_threshold\": 3}\n",
    "\n",
    "metric = TimeSeriesOutliers(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22290f8c165444e78a5e89c0807dd826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h2>Time Series Frequency ✅</h2>\\n            <p>Test that detect fre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TimeSeriesFrequency import TimeSeriesFrequency\n",
    "\n",
    "metric = TimeSeriesFrequency(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Method\n",
    "\n",
    "We use time series sampling to create our training and testing sets, a crucial step in our macro-to-micro model. This method maintains the temporal order of the data, preserving the inherent dependencies in our time series of macroeconomic indicators and default rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split date\n",
    "split_date = '2018-01-01'\n",
    "\n",
    "# Split data into train and test \n",
    "df_train = df.loc[df.index < split_date]\n",
    "df_test = df.loc[df.index >= split_date]\n",
    "\n",
    "# Split the train and test sets into X and y\n",
    "X_train = df_train.drop(target_column, axis=1)\n",
    "y_train = df_train[target_column]\n",
    "X_test = df_test.drop(target_column, axis=1)\n",
    "y_test = df_test[target_column]\n",
    "\n",
    "# Concatenate X_train with y_train to form df_train\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Concatenate X_test with y_test to form df_test\n",
    "df_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0e362 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0e362_row0_col0, #T_0e362_row0_col1, #T_0e362_row0_col2, #T_0e362_row0_col3, #T_0e362_row0_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0e362\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_0e362_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_0e362_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_0e362_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_0e362_level0_col3\" class=\"col_heading level0 col3\" >Required Context</th>\n",
       "      <th id=\"T_0e362_level0_col4\" class=\"col_heading level0 col4\" >Tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_0e362_row0_col0\" class=\"data row0 col0\" >time_series_univariate</td>\n",
       "      <td id=\"T_0e362_row0_col1\" class=\"data row0 col1\" >TimeSeriesUnivariate</td>\n",
       "      <td id=\"T_0e362_row0_col2\" class=\"data row0 col2\" >Test plan to perform time series univariate analysis.</td>\n",
       "      <td id=\"T_0e362_row0_col3\" class=\"data row0 col3\" >['dataset']</td>\n",
       "      <td id=\"T_0e362_row0_col4\" class=\"data row0 col4\" >TimeSeriesLinePlot (Metric)<br>TimeSeriesHistogram (Metric)<br>ACFandPACFPlot (Metric)<br>SeasonalDecompose (Metric)<br>AutoSeasonality (Metric)<br>AutoStationarity (Metric)<br>RollingStatsPlot (Metric)<br>AutoAR (Metric)<br>AutoMA (Metric)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15b0a3550>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.describe_plan(\"time_series_univariate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 15:32:21,251 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-14 15:32:21,251 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3355477e614a4a63b1945365573add99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of time series data by plotting the raw time series.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TimeSeriesLinePlot import TimeSeriesLinePlot\n",
    "\n",
    "vm_df_train = vm.init_dataset(dataset=df_train)\n",
    "test_context = TestContext(dataset=vm_df_train)\n",
    "\n",
    "metric = TimeSeriesLinePlot(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328be1fc792c4d7eba7d14f472cbd7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of time series data by plotting the histogram. The i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TimeSeriesHistogram import TimeSeriesHistogram\n",
    "\n",
    "metric = TimeSeriesHistogram(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanvalidmind/Library/Caches/pypoetry/virtualenvs/validmind-X_uvMH0R-py3.10/lib/python3.10/site-packages/statsmodels/graphics/tsaplots.py:348: FutureWarning: The default method 'yw' can produce PACF values outside of the [-1,1] interval. After 0.13, the default will change tounadjusted Yule-Walker ('ywm'). You can use this method now by setting method='ywm'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e52c7c403245ae93d4983342136dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Plots ACF and PACF for a given time series dataset.</p>'), HTML(value='<h3>Plots…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.ACFandPACFPlot import ACFandPACFPlot\n",
    "\n",
    "metric = ACFandPACFPlot(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 15:32:24,459 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of GDPC1: QS-OCT\n",
      "2023-07-14 15:32:24,459 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of GDPC1: QS-OCT\n",
      "2023-07-14 15:32:24,747 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of CSUSHPISA: QS-OCT\n",
      "2023-07-14 15:32:24,747 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of CSUSHPISA: QS-OCT\n",
      "2023-07-14 15:32:24,977 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of UNRATE: QS-OCT\n",
      "2023-07-14 15:32:24,977 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of UNRATE: QS-OCT\n",
      "2023-07-14 15:32:25,144 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of CPIAUCSL: QS-OCT\n",
      "2023-07-14 15:32:25,144 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of CPIAUCSL: QS-OCT\n",
      "2023-07-14 15:32:25,304 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of FEDFUNDS: QS-OCT\n",
      "2023-07-14 15:32:25,304 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of FEDFUNDS: QS-OCT\n",
      "2023-07-14 15:32:25,594 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of DRSFRMACBS: QS-OCT\n",
      "2023-07-14 15:32:25,594 - INFO(validmind.tests.data_validation.SeasonalDecompose): Frequency of DRSFRMACBS: QS-OCT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e70077509d4dbbb367677aaf1350d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Calculates seasonal_decompose metric for each of the dataset features</p>'), HTM…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.SeasonalDecompose import SeasonalDecompose\n",
    "\n",
    "params = {\"seasonal_model\": 'additive'}\n",
    "\n",
    "metric = SeasonalDecompose(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145c1470d3ae4df8a55f4cf33df399fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Automatically detects the optimal seasonal order for a time series dataset using…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.AutoSeasonality import AutoSeasonality\n",
    "\n",
    "params = {\"min_period\": 1,\n",
    "          \"min_period\": 3}\n",
    "\n",
    "metric = AutoSeasonality(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff2fc51f56943ada10d0a26ba17c9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Automatically detects stationarity for each time series in a DataFrame using the…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.AutoStationarity import AutoStationarity\n",
    "\n",
    "params = {\"max_order\": 3,\n",
    "          \"threshold\": 0.05}\n",
    "\n",
    "metric = AutoStationarity(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441cbc585f124c02ade942007cfc345c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This class provides a metric to visualize the stationarity of a given time serie…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.RollingStatsPlot import RollingStatsPlot\n",
    "\n",
    "params = {\"window_size\": 4}\n",
    "\n",
    "metric = RollingStatsPlot(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 15:32:29,088 - WARNING(validmind.tests.data_validation.AutoAR): Warning: CSUSHPISA is not stationary. Results may be inaccurate.\n",
      "2023-07-14 15:32:29,088 - WARNING(validmind.tests.data_validation.AutoAR): Warning: CSUSHPISA is not stationary. Results may be inaccurate.\n",
      "2023-07-14 15:32:29,133 - WARNING(validmind.tests.data_validation.AutoAR): Warning: DRSFRMACBS is not stationary. Results may be inaccurate.\n",
      "2023-07-14 15:32:29,133 - WARNING(validmind.tests.data_validation.AutoAR): Warning: DRSFRMACBS is not stationary. Results may be inaccurate.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3374540ff7ec40ec9d195a8884396ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Automatically detects the AR order of a time series using both BIC and AIC.</p>'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.AutoAR import AutoAR\n",
    "\n",
    "params = {\"max_ar_order\": 2}\n",
    "\n",
    "metric = AutoAR(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 15:32:29,238 - WARNING(validmind.tests.data_validation.AutoMA): Warning: CSUSHPISA is not stationary. Results may be inaccurate.\n",
      "2023-07-14 15:32:29,238 - WARNING(validmind.tests.data_validation.AutoMA): Warning: CSUSHPISA is not stationary. Results may be inaccurate.\n",
      "/Users/juanvalidmind/Library/Caches/pypoetry/virtualenvs/validmind-X_uvMH0R-py3.10/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "/Users/juanvalidmind/Library/Caches/pypoetry/virtualenvs/validmind-X_uvMH0R-py3.10/lib/python3.10/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "2023-07-14 15:32:29,472 - WARNING(validmind.tests.data_validation.AutoMA): Warning: DRSFRMACBS is not stationary. Results may be inaccurate.\n",
      "2023-07-14 15:32:29,472 - WARNING(validmind.tests.data_validation.AutoMA): Warning: DRSFRMACBS is not stationary. Results may be inaccurate.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4d206d33f740c0968432c0b53aba61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Automatically detects the MA order of a time series using both BIC and AIC.</p>'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.AutoMA import AutoMA\n",
    "\n",
    "params = {\"max_ar_order\": 2}\n",
    "\n",
    "metric = AutoMA(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cdffe th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_cdffe_row0_col0, #T_cdffe_row0_col1, #T_cdffe_row0_col2, #T_cdffe_row0_col3, #T_cdffe_row0_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cdffe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_cdffe_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_cdffe_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_cdffe_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_cdffe_level0_col3\" class=\"col_heading level0 col3\" >Required Context</th>\n",
       "      <th id=\"T_cdffe_level0_col4\" class=\"col_heading level0 col4\" >Tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_cdffe_row0_col0\" class=\"data row0 col0\" >time_series_multivariate</td>\n",
       "      <td id=\"T_cdffe_row0_col1\" class=\"data row0 col1\" >TimeSeriesMultivariate</td>\n",
       "      <td id=\"T_cdffe_row0_col2\" class=\"data row0 col2\" >Test plan to perform time series multivariate analysis.</td>\n",
       "      <td id=\"T_cdffe_row0_col3\" class=\"data row0 col3\" >['dataset']</td>\n",
       "      <td id=\"T_cdffe_row0_col4\" class=\"data row0 col4\" >ScatterPlot (Metric)<br>LaggedCorrelationHeatmap (Metric)<br>EngleGrangerCoint (Metric)<br>SpreadPlot (Metric)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17c8af310>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.describe_plan(\"time_series_multivariate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3029d3cbf1484bbb04af9310faad50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of data by plotting a scatter plot matrix for all co…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.ScatterPlot import ScatterPlot\n",
    "\n",
    "metric = ScatterPlot(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.data_validation.LaggedCorrelationHeatmap import LaggedCorrelationHeatmap\n",
    "\n",
    "params = {\"target_col\": target_column,\n",
    "          \"independent_vars\": feature_columns}\n",
    "\n",
    "metric = LaggedCorrelationHeatmap(test_context, params)\n",
    "#metric.run()\n",
    "# await metric.result.log()\n",
    "#metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6181797a5aa94766ad72f89e4bb0970b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Test for cointegration between pairs of time series variables in a given dataset…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.EngleGrangerCoint import EngleGrangerCoint\n",
    "\n",
    "params = {\"threshold\": 0.05}\n",
    "\n",
    "metric = EngleGrangerCoint(test_context, params)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c237914170344b7a89c404790f2e5a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This class provides a metric to visualize the spread between pairs of time serie…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.SpreadPlot import SpreadPlot\n",
    "\n",
    "metric = SpreadPlot(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             DRSFRMACBS   R-squared:                       0.570\n",
      "Model:                            OLS   Adj. R-squared:                  0.549\n",
      "Method:                 Least Squares   F-statistic:                     26.82\n",
      "Date:                Fri, 14 Jul 2023   Prob (F-statistic):           3.65e-17\n",
      "Time:                        15:32:34   Log-Likelihood:                 6.8781\n",
      "No. Observations:                 107   AIC:                            -1.756\n",
      "Df Residuals:                     101   BIC:                             14.28\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0929      0.043      2.181      0.031       0.008       0.177\n",
      "GDPC1         -0.0002      0.000     -0.485      0.628      -0.001       0.001\n",
      "CSUSHPISA     -0.0562      0.012     -4.826      0.000      -0.079      -0.033\n",
      "UNRATE         0.6963      0.106      6.567      0.000       0.486       0.907\n",
      "CPIAUCSL       0.0117      0.024      0.483      0.630      -0.036       0.060\n",
      "FEDFUNDS       0.1426      0.067      2.130      0.036       0.010       0.275\n",
      "==============================================================================\n",
      "Omnibus:                       22.566   Durbin-Watson:                   1.278\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               45.261\n",
      "Skew:                           0.831   Prob(JB):                     1.48e-10\n",
      "Kurtosis:                       5.719   Cond. No.                         565.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Create X_train, y_train \n",
    "y_train = df_train[target_column]\n",
    "X_train = df_train.drop(target_column, axis=1)\n",
    "\n",
    "# Add constant to X_train for intercept term\n",
    "X_train = sm.add_constant(X_train)\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Update df_test\n",
    "y_test = df_test[target_column]\n",
    "X_test = df_test.drop(target_column, axis=1)\n",
    "X_test = sm.add_constant(X_test)\n",
    "df_test = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Define the model\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "# Fit the model\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Print out the statistics\n",
    "print(model_fit.summary())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Non-Significant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['GDPC1', 'CPIAUCSL']\n",
    "df_train.drop(columns = features_to_drop, inplace=True)\n",
    "\n",
    "# Update df_test \n",
    "df_test.drop(columns = features_to_drop, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Model Fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             DRSFRMACBS   R-squared:                       0.569\n",
      "Model:                            OLS   Adj. R-squared:                  0.556\n",
      "Method:                 Least Squares   F-statistic:                     45.27\n",
      "Date:                Fri, 14 Jul 2023   Prob (F-statistic):           9.62e-19\n",
      "Time:                        15:32:34   Log-Likelihood:                 6.6709\n",
      "No. Observations:                 107   AIC:                            -5.342\n",
      "Df Residuals:                     103   BIC:                             5.350\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0923      0.026      3.531      0.001       0.040       0.144\n",
      "CSUSHPISA     -0.0576      0.011     -5.106      0.000      -0.080      -0.035\n",
      "UNRATE         0.7116      0.097      7.303      0.000       0.518       0.905\n",
      "FEDFUNDS       0.1434      0.066      2.186      0.031       0.013       0.273\n",
      "==============================================================================\n",
      "Omnibus:                       20.987   Durbin-Watson:                   1.251\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               40.129\n",
      "Skew:                           0.790   Prob(JB):                     1.93e-09\n",
      "Kurtosis:                       5.550   Cond. No.                         12.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Create X_train and y_train, X_test and y_test\n",
    "y_train = df_train[target_column]\n",
    "X_train = df_train.drop(target_column, axis=1)\n",
    "\n",
    "# Define the model\n",
    "model = sm.OLS(y_train, X_train)\n",
    "\n",
    "# Fit the model\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Print out the statistics\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create ValidMind Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 15:32:46,804 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-14 15:32:46,805 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n",
      "2023-07-14 15:32:46,809 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-14 15:32:46,810 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    }
   ],
   "source": [
    "# Update VM datasets\n",
    "vm_train_ds = vm.init_dataset(dataset=df_train, type=\"generic\", target_column=target_column)\n",
    "vm_test_ds = vm.init_dataset(dataset=df_test, type=\"generic\", target_column=target_column)\n",
    "\n",
    "# Create VM model\n",
    "vm_model = vm.init_model(\n",
    "    model = model_fit, \n",
    "    train_ds=vm_train_ds, \n",
    "    test_ds=vm_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a26c9 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a26c9_row0_col0, #T_a26c9_row0_col1, #T_a26c9_row0_col2, #T_a26c9_row0_col3, #T_a26c9_row0_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a26c9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_a26c9_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_a26c9_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_a26c9_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_a26c9_level0_col3\" class=\"col_heading level0 col3\" >Required Context</th>\n",
       "      <th id=\"T_a26c9_level0_col4\" class=\"col_heading level0 col4\" >Tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_a26c9_row0_col0\" class=\"data row0 col0\" >regression_model_description</td>\n",
       "      <td id=\"T_a26c9_row0_col1\" class=\"data row0 col1\" >RegressionModelDescription</td>\n",
       "      <td id=\"T_a26c9_row0_col2\" class=\"data row0 col2\" >Test plan for performance metric of regression model of statsmodels library</td>\n",
       "      <td id=\"T_a26c9_row0_col3\" class=\"data row0 col3\" >['model']</td>\n",
       "      <td id=\"T_a26c9_row0_col4\" class=\"data row0 col4\" >DatasetSplit (Metric)<br>ModelMetadata (Metric)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15acb0040>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.describe_plan(\"regression_model_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bd539caf5a49ec86b558c2d3386b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This section shows the size of the dataset split into training, test (and valida…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.DatasetSplit import DatasetSplit\n",
    "\n",
    "test_context = TestContext(model=vm_model)\n",
    "\n",
    "metric = DatasetSplit(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b8b50185cd48d4890dd03dc5f67b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<p>This section describes attributes of the selected model such as its modeling tec…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.ModelMetadata import ModelMetadata\n",
    "\n",
    "\n",
    "metric = ModelMetadata(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fcb54 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fcb54_row0_col0, #T_fcb54_row0_col1, #T_fcb54_row0_col2, #T_fcb54_row0_col3, #T_fcb54_row0_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fcb54\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_fcb54_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_fcb54_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_fcb54_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_fcb54_level0_col3\" class=\"col_heading level0 col3\" >Required Context</th>\n",
       "      <th id=\"T_fcb54_level0_col4\" class=\"col_heading level0 col4\" >Tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_fcb54_row0_col0\" class=\"data row0 col0\" >regression_models_evaluation</td>\n",
       "      <td id=\"T_fcb54_row0_col1\" class=\"data row0 col1\" >RegressionModelsEvaluation</td>\n",
       "      <td id=\"T_fcb54_row0_col2\" class=\"data row0 col2\" >Test plan for metrics comparison of regression model of statsmodels library</td>\n",
       "      <td id=\"T_fcb54_row0_col3\" class=\"data row0 col3\" >['models', 'model']</td>\n",
       "      <td id=\"T_fcb54_row0_col4\" class=\"data row0 col4\" >RegressionModelsCoeffs (Metric)<br>RegressionModelsPerformance (Metric)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15abf9180>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.describe_plan(\"regression_models_evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfca2cdcb084793b27f32d6d6adcbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This section shows the coefficients of different regression models that were tra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.RegressionModelsCoeffs import RegressionModelsCoeffs\n",
    "\n",
    "test_context = TestContext(models=[vm_model])\n",
    "metric = RegressionModelsCoeffs(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056e5abe688a4072ba834f4347eb896c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This section shows the in-sample and out-of-sample comparison of regression mode…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.RegressionModelsPerformance import RegressionModelsPerformance\n",
    "\n",
    "test_context = TestContext(models=[vm_model])\n",
    "metric = RegressionModelsPerformance(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8f52f th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8f52f_row0_col0, #T_8f52f_row0_col1, #T_8f52f_row0_col2, #T_8f52f_row0_col3, #T_8f52f_row0_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8f52f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_8f52f_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_8f52f_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_8f52f_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_8f52f_level0_col3\" class=\"col_heading level0 col3\" >Required Context</th>\n",
       "      <th id=\"T_8f52f_level0_col4\" class=\"col_heading level0 col4\" >Tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_8f52f_row0_col0\" class=\"data row0 col0\" >time_series_forecast</td>\n",
       "      <td id=\"T_8f52f_row0_col1\" class=\"data row0 col1\" >TimeSeriesForecast</td>\n",
       "      <td id=\"T_8f52f_row0_col2\" class=\"data row0 col2\" >Test plan to perform time series forecast tests.</td>\n",
       "      <td id=\"T_8f52f_row0_col3\" class=\"data row0 col3\" >['models']</td>\n",
       "      <td id=\"T_8f52f_row0_col4\" class=\"data row0 col4\" >RegressionModelForecastPlotLevels (Metric)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15adda710>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.describe_plan(\"time_series_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5435644fd4184fb48f04d00815951752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This section shows plots of training and test datasets vs forecast training and …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.RegressionModelForecastPlotLevels import RegressionModelForecastPlotLevels\n",
    "\n",
    "test_context = TestContext(models=[vm_model])\n",
    "\n",
    "params = {\"transformation\": \"integrate\"}\n",
    "\n",
    "metric = RegressionModelForecastPlotLevels(test_context)\n",
    "metric.run()\n",
    "# await metric.result.log()\n",
    "metric.result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-framework",
   "language": "python",
   "name": "dev-framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

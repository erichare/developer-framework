{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Scorecard Demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "To use the ValidMind Developer Framework with a Jupyter notebook, you need to install and initialize the client library first, along with getting your Python environment ready.\n",
    "\n",
    "If you don't already have one, you should also create a documentation project on the ValidMind platform. You will use this project to upload your documentation and test results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade validmind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "In a browser, go to the Client Integration page of your documentation project and click Copy to clipboard next to the code snippet. This code snippet gives you the API key, API secret, and project identifier to link your notebook to your documentation project.\n",
    "\n",
    "This step requires a documentation project. Learn how you can create one.\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 09:41:11,672 - INFO(validmind.api_client): Connected to ValidMind. Project: [6] Credit Risk Scorecard - Initial Validation (clk00h0u800x9qjy67gduf5om)\n"
     ]
    }
   ],
   "source": [
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
    "  api_key = \"2494c3838f48efe590d531bfe225d90b\",\n",
    "  api_secret = \"4f692f8161f128414fef542cab2a4e74834c75d01b3a8e088a1834f2afcfe838\",\n",
    "  project = \"clk00h0u800x9qjy67gduf5om\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Credit risk Scorecard** model created from the Lending Club dataset is instrumental in computing the Probability of Default (PD), a key factor in ECL calculations. This scorecard assesses several credit characteristics of potential borrowers, like their credit history, income, outstanding debts, and more, each of which is assigned a specific score. By combining these scores, we derive a total score for each borrower, which translates into an estimated Point-in-Time (PiT) PD. The PiT PD reflects the borrower's likelihood of default at a specific point in time, accounting for both current and foreseeable future conditions.\n",
    "\n",
    "Additionally, for a holistic view of credit risk, it's essential to estimate the Lifetime PD. The Lifetime PD, as the name suggests, predicts the borrower's likelihood of default throughout the life of the exposure, taking into account potential future changes in the economic and financial conditions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key and secret from environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv .env\n",
    "\n",
    "# Standard library imports\n",
    "import re\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "# Data handling and analysis imports\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# File handling import\n",
    "import zipfile\n",
    "\n",
    "# Scorecard development\n",
    "import scorecardpy as sc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_variables = [\n",
    "    \"id\", \"member_id\", \"funded_amnt\", \"emp_title\", \"url\", \"desc\", \"application_type\",\n",
    "    \"title\", \"zip_code\", \"delinq_2yrs\", \"mths_since_last_delinq\", \"mths_since_last_record\",\n",
    "    \"revol_bal\", \"total_rec_prncp\", \"total_rec_late_fee\", \"recoveries\", \"out_prncp_inv\", \"out_prncp\", \n",
    "    \"collection_recovery_fee\", \"next_pymnt_d\", \"initial_list_status\", \"pub_rec\",\n",
    "    \"collections_12_mths_ex_med\", \"policy_code\", \"acc_now_delinq\", \"pymnt_plan\",\n",
    "    \"tot_coll_amt\", \"tot_cur_bal\", \"total_rev_hi_lim\", \"last_pymnt_d\", \"last_credit_pull_d\",\n",
    "    'earliest_cr_line', 'issue_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_df(model, df, base_filename):\n",
    "    \"\"\"Save a model and a dataframe with a timestamp in the filename\"\"\"\n",
    "    # Get current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Convert the current date and time to string\n",
    "    timestamp_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    filename = f'{base_filename}_{timestamp_str}.pkl'\n",
    "\n",
    "    # Save the model and dataframe\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump((model, df), file)\n",
    "        \n",
    "    print(f\"Model and dataframe saved as {filename}\")\n",
    "\n",
    "def get_numerical_columns(df):\n",
    "        numerical_columns = df.select_dtypes(\n",
    "            include=[\"int\", \"float\", \"uint\"]\n",
    "        ).columns.tolist()\n",
    "        return numerical_columns\n",
    "\n",
    "def get_categorical_columns(df):\n",
    "        categorical_columns = df.select_dtypes(\n",
    "            include=[\"object\", \"category\"]\n",
    "        ).columns.tolist()\n",
    "        return categorical_columns\n",
    "\n",
    "def add_target_column(df, target_column):\n",
    "    # Assuming the column name is 'loan_status'\n",
    "    df[target_column] = df['loan_status'].apply(lambda x: 0 if x == \"Fully Paid\" else 1 if x == \"Charged Off\" else np.nan)\n",
    "    # Remove rows where the target column is NaN\n",
    "    df = df.dropna(subset=[target_column])\n",
    "    # Convert target column to integer\n",
    "    df[target_column] = df[target_column].astype(int)\n",
    "    return df\n",
    "\n",
    "def variables_with_min_missing(df, min_missing_percentage):\n",
    "    # Calculate the percentage of missing values in each column\n",
    "    missing_percentages = df.isnull().mean() * 100\n",
    "\n",
    "    # Get the variables where the percentage of missing values is greater than the specified minimum\n",
    "    variables_to_drop = missing_percentages[missing_percentages > min_missing_percentage].index.tolist()\n",
    "\n",
    "    # Also add any columns where all values are missing\n",
    "    variables_to_drop.extend(df.columns[df.isnull().all()].tolist())\n",
    "\n",
    "    # Remove duplicates (if any)\n",
    "    variables_to_drop = list(set(variables_to_drop))\n",
    "\n",
    "    return variables_to_drop\n",
    "\n",
    "def clean_term_column(df, column):\n",
    "    \"\"\"\n",
    "    Function to remove 'months' string from the 'term' column and convert it to categorical\n",
    "    \"\"\"\n",
    "    # Ensure the column exists in the dataframe\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"The column '{column}' does not exist in the dataframe.\")\n",
    "    \n",
    "    df[column] = df[column].str.replace(' months', '')\n",
    "    \n",
    "    # Convert to categorical\n",
    "    df[column] = df[column].astype('object')\n",
    "\n",
    "def clean_emp_length_column(df, column):\n",
    "    \"\"\"\n",
    "    Function to clean 'emp_length' column and convert it to categorical.\n",
    "    \"\"\"\n",
    "    # Ensure the column exists in the dataframe\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"The column '{column}' does not exist in the dataframe.\")\n",
    "    \n",
    "    df[column] = df[column].replace('n/a', np.nan)\n",
    "    df[column] = df[column].str.replace('< 1 year', str(0))\n",
    "    df[column] = df[column].apply(lambda x: re.sub('\\D', '', str(x)))\n",
    "    df[column].fillna(value = 0, inplace=True)\n",
    "\n",
    "    # Convert to categorical\n",
    "    df[column] = df[column].astype('object')\n",
    "\n",
    "def clean_inq_last_6mths(df, column):\n",
    "    \"\"\"\n",
    "    Function to convert 'inq_last_6mths' column into categorical.\n",
    "    \"\"\"\n",
    "    # Ensure the column exists in the dataframe\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"The column '{column}' does not exist in the dataframe.\")\n",
    "\n",
    "    # Convert to categorical\n",
    "    df[column] = df[column].astype('category')\n",
    "\n",
    "def compute_outliers(series, threshold=1.5):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "    return series[(series < lower_bound) | (series > upper_bound)]\n",
    "\n",
    "def remove_iqr_outliers(df, target_column, threshold=1.5):\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    num_cols.remove(target_column)  # Exclude target_column from numerical columns\n",
    "    for col in num_cols:\n",
    "        outliers = compute_outliers(df[col], threshold)\n",
    "        df = df[~df[col].isin(outliers)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Raw Data\n",
    "def import_raw_data(): \n",
    "    # Download the Lending Club dataset from a public S3 bucket\n",
    "    lending_club_url = \"https://vmai.s3.us-west-1.amazonaws.com/datasets/lending_club_loan_data_2007_2014.csv\"\n",
    "    df_out = pd.read_csv(lending_club_url)\n",
    "    return df_out\n",
    "\n",
    "# 2. Data Preparation: Add Definition of Default\n",
    "def data_preparation_add_default_definition(df, default_column):\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    df_out = add_target_column(df_out, default_column)\n",
    "\n",
    "    # Drop 'loan_status' variable \n",
    "    df_out.drop(columns='loan_status', axis=1, inplace=True)\n",
    "\n",
    "    # Remove unused variables\n",
    "    df_out = df_out.drop(columns=unused_variables)\n",
    "\n",
    "    # Remove missing values\n",
    "    min_missing_count = 80\n",
    "    variables_to_drop = variables_with_min_missing(df_out, min_missing_count)\n",
    "    df_out.drop(columns=variables_to_drop, axis=1, inplace=True)\n",
    "    df_out.dropna(axis=0, subset=[\"emp_length\"], inplace=True)\n",
    "    df_out.dropna(axis=0, subset=[\"revol_util\"], inplace=True)\n",
    "\n",
    "    # Format variable types\n",
    "    clean_emp_length_column(df_out, 'emp_length')\n",
    "    clean_term_column(df_out, 'term')\n",
    "    clean_inq_last_6mths(df_out, 'inq_last_6mths')\n",
    "\n",
    "    # Remove outliers\n",
    "    df_out = remove_iqr_outliers(df_out, default_column, threshold=1.5)\n",
    "\n",
    "    return df_out\n",
    "\n",
    "# 3. Data Sampling: Data Split \n",
    "def data_sampling(df, target_column):\n",
    "    df_out = df.copy()\n",
    "\n",
    "    # Split data into train and test \n",
    "    X = df_out.drop(target_column, axis = 1)\n",
    "    y = df_out[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                    random_state = 42, stratify = y)\n",
    "\n",
    "    # Concatenate X_train with y_train to form df_train\n",
    "    df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "    # Concatenate X_test with y_test to form df_test\n",
    "    df_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    return df_train, X_train, y_train, df_test, X_test, y_test\n",
    "\n",
    "# 4. EDA: Drop Unused Categories\n",
    "def eda_drop_categories(df):\n",
    "\n",
    "    df_out = df.copy()\n",
    " \n",
    "    # Select rows where purpose is 'debt_consolidation' or 'credit_card'\n",
    "    df_out = df_out[df_out['purpose'].isin(['debt_consolidation', 'credit_card'])]\n",
    "    \n",
    "    # Remove rows where grade is 'F' or 'G'\n",
    "    df_out = df_out[~df_out['grade'].isin(['F', 'G'])]\n",
    "\n",
    "    # Remove rows where sub_grade starts with 'F' or 'G'\n",
    "    df_out = df_out[~df_out['sub_grade'].str.startswith(('F', 'G'))]\n",
    "    \n",
    "    # Remove rows where home_ownership is 'OTHER', 'NONE', or 'ANY'\n",
    "    df_out = df_out[~df_out['home_ownership'].isin(['OTHER', 'NONE', 'ANY'])]\n",
    "\n",
    "    return df_out\n",
    "\n",
    "# 5. EDA: Drop Unused Features\n",
    "def drop_features(df, features_to_drop):\n",
    "    df_out = df.copy()\n",
    "    df_out = df_out.drop(columns = features_to_drop, axis=1)\n",
    "    return df_out \n",
    "\n",
    "# 5. EDA: Convert Features to WoE Values\n",
    "def convert_to_woe(df, woe_df, target_col):\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    \n",
    "    # Create bins from woe_df\n",
    "    bins = transform_woe_df(woe_df)\n",
    "    \n",
    "    # Make sure we don't transform the target column\n",
    "    if target_col in bins:\n",
    "        del bins[target_col]\n",
    "    \n",
    "    # Apply the WoE transformation\n",
    "    df_out = sc.woebin_ply(df_out, bins=bins)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "def transform_woe_df(woe_df):\n",
    "    # Select and rename columns\n",
    "    transformed_df = woe_df[['variable', 'bin', 'count', 'count_distr', 'good', 'bad', 'badprob', 'woe', 'bin_iv', 'total_iv']].copy()\n",
    "    transformed_df.rename(columns={\n",
    "        'bin_iv': 'total_iv'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Create 'is_special_values' column (assuming there are no special values)\n",
    "    transformed_df['is_special_values'] = False\n",
    "    \n",
    "    # Transform 'bin' column into interval format and store it in 'breaks' column\n",
    "    transformed_df['breaks'] = transformed_df['bin'].apply(lambda x: '[-inf, %s)' % x if isinstance(x, float) else '[%s, inf)' % x)\n",
    "    \n",
    "    # Group by 'variable' to create bins dictionary\n",
    "    bins = {}\n",
    "    for variable, group in transformed_df.groupby('variable'):\n",
    "        bins[variable] = group\n",
    "    \n",
    "    return bins\n",
    "\n",
    "# 6. Model Training: Add Constant\n",
    "def add_constant(df, target_column):\n",
    "    \n",
    "    df_out = df.copy()\n",
    "    \n",
    "    # Add constant to X_train for intercept term\n",
    "    y = df_out[target_column]\n",
    "    X = df_out.drop(target_column, axis=1)\n",
    "    X = sm.add_constant(X)\n",
    "    df_out = pd.concat([X, y], axis=1)\n",
    "\n",
    "    return df_out, X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Raw Data: Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/rbr74q892k13m82y37y396h40000gn/T/ipykernel_60171/3836106577.py:5: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_out = pd.read_csv(lending_club_url)\n"
     ]
    }
   ],
   "source": [
    "df_1_raw_data = import_raw_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Assess Dataset 1: raw data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 09:41:50,297 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-08-06 09:41:50,297 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dcfd6e28d5e4da6b9245defcb8b5552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This section provides descriptive statistics for numerical and categorical varia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.vm_models.test_context import TestContext\n",
    "from validmind.tests.data_validation.DescriptiveStatistics import DescriptiveStatistics\n",
    "\n",
    "vm_df_1_raw_data = vm.init_dataset(dataset=df_1_raw_data)\n",
    "test_context_1_raw_data = TestContext(dataset=vm_df_1_raw_data)\n",
    "\n",
    "metric = DescriptiveStatistics(test_context_1_raw_data)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4496b0fad41c4beaabafa3861888c07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of missing values by plotting horizontal bar plots w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.MissingValuesBarPlot import MissingValuesBarPlot\n",
    "\n",
    "params = {\"threshold\": 70,\n",
    "          \"fig_height\": 1100}\n",
    "\n",
    "metric = MissingValuesBarPlot(test_context_1_raw_data, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Definition of Default: Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/rbr74q892k13m82y37y396h40000gn/T/ipykernel_60171/2227589160.py:35: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_column = 'default'\n",
    "df_2_default_definition = data_preparation_add_default_definition(\n",
    "    df = df_1_raw_data, \n",
    "    default_column = target_column)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Assess Dataset 2: definition of default**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 09:42:02,134 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-08-06 09:42:02,138 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df372cd4b91b465b96d13f3d2d4e632d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h2>Class Imbalance ❌</h2>\\n            <p>The class imbalance test m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.ClassImbalance import ClassImbalance\n",
    "\n",
    "vm_df_2_default_definition = vm.init_dataset(dataset=df_2_default_definition,\n",
    "                        target_column=target_column)\n",
    "test_context_2_default_definition = TestContext(dataset=vm_df_2_default_definition)\n",
    "\n",
    "metric = ClassImbalance(test_context_2_default_definition)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c889445149794b7eba6f7b410d9afdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Analyzes the distribution of outliers in numerical features using the Interquart…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.IQROutliersTable import IQROutliersTable\n",
    "\n",
    "num_features = get_numerical_columns(df_2_default_definition)\n",
    "params = {\"num_features\": num_features,\n",
    "          \"threshold\": 1.5\n",
    "        }\n",
    "\n",
    "metric = IQROutliersTable(test_context_2_default_definition, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2856f8c54542d7bcb38c752bca7e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of the outliers for numeric variables based on perce…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.IQROutliersBarPlot import IQROutliersBarPlot\n",
    "\n",
    "num_features = get_numerical_columns(df_2_default_definition)\n",
    "params = {\"num_features\": num_features,\n",
    "          \"threshold\": 1.5,\n",
    "          \"fig_width\": 500}\n",
    "\n",
    "metric = IQROutliersBarPlot(test_context_2_default_definition, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We employ stratified sampling to create our training and testing sets. Stratified sampling is particularly important in this context. When the `stratify = y` parameter is set, it ensures that the distribution of the target variable (`y`) in the test set is the same as that in the original dataset. \n",
    "\n",
    "This is crucial for maintaining a consistent representation of the target variable classes, especially important in scenarios where the classes are imbalanced, which is often the case in credit risk scorecards."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Split: Train and Test from Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2, X_train, y_train, df_test_2, X_test, y_test = data_sampling(\n",
    "    df = df_2_default_definition,\n",
    "    target_column=target_column)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Assess Train Dataset 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 09:42:25,810 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-08-06 09:42:25,811 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cca6fe1d18490d86fb708673e056f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of numerical data by plotting the histogram. The inp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TabularNumericalHistograms import TabularNumericalHistograms\n",
    "\n",
    "vm_df_train_2 = vm.init_dataset(dataset=df_train_2,\n",
    "                                target_column=target_column)\n",
    "test_context_train_2 = TestContext(dataset=vm_df_train_2)\n",
    "\n",
    "metric = TabularNumericalHistograms(test_context_train_2)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd7c66238e44bbbb432965791ec6e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h2>Cardinality ✅</h2>\\n            <p>The high cardinality test meas…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.HighCardinality import HighCardinality\n",
    "metric = HighCardinality(test_context_train_2)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe86336fcb843b2b648984b561797da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of categorical data by plotting bar plots. The input…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TabularCategoricalBarPlots import TabularCategoricalBarPlots\n",
    "metric = TabularCategoricalBarPlots(test_context_train_2)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Categories: Train and Test Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_3_eda_drop_categories = eda_drop_categories(df_train_2)\n",
    "df_test_3_eda_drop_categories = eda_drop_categories(df_test_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Assess Train Dataset 3: drop categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 09:43:18,651 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-08-06 09:43:18,652 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column default is correct and contains only 1 and 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdfb1104a3741e799e807249f1ff82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of target ratios by plotting bar plots. The input da…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TargetRateBarPlots import TargetRateBarPlots\n",
    "\n",
    "vm_df_train_3_eda_drop_categories = vm.init_dataset(\n",
    "    dataset=df_train_3_eda_drop_categories, \n",
    "    target_column=target_column)\n",
    "\n",
    "test_context_train_3_eda_drop_categories = TestContext(\n",
    "    dataset=vm_df_train_3_eda_drop_categories)\n",
    "\n",
    "# Configure the metric\n",
    "params = {\n",
    "    \"default_column\": target_column,\n",
    "    \"columns\": None\n",
    "}\n",
    "\n",
    "metric = TargetRateBarPlots(test_context_train_3_eda_drop_categories, params=params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Features: Train and Test Dataset 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['addr_state', 'total_rec_int', 'loan_amnt',\n",
    "                    'funded_amnt_inv', 'dti', 'revol_util', 'total_pymnt', \n",
    "                    'total_pymnt_inv', 'last_pymnt_amnt']\n",
    "\n",
    "df_train_4_eda_drop_features = drop_features(\n",
    "    df=df_train_3_eda_drop_categories, \n",
    "    features_to_drop = features_to_drop)\n",
    "\n",
    "df_test_4_eda_drop_features = drop_features(\n",
    "    df=df_test_3_eda_drop_categories, \n",
    "    features_to_drop = features_to_drop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Assess Train Dataset 4: drop features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 09:43:29,679 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-08-06 09:43:29,681 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211cc561eb2b4e36bea771a31053e997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Perform a Chi-Squared test of independence for each categorical variable with th…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.ChiSquaredFeaturesTable import ChiSquaredFeaturesTable\n",
    "\n",
    "vm_df_train_4_eda_drop_features = vm.init_dataset(dataset=df_train_4_eda_drop_features, target_column=target_column)\n",
    "test_context_train_4_eda_drop_features = TestContext(dataset=vm_df_train_4_eda_drop_features)\n",
    "\n",
    "cat_features = get_categorical_columns(df_train_4_eda_drop_features)\n",
    "params = {\"cat_features\": cat_features,\n",
    "          \"p_threshold\": 0.05}\n",
    "\n",
    "metric = ChiSquaredFeaturesTable(test_context_train_4_eda_drop_features, params)\n",
    "metric.run()\n",
    "await metric.result.log() \n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726b2d506b6a4cf7a3a597387cb02c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Perform an ANOVA F-test for each numerical variable with the target. The input d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.ANOVAOneWayTable import ANOVAOneWayTable\n",
    "\n",
    "num_features = get_numerical_columns(df_train_4_eda_drop_features)\n",
    "params = {\"num_features\": num_features,\n",
    "          \"p_threshold\": 0.05}\n",
    "\n",
    "metric = ANOVAOneWayTable(test_context_train_4_eda_drop_features, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f622b468954a59b1c5248139070fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Extracts the Pearson correlation coefficient for all pairs of numerical variable…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.PearsonCorrelationMatrix import PearsonCorrelationMatrix\n",
    "\n",
    "params = {\"declutter\": False,\n",
    "          \"features\": None,\n",
    "          \"fontsize\": 13}\n",
    "\n",
    "metric = PearsonCorrelationMatrix(test_context_train_4_eda_drop_features, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983090806f8e40239067daca98765d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of correlations between features and target by plott…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.FeatureTargetCorrelationPlot import FeatureTargetCorrelationPlot\n",
    "\n",
    "params = {\"features\": None}\n",
    "\n",
    "metric = FeatureTargetCorrelationPlot(test_context_train_4_eda_drop_features, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Assess Train Dataset 4: class binning and merging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with breaks_adj: None\n",
      "Performing binning with breaks_adj: None\n",
      "[INFO] creating woe binning ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43cd0adfb674a7582d0b7ceedf88524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<p>Implements WoE-based automatic binning for features in a dataset and calculates …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.WOEBinTable import WOEBinTable\n",
    "\n",
    "# Run test\n",
    "metric = WOEBinTable(test_context_train_4_eda_drop_features)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "woe_iv_dic = metric.result.metric.value['woe_iv']\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with breaks_adj: {'int_rate': [5, 10, 15]}\n",
      "Performing binning with breaks_adj: {'int_rate': [5, 10, 15]}\n",
      "[INFO] creating woe binning ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead7a27a1f4e44c198930182c295d836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<p>Implements WoE-based automatic binning for features in a dataset and calculates …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set test parameters\n",
    "params = {\n",
    "    \"breaks_adj\": {\n",
    "        \"int_rate\": [5,10,15]}  \n",
    "     }\n",
    "\n",
    "# Run test\n",
    "metric = WOEBinTable(test_context_train_4_eda_drop_features, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "woe_iv_dic = metric.result.metric.value['woe_iv']\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c9b02770d94073a3bd986360bd2e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of the WoE and IV values distribution for categorica…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.WOEBinPlots import WOEBinPlots\n",
    "\n",
    "# Set test parameters\n",
    "params = {\n",
    "    \"breaks_adj\": {\"int_rate\": [5,10,15]},\n",
    "    \"fig_height\": 500,\n",
    "}\n",
    "\n",
    "# Run test\n",
    "metric = WOEBinPlots(test_context_train_4_eda_drop_features, params=params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Features into WoE Values: Train and Test Dataset 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with breaks_adj: {'int_rate': [5, 10, 15]}\n",
      "Performing binning with breaks_adj: {'int_rate': [5, 10, 15]}\n",
      "[INFO] creating woe binning ...\n"
     ]
    }
   ],
   "source": [
    "# Compute WoE \n",
    "params = {\n",
    "    \"breaks_adj\": {\n",
    "        \"int_rate\": [5,10,15]}  \n",
    "     }\n",
    "\n",
    "metric = WOEBinTable(test_context_train_4_eda_drop_features, params=params)\n",
    "metric.run()\n",
    "woe_dic = metric.result.metric.value['woe_iv']\n",
    "woe_df = pd.DataFrame(woe_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] converting into woe values ...\n",
      "[INFO] converting into woe values ...\n"
     ]
    }
   ],
   "source": [
    "df_train_5_convert_to_woe = convert_to_woe(\n",
    "    df=df_train_4_eda_drop_features,\n",
    "    woe_df=woe_df,\n",
    "    target_col=target_column) \n",
    "\n",
    "df_test_5_convert_to_woe = convert_to_woe(\n",
    "    df=df_test_4_eda_drop_features, \n",
    "    woe_df=woe_df, \n",
    "    target_col=target_column) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Constant: Train and Test Dataset 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_6_add_const, X_train, y_train = add_constant(\n",
    "    df=df_train_5_convert_to_woe,\n",
    "    target_column=target_column)\n",
    "\n",
    "df_test_6_add_const, X_test, y_test = add_constant(\n",
    "    df=df_test_5_convert_to_woe,\n",
    "    target_column=target_column)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:               105815\n",
      "Model:                            GLM   Df Residuals:                   105800\n",
      "Model Family:                Binomial   Df Model:                           14\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -45535.\n",
      "Date:                Sun, 06 Aug 2023   Deviance:                       91071.\n",
      "Time:                        09:44:19   Pearson chi2:                 1.06e+05\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.07964\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -1.5144      0.009   -176.593      0.000      -1.531      -1.498\n",
      "installment_woe             1.4156      0.060     23.753      0.000       1.299       1.532\n",
      "term_woe                    0.6276      0.020     31.839      0.000       0.589       0.666\n",
      "int_rate_woe                0.2125      0.030      7.190      0.000       0.155       0.270\n",
      "sub_grade_woe               0.3581      0.037      9.701      0.000       0.286       0.430\n",
      "emp_length_woe              0.8059      0.190      4.234      0.000       0.433       1.179\n",
      "annual_inc_woe              1.1713      0.040     28.970      0.000       1.092       1.251\n",
      "inq_last_6mths_woe          0.4061      0.065      6.286      0.000       0.279       0.533\n",
      "Unnamed: 0_woe              0.5037      0.047     10.764      0.000       0.412       0.595\n",
      "home_ownership_woe          0.7176      0.088      8.142      0.000       0.545       0.890\n",
      "verification_status_woe     0.2440      0.042      5.746      0.000       0.161       0.327\n",
      "open_acc_woe                1.6057      0.165      9.749      0.000       1.283       1.929\n",
      "purpose_woe                 0.2211      0.098      2.267      0.023       0.030       0.412\n",
      "grade_woe                   0.2113      0.039      5.464      0.000       0.135       0.287\n",
      "total_acc_woe               1.1828      0.169      7.018      0.000       0.852       1.513\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "model_fit_1_candidate = model.fit()\n",
    "\n",
    "# Print out the statistics\n",
    "print(model_fit_1_candidate.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Features: Train and Test Dataset 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = []\n",
    "\n",
    "df_train_7_drop_features = drop_features(\n",
    "    df=df_train_6_add_const, \n",
    "    features_to_drop=features_to_drop)\n",
    "\n",
    "df_test_7_drop_features = drop_features(\n",
    "    df=df_test_6_add_const, \n",
    "    features_to_drop=features_to_drop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and dataframe saved as model_fit_glm_scorecard_20230806_094419.pkl\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:               105815\n",
      "Model:                            GLM   Df Residuals:                   105800\n",
      "Model Family:                Binomial   Df Model:                           14\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -45535.\n",
      "Date:                Sun, 06 Aug 2023   Deviance:                       91071.\n",
      "Time:                        09:44:19   Pearson chi2:                 1.06e+05\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.07964\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -1.5144      0.009   -176.593      0.000      -1.531      -1.498\n",
      "installment_woe             1.4156      0.060     23.753      0.000       1.299       1.532\n",
      "term_woe                    0.6276      0.020     31.839      0.000       0.589       0.666\n",
      "int_rate_woe                0.2125      0.030      7.190      0.000       0.155       0.270\n",
      "sub_grade_woe               0.3581      0.037      9.701      0.000       0.286       0.430\n",
      "emp_length_woe              0.8059      0.190      4.234      0.000       0.433       1.179\n",
      "annual_inc_woe              1.1713      0.040     28.970      0.000       1.092       1.251\n",
      "inq_last_6mths_woe          0.4061      0.065      6.286      0.000       0.279       0.533\n",
      "Unnamed: 0_woe              0.5037      0.047     10.764      0.000       0.412       0.595\n",
      "home_ownership_woe          0.7176      0.088      8.142      0.000       0.545       0.890\n",
      "verification_status_woe     0.2440      0.042      5.746      0.000       0.161       0.327\n",
      "open_acc_woe                1.6057      0.165      9.749      0.000       1.283       1.929\n",
      "purpose_woe                 0.2211      0.098      2.267      0.023       0.030       0.412\n",
      "grade_woe                   0.2113      0.039      5.464      0.000       0.135       0.287\n",
      "total_acc_woe               1.1828      0.169      7.018      0.000       0.852       1.513\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create X_train and y_train\n",
    "y_train = df_train_7_drop_features[target_column]\n",
    "X_train = df_train_7_drop_features.drop(target_column, axis=1)\n",
    "y_test = df_test_7_drop_features[target_column]\n",
    "X_test = df_test_7_drop_features.drop(target_column, axis=1)\n",
    "\n",
    "# Define the model\n",
    "model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "model_fit_2_final = model.fit()\n",
    "\n",
    "# Save the model and train dataset for PD development \n",
    "save_data = True\n",
    "if save_data:\n",
    "    save_model_and_df(model_fit_2_final, df=df_train_7_drop_features, base_filename='model_fit_glm_scorecard')\n",
    "\n",
    "# Print out the statistics\n",
    "print(model_fit_2_final.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Assess Model Fit 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 09:44:19,738 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-08-06 09:44:19,744 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n",
      "2023-08-06 09:44:21,149 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-08-06 09:44:21,150 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    }
   ],
   "source": [
    "# Create VM dataset\n",
    "vm_df_train_7_select_features = vm.init_dataset(\n",
    "    dataset=df_train_7_drop_features,\n",
    "    target_column=target_column)\n",
    "vm_df_test_7_select_features = vm.init_dataset(\n",
    "    dataset=df_test_7_drop_features,\n",
    "    target_column=target_column)\n",
    "\n",
    "# Create VM model\n",
    "vm_model_fit_2_final = vm.init_model(\n",
    "    model = model_fit_2_final, \n",
    "    train_ds=vm_df_train_7_select_features, \n",
    "    test_ds=vm_df_test_7_select_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5152153e59ee4e2494b8cf86b677b4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<p>Regression Coefficients with Confidence Intervals Plot</p>\\n<p>This class is use…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.RegressionCoeffsPlot import RegressionCoeffsPlot\n",
    "\n",
    "test_context_models_fit_2_final = TestContext(models = [vm_model_fit_2_final])\n",
    "\n",
    "metric = RegressionCoeffsPlot(test_context_models_fit_2_final)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a27941db6af484cb5eaa302f4b97877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This section shows the coefficients of different regression models that were tra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.RegressionModelsCoeffs import RegressionModelsCoeffs\n",
    "\n",
    "metric = RegressionModelsCoeffs(test_context_models_fit_2_final)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883d2d6c5ae54383bd2d5cf96589e27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>A confusion matrix is a table that is used to describe the performance of a clas…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.LogRegressionConfusionMatrix import LogRegressionConfusionMatrix\n",
    "\n",
    "test_context_model_fit_2_final = TestContext(model= vm_model_fit_2_final)\n",
    "\n",
    "# Configure test parameters\n",
    "params = {\n",
    "    \"cut_off_threshold\": 0.5,\n",
    "}\n",
    "\n",
    "metric = LogRegressionConfusionMatrix(test_context_model_fit_2_final, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b918a302a6424e99a11ce2169d5f1d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>A receiver operating characteristic (ROC), or simply ROC curve, is a graphical p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.RegressionROCCurve import RegressionROCCurve\n",
    "\n",
    "metric = RegressionROCCurve(test_context_model_fit_2_final)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77f2670b1a448a68fb89a8dddd31bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Compute and display the AUC, GINI, and KS for train and test sets.</p>'), HTML(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.GINITable import GINITable\n",
    "\n",
    "metric = GINITable(test_context_model_fit_2_final)\n",
    "metric.run()\n",
    "await metric.result.log() \n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d0b26de7e6488db72e554b9ac1be4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This metric calculates the probability of default (PD) for each instance in the …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.LogisticRegPredictionHistogram import LogisticRegPredictionHistogram\n",
    "\n",
    "# Configure test parameters\n",
    "params = {\n",
    "    \"title\": \"Histogram of Probability of Default\",\n",
    "}\n",
    "\n",
    "metric = LogisticRegPredictionHistogram(test_context_model_fit_2_final, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f068ff7af3e145399d1ec8c0d3bbe48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This metric calculates the cumulative probabilities for each instance in the tra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.LogisticRegCumulativeProb import LogisticRegCumulativeProb\n",
    "\n",
    "# Configure test parameters\n",
    "params = {\n",
    "    \"title\": \"Cumulative Probability of Default\",\n",
    "}\n",
    "\n",
    "metric = LogisticRegCumulativeProb(test_context_model_fit_2_final, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa0179d7fa1472581ed3c76d11786df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This metric calculates the credit score for each instance in the training and te…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.statsmodels.ScorecardHistogram import ScorecardHistogram\n",
    "\n",
    "# Configure test parameters\n",
    "params = {\n",
    "    \"target_score\": 600,\n",
    "    \"target_odds\": 50,\n",
    "    \"pdo\": 20,\n",
    "    \"title\": \"Histogram of Credit Scores\",\n",
    "}\n",
    "\n",
    "metric = ScorecardHistogram(test_context_model_fit_2_final, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-framework",
   "language": "python",
   "name": "dev-framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

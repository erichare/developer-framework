{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Scorecard Demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Credit risk Scorecard** model created from the Lending Club dataset is instrumental in computing the Probability of Default (PD), a key factor in ECL calculations. This scorecard assesses several credit characteristics of potential borrowers, like their credit history, income, outstanding debts, and more, each of which is assigned a specific score. By combining these scores, we derive a total score for each borrower, which translates into an estimated Point-in-Time (PiT) PD. The PiT PD reflects the borrower's likelihood of default at a specific point in time, accounting for both current and foreseeable future conditions.\n",
    "\n",
    "Additionally, for a holistic view of credit risk, it's essential to estimate the Lifetime PD. The Lifetime PD, as the name suggests, predicts the borrower's likelihood of default throughout the life of the exposure, taking into account potential future changes in the economic and financial conditions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key and secret from environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv .env\n",
    "\n",
    "# Standard library imports\n",
    "import re\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "# Data handling and analysis imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# File handling import\n",
    "import zipfile\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to ValidMind Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 15:06:45,509 - INFO(validmind.api_client): Connected to ValidMind. Project: [6] Credit Risk Scorecard - Initial Validation (clk00h0u800x9qjy67gduf5om)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
    "  api_key = \"2494c3838f48efe590d531bfe225d90b\",\n",
    "  api_secret = \"4f692f8161f128414fef542cab2a4e74834c75d01b3a8e088a1834f2afcfe838\",\n",
    "  project = \"clk00h0u800x9qjy67gduf5om\"\n",
    ")\n",
    "  \n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_df(model, df, base_filename):\n",
    "    \"\"\"Save a model and a dataframe with a timestamp in the filename\"\"\"\n",
    "    # Get current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Convert the current date and time to string\n",
    "    timestamp_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    filename = f'{base_filename}_{timestamp_str}.pkl'\n",
    "\n",
    "    # Save the model and dataframe\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump((model, df), file)\n",
    "        \n",
    "    print(f\"Model and dataframe saved as {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_columns(df):\n",
    "        numerical_columns = df.select_dtypes(\n",
    "            include=[\"int\", \"float\", \"uint\"]\n",
    "        ).columns.tolist()\n",
    "        return numerical_columns\n",
    "\n",
    "def get_categorical_columns(df):\n",
    "        categorical_columns = df.select_dtypes(\n",
    "            include=[\"object\", \"category\"]\n",
    "        ).columns.tolist()\n",
    "        return categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target_column(df, target_column):\n",
    "    # Assuming the column name is 'loan_status'\n",
    "    df[target_column] = df['loan_status'].apply(lambda x: 0 if x == \"Fully Paid\" else 1 if x == \"Charged Off\" else np.nan)\n",
    "    # Remove rows where the target column is NaN\n",
    "    df = df.dropna(subset=[target_column])\n",
    "    # Convert target column to integer\n",
    "    df[target_column] = df[target_column].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_variables = [\"id\", \"member_id\", \"funded_amnt\", \"emp_title\", \"url\", \"desc\", \"application_type\",\n",
    "                    \"title\", \"zip_code\", \"delinq_2yrs\", \"mths_since_last_delinq\", \"mths_since_last_record\",\n",
    "                    \"revol_bal\", \"total_rec_prncp\", \"total_rec_late_fee\", \"recoveries\", \"out_prncp_inv\", \"out_prncp\", \n",
    "                    \"collection_recovery_fee\", \"next_pymnt_d\", \"initial_list_status\", \"pub_rec\",\n",
    "                    \"collections_12_mths_ex_med\", \"policy_code\", \"acc_now_delinq\", \"pymnt_plan\",\n",
    "                    \"tot_coll_amt\", \"tot_cur_bal\", \"total_rev_hi_lim\", \"last_pymnt_d\", \"last_credit_pull_d\",\n",
    "                    'earliest_cr_line', 'issue_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variables_with_min_missing(df, min_missing_percentage):\n",
    "    # Calculate the percentage of missing values in each column\n",
    "    missing_percentages = df.isnull().mean() * 100\n",
    "\n",
    "    # Get the variables where the percentage of missing values is greater than the specified minimum\n",
    "    variables_to_drop = missing_percentages[missing_percentages > min_missing_percentage].index.tolist()\n",
    "\n",
    "    # Also add any columns where all values are missing\n",
    "    variables_to_drop.extend(df.columns[df.isnull().all()].tolist())\n",
    "\n",
    "    # Remove duplicates (if any)\n",
    "    variables_to_drop = list(set(variables_to_drop))\n",
    "\n",
    "    return variables_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_term_column(df, column):\n",
    "    \"\"\"\n",
    "    Function to remove 'months' string from the 'term' column and convert it to categorical\n",
    "    \"\"\"\n",
    "    # Ensure the column exists in the dataframe\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"The column '{column}' does not exist in the dataframe.\")\n",
    "    \n",
    "    df[column] = df[column].str.replace(' months', '')\n",
    "    \n",
    "    # Convert to categorical\n",
    "    df[column] = df[column].astype('object')\n",
    "\n",
    "def clean_emp_length_column(df, column):\n",
    "    \"\"\"\n",
    "    Function to clean 'emp_length' column and convert it to categorical.\n",
    "    \"\"\"\n",
    "    # Ensure the column exists in the dataframe\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"The column '{column}' does not exist in the dataframe.\")\n",
    "    \n",
    "    df[column] = df[column].replace('n/a', np.nan)\n",
    "    df[column] = df[column].str.replace('< 1 year', str(0))\n",
    "    df[column] = df[column].apply(lambda x: re.sub('\\D', '', str(x)))\n",
    "    df[column].fillna(value = 0, inplace=True)\n",
    "\n",
    "    # Convert to categorical\n",
    "    df[column] = df[column].astype('object')\n",
    "\n",
    "def clean_inq_last_6mths(df, column):\n",
    "    \"\"\"\n",
    "    Function to convert 'inq_last_6mths' column into categorical.\n",
    "    \"\"\"\n",
    "    # Ensure the column exists in the dataframe\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"The column '{column}' does not exist in the dataframe.\")\n",
    "\n",
    "    # Convert to categorical\n",
    "    df[column] = df[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_outliers(series, threshold=1.5):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "    return series[(series < lower_bound) | (series > upper_bound)]\n",
    "\n",
    "def remove_iqr_outliers(df, target_column, threshold=1.5):\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    num_cols.remove(target_column)  # Exclude target_column from numerical columns\n",
    "    for col in num_cols:\n",
    "        outliers = compute_outliers(df[col], threshold)\n",
    "        df = df[~df[col].isin(outliers)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def class_binning(df, bin_mappings):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    for feature, bins in bin_mappings.items():\n",
    "        # Convert to numeric, turn non-numeric data into NaN\n",
    "        df_new[feature] = pd.to_numeric(df_new[feature], errors='coerce')\n",
    "        \n",
    "        # Fill NaN with a default value\n",
    "        df_new[feature].fillna(-1, inplace=True)\n",
    "        \n",
    "        # Bin the feature\n",
    "        bins = [-np.inf] + bins + [np.inf]\n",
    "        df_new[f'{feature}_bucket'] = pd.cut(df_new[feature], bins=bins, right=False, include_lowest=True)\n",
    "        df_new.drop(columns=feature, inplace=True)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "\n",
    "def class_coarsing(df, coarse_mappings):\n",
    "    df_new = df.copy()\n",
    "\n",
    "    for feature, coarse_bins in coarse_mappings.items():\n",
    "        df_new[f'{feature}_coarse'] = df_new[feature]  # start with original categories\n",
    "\n",
    "        for i, coarse_bin in enumerate(coarse_bins):\n",
    "            df_new.loc[df_new[feature].isin(coarse_bin), f'{feature}_coarse'] = f'{feature}_group_{i}'\n",
    "\n",
    "        df_new.drop(columns=feature, inplace=True)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_categorical_features(df):\n",
    "    # Get the column names of features with the data type \"category\"\n",
    "    categorical_features = df.select_dtypes(include='category').columns.tolist()\n",
    "\n",
    "    return categorical_features\n",
    "\n",
    "\n",
    "def convert_categorical_to_object(df):\n",
    "    # Find the categorical features\n",
    "    categorical_features = find_categorical_features(df)\n",
    "\n",
    "    # Convert the categorical features to object type\n",
    "    df[categorical_features] = df[categorical_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_categories(woe_df, original_df):\n",
    "    for feature in woe_df['Feature'].unique():\n",
    "        woe_categories = woe_df[woe_df['Feature'] == feature]['Category'].unique()\n",
    "        original_categories = original_df[feature].unique()\n",
    "        \n",
    "        # Check categories in WoE table that are not in original DataFrame\n",
    "        for category in woe_categories:\n",
    "            if category not in original_categories:\n",
    "                print(f\"Category '{category}' not found in feature '{feature}' in original DataFrame.\")\n",
    "                \n",
    "        # Check categories in original DataFrame that are not in WoE table\n",
    "        for category in original_categories:\n",
    "            if category not in woe_categories:\n",
    "                print(f\"Category '{category}' in feature '{feature}' not found in WoE table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_encoder(woe_df, original_df, target):\n",
    "    # Create a new DataFrame with the same columns as original_df\n",
    "    woe_encoded_df = pd.DataFrame(columns=original_df.columns, index=original_df.index)\n",
    "\n",
    "    # Loop through each feature-category and assign the corresponding WoE value as float\n",
    "    for feature in woe_df['Feature'].unique():\n",
    "        # Check that the feature exists in the original DataFrame\n",
    "        if feature not in original_df.columns:\n",
    "            print(f\"Feature {feature} not found in original DataFrame. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        feature_woe = woe_df[woe_df['Feature'] == feature]\n",
    "        woe_dict = dict(zip(feature_woe['Category'], feature_woe['WoE']))\n",
    "\n",
    "        # Check that the categories exist in the original DataFrame\n",
    "        # Converting both to strings to avoid datatype issues\n",
    "        original_categories = original_df[feature].astype(str).unique()\n",
    "        woe_categories = feature_woe['Category'].astype(str).unique()\n",
    "        \n",
    "        # Two-way check:\n",
    "        # 1. For each category in the original DataFrame, check if it exists in the WoE DataFrame\n",
    "        missing_from_woe = [category for category in original_categories if category not in woe_categories]\n",
    "        if missing_from_woe:\n",
    "            print(f\"Categories {missing_from_woe} from original DataFrame not found in WoE DataFrame for feature {feature}.\")\n",
    "            \n",
    "        # 2. For each category in the WoE DataFrame, check if it exists in the original DataFrame\n",
    "        missing_from_original = [category for category in woe_categories if category not in original_categories]\n",
    "        if missing_from_original:\n",
    "            print(f\"Categories {missing_from_original} from WoE DataFrame not found in original DataFrame for feature {feature}.\")\n",
    "        \n",
    "        # Also converting original dataframe feature to string before replacement\n",
    "        woe_encoded_df[feature] = original_df[feature].astype(str).replace(woe_dict).astype(float)\n",
    "\n",
    "    # Check that the target exists in the original DataFrame\n",
    "    if target not in original_df.columns:\n",
    "        print(f\"Target {target} not found in original DataFrame. Returning None...\")\n",
    "        return None\n",
    "\n",
    "    # Add the target column to the new DataFrame\n",
    "    woe_encoded_df[target] = original_df[target]\n",
    "\n",
    "    return woe_encoded_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/rbr74q892k13m82y37y396h40000gn/T/ipykernel_62689/403622063.py:2: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(filepath)\n"
     ]
    }
   ],
   "source": [
    "filepath = '/Users/juanvalidmind/Dev/datasets/lending club/data_2007_2014/loan_data_2007_2014.csv'\n",
    "df_raw = pd.read_csv(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 15:06:48,329 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-27 15:06:48,329 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7757b9e8d56f49729a50fc51b527a3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>This section provides descriptive statistics for numerical and categorical varia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.vm_models.test_context import TestContext\n",
    "from validmind.tests.data_validation.DescriptiveStatistics import DescriptiveStatistics\n",
    "\n",
    "vm_df_raw = vm.init_dataset(dataset=df_raw)\n",
    "test_context_raw = TestContext(dataset=vm_df_raw)\n",
    "\n",
    "metric = DescriptiveStatistics(test_context_raw)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9991dcd863475d807cb0406d204cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of missing values by plotting horizontal bar plots w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.MissingValuesBarPlot import MissingValuesBarPlot\n",
    "\n",
    "params = {\"threshold\": 70,\n",
    "          \"fig_height\": 1100}\n",
    "\n",
    "metric = MissingValuesBarPlot(test_context_raw, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tn/rbr74q892k13m82y37y396h40000gn/T/ipykernel_62689/668951511.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/tn/rbr74q892k13m82y37y396h40000gn/T/ipykernel_62689/2621629285.py:6: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definition of default\n",
    "target_column = 'default'\n",
    "df_prep_1 = add_target_column(df_raw, target_column)\n",
    "\n",
    "# Drop 'loan_status' variable \n",
    "df_prep_1.drop(columns='loan_status', axis=1, inplace=True)\n",
    "\n",
    "# Remove unused variables\n",
    "df_prep_1 = df_prep_1.drop(columns=unused_variables)\n",
    "\n",
    "# Remove missing values\n",
    "min_missing_count = 80\n",
    "variables_to_drop = variables_with_min_missing(df_prep_1, min_missing_count)\n",
    "df_prep_1.drop(columns=variables_to_drop, axis=1, inplace=True)\n",
    "df_prep_1.dropna(axis=0, subset=[\"emp_length\"], inplace=True)\n",
    "df_prep_1.dropna(axis=0, subset=[\"revol_util\"], inplace=True)\n",
    "\n",
    "# Format variable types\n",
    "clean_emp_length_column(df_prep_1, 'emp_length')\n",
    "clean_term_column(df_prep_1, 'term')\n",
    "clean_inq_last_6mths(df_prep_1, 'inq_last_6mths')\n",
    "\n",
    "# Remove outliers\n",
    "df_prep_1 = remove_iqr_outliers(df_prep_1, target_column, threshold=1.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 15:06:59,701 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-27 15:06:59,701 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826229ef43d44b73b91e1d04569e07fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h2>Class Imbalance ❌</h2>\\n            <p>The class imbalance test m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.ClassImbalance import ClassImbalance\n",
    "\n",
    "vm_df_prep_1 = vm.init_dataset(dataset=df_prep_1,\n",
    "                        target_column=target_column)\n",
    "test_context_prep_1 = TestContext(dataset=vm_df_prep_1)\n",
    "\n",
    "metric = ClassImbalance(test_context_prep_1)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813866a60f5d40b5bcb12b4ad5fae31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Analyzes the distribution of outliers in numerical features using the Interquart…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.IQROutliersTable import IQROutliersTable\n",
    "\n",
    "num_features = get_numerical_columns(df_prep_1)\n",
    "params = {\"num_features\": num_features,\n",
    "          \"threshold\": 1.5\n",
    "        }\n",
    "\n",
    "metric = IQROutliersTable(test_context_prep_1, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ca4aebe2274cba82c22953d03a1d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of the outliers for numeric variables based on perce…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.IQROutliersBarPlot import IQROutliersBarPlot\n",
    "\n",
    "num_features = get_numerical_columns(df_prep_1)\n",
    "params = {\"num_features\": num_features,\n",
    "          \"threshold\": 1.5,\n",
    "          \"fig_width\": 500}\n",
    "\n",
    "metric = IQROutliersBarPlot(test_context_prep_1, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We employ stratified sampling to create our training and testing sets. Stratified sampling is particularly important in this context. When the `stratify = y` parameter is set, it ensures that the distribution of the target variable (`y`) in the test set is the same as that in the original dataset. \n",
    "\n",
    "This is crucial for maintaining a consistent representation of the target variable classes, especially important in scenarios where the classes are imbalanced, which is often the case in credit risk scorecards."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test \n",
    "X = df_prep_1.drop(target_column, axis = 1)\n",
    "y = df_prep_1[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                    random_state = 42, stratify = y)\n",
    "\n",
    "# Concatenate X_train with y_train to form df_train\n",
    "df_train_1 = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Concatenate X_test with y_test to form df_test\n",
    "df_test_1 = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Train Data 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 15:07:22,116 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-27 15:07:22,116 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc4543840c844f1b348fc7e117ec61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of numerical data by plotting the histogram. The inp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TabularNumericalHistograms import TabularNumericalHistograms\n",
    "\n",
    "vm_df = vm.init_dataset(dataset=df_train_1,\n",
    "                                target_column=target_column)\n",
    "test_context_train_1 = TestContext(dataset=vm_df)\n",
    "\n",
    "metric = TabularNumericalHistograms(test_context_train_1)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c4b97e73ee48f791ab9138f00c95ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h2>Cardinality ✅</h2>\\n            <p>The high cardinality test meas…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.HighCardinality import HighCardinality\n",
    "metric = HighCardinality(test_context_train_1)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df81cebe90b6416896d03e3ea0bd6276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of categorical data by plotting bar plots. The input…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TabularCategoricalBarPlots import TabularCategoricalBarPlots\n",
    "metric = TabularCategoricalBarPlots(test_context_train_1)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows where purpose is 'debt_consolidation' or 'credit_card'\n",
    "df_train_1 = df_train_1[df_train_1['purpose'].isin(['debt_consolidation', 'credit_card'])]\n",
    "df_test_1 = df_test_1[df_test_1['purpose'].isin(['debt_consolidation', 'credit_card'])]\n",
    "\n",
    "# Remove rows where grade is 'F' or 'G'\n",
    "df_train_1 = df_train_1[~df_train_1['grade'].isin(['F', 'G'])]\n",
    "df_test_1 = df_test_1[~df_test_1['grade'].isin(['F', 'G'])]\n",
    "\n",
    "# Remove rows where sub_grade starts with 'F' or 'G'\n",
    "df_train_1 = df_train_1[~df_train_1['sub_grade'].str.startswith(('F', 'G'))]\n",
    "df_test_1 = df_test_1[~df_test_1['sub_grade'].str.startswith(('F', 'G'))]\n",
    "\n",
    "# Remove rows where home_ownership is 'OTHER', 'NONE', or 'ANY'\n",
    "df_train_1 = df_train_1[~df_train_1['home_ownership'].isin(['OTHER', 'NONE', 'ANY'])]\n",
    "df_test_1 = df_test_1[~df_test_1['home_ownership'].isin(['OTHER', 'NONE', 'ANY'])]\n",
    "\n",
    "# Update train and test\n",
    "df_train_2 = df_train_1.copy()\n",
    "df_test_2 = df_test_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 15:08:20,448 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-27 15:08:20,449 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column default is correct and contains only 1 and 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fb3247514d4761a1cfc643e1f7d540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of target ratios by plotting bar plots. The input da…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.TargetRateBarPlots import TargetRateBarPlots\n",
    "\n",
    "vm_df = vm.init_dataset(dataset=df_train_2, target_column=target_column)\n",
    "test_context_train_2 = TestContext(dataset=vm_df)\n",
    "\n",
    "# Configure the metric\n",
    "params = {\n",
    "    \"default_column\": target_column,\n",
    "    \"columns\": None\n",
    "}\n",
    "\n",
    "metric = TargetRateBarPlots(test_context_train_2, params=params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_categorical_features = ['addr_state']\n",
    "drop_numerical_features = ['total_rec_int', 'loan_amnt',\n",
    "                           'funded_amnt_inv', 'dti', 'revol_util', 'total_pymnt', \n",
    "                           'total_pymnt_inv', 'last_pymnt_amnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop variables from next analysis\n",
    "df_train_3 = df_train_2.drop(columns = drop_categorical_features + drop_numerical_features, axis=1)\n",
    "\n",
    "# Update df_test \n",
    "df_test_3 = df_test_2.drop(columns = drop_categorical_features + drop_numerical_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 15:08:31,782 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-27 15:08:31,782 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3091a36b3d4de3834dd74a2f0ba7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Perform a Chi-Squared test of independence for each categorical variable with th…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.ChiSquaredFeaturesTable import ChiSquaredFeaturesTable\n",
    "\n",
    "vm_df = vm.init_dataset(dataset=df_train_3, target_column=target_column)\n",
    "test_context_train_3 = TestContext(dataset=vm_df)\n",
    "\n",
    "cat_features = get_categorical_columns(df_train_3)\n",
    "params = {\"cat_features\": cat_features,\n",
    "          \"p_threshold\": 0.05}\n",
    "\n",
    "metric = ChiSquaredFeaturesTable(test_context_train_3, params)\n",
    "metric.run()\n",
    "await metric.result.log() \n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab66a989fefa42bba7f8b46373afa856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Perform an ANOVA F-test for each numerical variable with the target. The input d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.ANOVAOneWayTable import ANOVAOneWayTable\n",
    "\n",
    "num_features = get_numerical_columns(df_train_3)\n",
    "params = {\"num_features\": num_features,\n",
    "          \"p_threshold\": 0.05}\n",
    "\n",
    "metric = ANOVAOneWayTable(test_context_train_3, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0e14d2d70a4fcb8662bdb345859108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Extracts the Pearson correlation coefficient for all pairs of numerical variable…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.PearsonCorrelationMatrix import PearsonCorrelationMatrix\n",
    "\n",
    "params = {\"declutter\": False,\n",
    "          \"features\": None,\n",
    "          \"fontsize\": 13}\n",
    "\n",
    "metric = PearsonCorrelationMatrix(test_context_train_3, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4d1b79d7904058967791a1b77921ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Generates a visual analysis of correlations between features and target by plott…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.FeatureTargetCorrelationPlot import FeatureTargetCorrelationPlot\n",
    "\n",
    "params = {\"features\": None}\n",
    "\n",
    "metric = FeatureTargetCorrelationPlot(test_context_train_3, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Train Data I: Class Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n"
     ]
    }
   ],
   "source": [
    "import scorecardpy as sc\n",
    "import pandas as pd\n",
    "\n",
    "def binning_data(df, y):\n",
    "    '''\n",
    "    This function performs automatic binning using WoE.\n",
    "    \n",
    "    df: A pandas dataframe\n",
    "    y: The target variable in quotes, e.g. 'target'\n",
    "    '''\n",
    "\n",
    "    # Identify non-numeric columns\n",
    "    non_numeric_cols = df.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "\n",
    "    # Convert non-numeric columns to string type\n",
    "    df[non_numeric_cols] = df[non_numeric_cols].astype(str)\n",
    "\n",
    "    # Perform binning\n",
    "    try:\n",
    "        bins = sc.woebin(df, y)\n",
    "    except Exception as e:\n",
    "        print(\"Error during binning: \")\n",
    "        print(e)\n",
    "    else:\n",
    "        # Concatenate the individual dataframes into a single dataframe\n",
    "        bins_df = pd.concat(bins.values(), keys=bins.keys())\n",
    "        \n",
    "        # Reset index and convert multi-index into columns\n",
    "        bins_df.reset_index(inplace=True)\n",
    "        \n",
    "        # Drop the 'variable' column as it is identical to 'level_0'\n",
    "        bins_df.drop(columns=['variable'], inplace=True)\n",
    "        \n",
    "        # Rename 'level_0' to 'variable' and 'level_1' to 'bin_number'\n",
    "        bins_df.rename(columns={'level_0': 'variable', 'level_1': 'bin_number'}, inplace=True)\n",
    "        \n",
    "        return bins_df\n",
    "\n",
    "\n",
    "bins = binning_data(df_train_3, y=target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>bin_number</th>\n",
       "      <th>bin</th>\n",
       "      <th>count</th>\n",
       "      <th>count_distr</th>\n",
       "      <th>good</th>\n",
       "      <th>bad</th>\n",
       "      <th>badprob</th>\n",
       "      <th>woe</th>\n",
       "      <th>bin_iv</th>\n",
       "      <th>total_iv</th>\n",
       "      <th>breaks</th>\n",
       "      <th>is_special_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emp_length</td>\n",
       "      <td>0</td>\n",
       "      <td>1%,%2%,%4</td>\n",
       "      <td>25128</td>\n",
       "      <td>0.237471</td>\n",
       "      <td>20830</td>\n",
       "      <td>4298</td>\n",
       "      <td>0.171044</td>\n",
       "      <td>-0.063836</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>1%,%2%,%4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emp_length</td>\n",
       "      <td>1</td>\n",
       "      <td>6%,%3</td>\n",
       "      <td>15853</td>\n",
       "      <td>0.149818</td>\n",
       "      <td>13020</td>\n",
       "      <td>2833</td>\n",
       "      <td>0.178704</td>\n",
       "      <td>-0.010742</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>6%,%3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emp_length</td>\n",
       "      <td>2</td>\n",
       "      <td>10%,%5</td>\n",
       "      <td>39904</td>\n",
       "      <td>0.377111</td>\n",
       "      <td>32691</td>\n",
       "      <td>7213</td>\n",
       "      <td>0.180759</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>10%,%5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emp_length</td>\n",
       "      <td>3</td>\n",
       "      <td>7%,%8%,%0%,%9</td>\n",
       "      <td>24930</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>20197</td>\n",
       "      <td>4733</td>\n",
       "      <td>0.189852</td>\n",
       "      <td>0.063434</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>7%,%8%,%0%,%9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>0</td>\n",
       "      <td>[-inf,44000.0)</td>\n",
       "      <td>28661</td>\n",
       "      <td>0.270860</td>\n",
       "      <td>22263</td>\n",
       "      <td>6398</td>\n",
       "      <td>0.223230</td>\n",
       "      <td>0.267468</td>\n",
       "      <td>0.021052</td>\n",
       "      <td>0.057567</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>1</td>\n",
       "      <td>[44000.0,66000.0)</td>\n",
       "      <td>38276</td>\n",
       "      <td>0.361726</td>\n",
       "      <td>31012</td>\n",
       "      <td>7264</td>\n",
       "      <td>0.189779</td>\n",
       "      <td>0.062965</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.057567</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>2</td>\n",
       "      <td>[66000.0,96000.0)</td>\n",
       "      <td>26692</td>\n",
       "      <td>0.252252</td>\n",
       "      <td>22749</td>\n",
       "      <td>3943</td>\n",
       "      <td>0.147722</td>\n",
       "      <td>-0.238171</td>\n",
       "      <td>0.013238</td>\n",
       "      <td>0.057567</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>3</td>\n",
       "      <td>[96000.0,inf)</td>\n",
       "      <td>12186</td>\n",
       "      <td>0.115163</td>\n",
       "      <td>10714</td>\n",
       "      <td>1472</td>\n",
       "      <td>0.120794</td>\n",
       "      <td>-0.470521</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>0.057567</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>open_acc</td>\n",
       "      <td>0</td>\n",
       "      <td>[-inf,7.0)</td>\n",
       "      <td>17356</td>\n",
       "      <td>0.164022</td>\n",
       "      <td>14509</td>\n",
       "      <td>2847</td>\n",
       "      <td>0.164035</td>\n",
       "      <td>-0.114095</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>open_acc</td>\n",
       "      <td>1</td>\n",
       "      <td>[7.0,11.0)</td>\n",
       "      <td>41370</td>\n",
       "      <td>0.390965</td>\n",
       "      <td>34005</td>\n",
       "      <td>7365</td>\n",
       "      <td>0.178028</td>\n",
       "      <td>-0.015360</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>open_acc</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.0,15.0)</td>\n",
       "      <td>29743</td>\n",
       "      <td>0.281085</td>\n",
       "      <td>24186</td>\n",
       "      <td>5557</td>\n",
       "      <td>0.186834</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>open_acc</td>\n",
       "      <td>3</td>\n",
       "      <td>[15.0,inf)</td>\n",
       "      <td>17346</td>\n",
       "      <td>0.163928</td>\n",
       "      <td>14038</td>\n",
       "      <td>3308</td>\n",
       "      <td>0.190707</td>\n",
       "      <td>0.068984</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>term</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>90977</td>\n",
       "      <td>0.859774</td>\n",
       "      <td>77248</td>\n",
       "      <td>13729</td>\n",
       "      <td>0.150906</td>\n",
       "      <td>-0.213102</td>\n",
       "      <td>0.036425</td>\n",
       "      <td>0.197250</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>term</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>14838</td>\n",
       "      <td>0.140226</td>\n",
       "      <td>9490</td>\n",
       "      <td>5348</td>\n",
       "      <td>0.360426</td>\n",
       "      <td>0.940893</td>\n",
       "      <td>0.160825</td>\n",
       "      <td>0.197250</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sub_grade</td>\n",
       "      <td>0</td>\n",
       "      <td>A1%,%A2%,%A3%,%A4%,%A5</td>\n",
       "      <td>18967</td>\n",
       "      <td>0.179247</td>\n",
       "      <td>17735</td>\n",
       "      <td>1232</td>\n",
       "      <td>0.064955</td>\n",
       "      <td>-1.152493</td>\n",
       "      <td>0.161218</td>\n",
       "      <td>0.399033</td>\n",
       "      <td>A1%,%A2%,%A3%,%A4%,%A5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sub_grade</td>\n",
       "      <td>1</td>\n",
       "      <td>B1%,%B2%,%B3</td>\n",
       "      <td>23284</td>\n",
       "      <td>0.220044</td>\n",
       "      <td>20559</td>\n",
       "      <td>2725</td>\n",
       "      <td>0.117033</td>\n",
       "      <td>-0.506422</td>\n",
       "      <td>0.047696</td>\n",
       "      <td>0.399033</td>\n",
       "      <td>B1%,%B2%,%B3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sub_grade</td>\n",
       "      <td>2</td>\n",
       "      <td>B4%,%B5%,%C1</td>\n",
       "      <td>22381</td>\n",
       "      <td>0.211511</td>\n",
       "      <td>18804</td>\n",
       "      <td>3577</td>\n",
       "      <td>0.159823</td>\n",
       "      <td>-0.145136</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.399033</td>\n",
       "      <td>B4%,%B5%,%C1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sub_grade</td>\n",
       "      <td>3</td>\n",
       "      <td>C2%,%C3%,%C4%,%C5%,%D1%,%D2%,%D3</td>\n",
       "      <td>32226</td>\n",
       "      <td>0.304550</td>\n",
       "      <td>24153</td>\n",
       "      <td>8073</td>\n",
       "      <td>0.250512</td>\n",
       "      <td>0.418525</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>0.399033</td>\n",
       "      <td>C2%,%C3%,%C4%,%C5%,%D1%,%D2%,%D3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sub_grade</td>\n",
       "      <td>4</td>\n",
       "      <td>D4%,%D5%,%E1%,%E2%,%E3%,%E5%,%E4</td>\n",
       "      <td>8957</td>\n",
       "      <td>0.084648</td>\n",
       "      <td>5487</td>\n",
       "      <td>3470</td>\n",
       "      <td>0.387406</td>\n",
       "      <td>1.056182</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.399033</td>\n",
       "      <td>D4%,%D5%,%E1%,%E2%,%E3%,%E5%,%E4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>int_rate</td>\n",
       "      <td>0</td>\n",
       "      <td>[-inf,7.5)</td>\n",
       "      <td>6712</td>\n",
       "      <td>0.063431</td>\n",
       "      <td>6433</td>\n",
       "      <td>279</td>\n",
       "      <td>0.041567</td>\n",
       "      <td>-1.623576</td>\n",
       "      <td>0.096669</td>\n",
       "      <td>0.401817</td>\n",
       "      <td>7.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>int_rate</td>\n",
       "      <td>1</td>\n",
       "      <td>[7.5,9.5)</td>\n",
       "      <td>13379</td>\n",
       "      <td>0.126438</td>\n",
       "      <td>12342</td>\n",
       "      <td>1037</td>\n",
       "      <td>0.077510</td>\n",
       "      <td>-0.962267</td>\n",
       "      <td>0.084614</td>\n",
       "      <td>0.401817</td>\n",
       "      <td>9.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>int_rate</td>\n",
       "      <td>2</td>\n",
       "      <td>[9.5,13.5)</td>\n",
       "      <td>38544</td>\n",
       "      <td>0.364258</td>\n",
       "      <td>33382</td>\n",
       "      <td>5162</td>\n",
       "      <td>0.133925</td>\n",
       "      <td>-0.352284</td>\n",
       "      <td>0.040256</td>\n",
       "      <td>0.401817</td>\n",
       "      <td>13.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>int_rate</td>\n",
       "      <td>3</td>\n",
       "      <td>[13.5,16.5)</td>\n",
       "      <td>29118</td>\n",
       "      <td>0.275178</td>\n",
       "      <td>22707</td>\n",
       "      <td>6411</td>\n",
       "      <td>0.220173</td>\n",
       "      <td>0.249751</td>\n",
       "      <td>0.018549</td>\n",
       "      <td>0.401817</td>\n",
       "      <td>16.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>int_rate</td>\n",
       "      <td>4</td>\n",
       "      <td>[16.5,inf)</td>\n",
       "      <td>18062</td>\n",
       "      <td>0.170694</td>\n",
       "      <td>11874</td>\n",
       "      <td>6188</td>\n",
       "      <td>0.342598</td>\n",
       "      <td>0.862669</td>\n",
       "      <td>0.161729</td>\n",
       "      <td>0.401817</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>purpose</td>\n",
       "      <td>0</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>27832</td>\n",
       "      <td>0.263025</td>\n",
       "      <td>23409</td>\n",
       "      <td>4423</td>\n",
       "      <td>0.158918</td>\n",
       "      <td>-0.151894</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>purpose</td>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>77983</td>\n",
       "      <td>0.736975</td>\n",
       "      <td>63329</td>\n",
       "      <td>14654</td>\n",
       "      <td>0.187913</td>\n",
       "      <td>0.050779</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>home_ownership</td>\n",
       "      <td>0</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>47821</td>\n",
       "      <td>0.451930</td>\n",
       "      <td>39977</td>\n",
       "      <td>7844</td>\n",
       "      <td>0.164028</td>\n",
       "      <td>-0.114147</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>home_ownership</td>\n",
       "      <td>1</td>\n",
       "      <td>OWN</td>\n",
       "      <td>8200</td>\n",
       "      <td>0.077494</td>\n",
       "      <td>6654</td>\n",
       "      <td>1546</td>\n",
       "      <td>0.188537</td>\n",
       "      <td>0.054861</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>OWN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>home_ownership</td>\n",
       "      <td>2</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49794</td>\n",
       "      <td>0.470576</td>\n",
       "      <td>40107</td>\n",
       "      <td>9687</td>\n",
       "      <td>0.194542</td>\n",
       "      <td>0.093643</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>RENT</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>grade</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>18967</td>\n",
       "      <td>0.179247</td>\n",
       "      <td>17735</td>\n",
       "      <td>1232</td>\n",
       "      <td>0.064955</td>\n",
       "      <td>-1.152493</td>\n",
       "      <td>0.161218</td>\n",
       "      <td>0.378973</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>grade</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>38628</td>\n",
       "      <td>0.365052</td>\n",
       "      <td>33567</td>\n",
       "      <td>5061</td>\n",
       "      <td>0.131019</td>\n",
       "      <td>-0.377571</td>\n",
       "      <td>0.045950</td>\n",
       "      <td>0.378973</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>grade</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>28552</td>\n",
       "      <td>0.269829</td>\n",
       "      <td>22283</td>\n",
       "      <td>6269</td>\n",
       "      <td>0.219564</td>\n",
       "      <td>0.246201</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>0.378973</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>grade</td>\n",
       "      <td>3</td>\n",
       "      <td>D%,%E</td>\n",
       "      <td>19668</td>\n",
       "      <td>0.185872</td>\n",
       "      <td>13153</td>\n",
       "      <td>6515</td>\n",
       "      <td>0.331249</td>\n",
       "      <td>0.811866</td>\n",
       "      <td>0.154149</td>\n",
       "      <td>0.378973</td>\n",
       "      <td>D%,%E</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>verification_status</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>44405</td>\n",
       "      <td>0.419647</td>\n",
       "      <td>38001</td>\n",
       "      <td>6404</td>\n",
       "      <td>0.144218</td>\n",
       "      <td>-0.266281</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.044890</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>verification_status</td>\n",
       "      <td>1</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>29621</td>\n",
       "      <td>0.279932</td>\n",
       "      <td>23647</td>\n",
       "      <td>5974</td>\n",
       "      <td>0.201681</td>\n",
       "      <td>0.138589</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>0.044890</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>verification_status</td>\n",
       "      <td>2</td>\n",
       "      <td>Verified</td>\n",
       "      <td>31789</td>\n",
       "      <td>0.300421</td>\n",
       "      <td>25090</td>\n",
       "      <td>6699</td>\n",
       "      <td>0.210733</td>\n",
       "      <td>0.193898</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.044890</td>\n",
       "      <td>Verified</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>installment</td>\n",
       "      <td>0</td>\n",
       "      <td>[-inf,260.0)</td>\n",
       "      <td>29513</td>\n",
       "      <td>0.278911</td>\n",
       "      <td>25019</td>\n",
       "      <td>4494</td>\n",
       "      <td>0.152272</td>\n",
       "      <td>-0.202484</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>260.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>installment</td>\n",
       "      <td>1</td>\n",
       "      <td>[260.0,420.0)</td>\n",
       "      <td>40627</td>\n",
       "      <td>0.383944</td>\n",
       "      <td>33471</td>\n",
       "      <td>7156</td>\n",
       "      <td>0.176139</td>\n",
       "      <td>-0.028320</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>420.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>installment</td>\n",
       "      <td>2</td>\n",
       "      <td>[420.0,520.0)</td>\n",
       "      <td>15812</td>\n",
       "      <td>0.149431</td>\n",
       "      <td>12739</td>\n",
       "      <td>3073</td>\n",
       "      <td>0.194346</td>\n",
       "      <td>0.092395</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>520.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>installment</td>\n",
       "      <td>3</td>\n",
       "      <td>[520.0,inf)</td>\n",
       "      <td>19863</td>\n",
       "      <td>0.187714</td>\n",
       "      <td>15509</td>\n",
       "      <td>4354</td>\n",
       "      <td>0.219202</td>\n",
       "      <td>0.244083</td>\n",
       "      <td>0.012065</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>inq_last_6mths</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54276</td>\n",
       "      <td>0.512933</td>\n",
       "      <td>45404</td>\n",
       "      <td>8872</td>\n",
       "      <td>0.163461</td>\n",
       "      <td>-0.118291</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>inq_last_6mths</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30245</td>\n",
       "      <td>0.285829</td>\n",
       "      <td>24626</td>\n",
       "      <td>5619</td>\n",
       "      <td>0.185783</td>\n",
       "      <td>0.036760</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>inq_last_6mths</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0%,%2.0%,%4.0%,%6.0</td>\n",
       "      <td>15429</td>\n",
       "      <td>0.145811</td>\n",
       "      <td>12163</td>\n",
       "      <td>3266</td>\n",
       "      <td>0.211679</td>\n",
       "      <td>0.199576</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>5.0%,%2.0%,%4.0%,%6.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>inq_last_6mths</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0%,%7.0%,%8.0</td>\n",
       "      <td>5865</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>4545</td>\n",
       "      <td>1320</td>\n",
       "      <td>0.225064</td>\n",
       "      <td>0.278013</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>3.0%,%7.0%,%8.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>total_acc</td>\n",
       "      <td>0</td>\n",
       "      <td>[-inf,21.0)</td>\n",
       "      <td>45622</td>\n",
       "      <td>0.431149</td>\n",
       "      <td>37020</td>\n",
       "      <td>8602</td>\n",
       "      <td>0.188549</td>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>21.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>total_acc</td>\n",
       "      <td>1</td>\n",
       "      <td>[21.0,26.0)</td>\n",
       "      <td>19993</td>\n",
       "      <td>0.188943</td>\n",
       "      <td>16368</td>\n",
       "      <td>3625</td>\n",
       "      <td>0.181313</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>total_acc</td>\n",
       "      <td>2</td>\n",
       "      <td>[26.0,34.0)</td>\n",
       "      <td>22833</td>\n",
       "      <td>0.215782</td>\n",
       "      <td>18847</td>\n",
       "      <td>3986</td>\n",
       "      <td>0.174572</td>\n",
       "      <td>-0.039157</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>total_acc</td>\n",
       "      <td>3</td>\n",
       "      <td>[34.0,inf)</td>\n",
       "      <td>17367</td>\n",
       "      <td>0.164126</td>\n",
       "      <td>14503</td>\n",
       "      <td>2864</td>\n",
       "      <td>0.164910</td>\n",
       "      <td>-0.107728</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>inf</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               variable  bin_number                               bin  count  \\\n",
       "0            emp_length           0                         1%,%2%,%4  25128   \n",
       "1            emp_length           1                             6%,%3  15853   \n",
       "2            emp_length           2                            10%,%5  39904   \n",
       "3            emp_length           3                     7%,%8%,%0%,%9  24930   \n",
       "4            annual_inc           0                    [-inf,44000.0)  28661   \n",
       "5            annual_inc           1                 [44000.0,66000.0)  38276   \n",
       "6            annual_inc           2                 [66000.0,96000.0)  26692   \n",
       "7            annual_inc           3                     [96000.0,inf)  12186   \n",
       "8              open_acc           0                        [-inf,7.0)  17356   \n",
       "9              open_acc           1                        [7.0,11.0)  41370   \n",
       "10             open_acc           2                       [11.0,15.0)  29743   \n",
       "11             open_acc           3                        [15.0,inf)  17346   \n",
       "12                 term           0                                36  90977   \n",
       "13                 term           1                                60  14838   \n",
       "14            sub_grade           0            A1%,%A2%,%A3%,%A4%,%A5  18967   \n",
       "15            sub_grade           1                      B1%,%B2%,%B3  23284   \n",
       "16            sub_grade           2                      B4%,%B5%,%C1  22381   \n",
       "17            sub_grade           3  C2%,%C3%,%C4%,%C5%,%D1%,%D2%,%D3  32226   \n",
       "18            sub_grade           4  D4%,%D5%,%E1%,%E2%,%E3%,%E5%,%E4   8957   \n",
       "19             int_rate           0                        [-inf,7.5)   6712   \n",
       "20             int_rate           1                         [7.5,9.5)  13379   \n",
       "21             int_rate           2                        [9.5,13.5)  38544   \n",
       "22             int_rate           3                       [13.5,16.5)  29118   \n",
       "23             int_rate           4                        [16.5,inf)  18062   \n",
       "24              purpose           0                       credit_card  27832   \n",
       "25              purpose           1                debt_consolidation  77983   \n",
       "26       home_ownership           0                          MORTGAGE  47821   \n",
       "27       home_ownership           1                               OWN   8200   \n",
       "28       home_ownership           2                              RENT  49794   \n",
       "29                grade           0                                 A  18967   \n",
       "30                grade           1                                 B  38628   \n",
       "31                grade           2                                 C  28552   \n",
       "32                grade           3                             D%,%E  19668   \n",
       "33  verification_status           0                      Not Verified  44405   \n",
       "34  verification_status           1                   Source Verified  29621   \n",
       "35  verification_status           2                          Verified  31789   \n",
       "36          installment           0                      [-inf,260.0)  29513   \n",
       "37          installment           1                     [260.0,420.0)  40627   \n",
       "38          installment           2                     [420.0,520.0)  15812   \n",
       "39          installment           3                       [520.0,inf)  19863   \n",
       "40       inq_last_6mths           0                               0.0  54276   \n",
       "41       inq_last_6mths           1                               1.0  30245   \n",
       "42       inq_last_6mths           2             5.0%,%2.0%,%4.0%,%6.0  15429   \n",
       "43       inq_last_6mths           3                   3.0%,%7.0%,%8.0   5865   \n",
       "44            total_acc           0                       [-inf,21.0)  45622   \n",
       "45            total_acc           1                       [21.0,26.0)  19993   \n",
       "46            total_acc           2                       [26.0,34.0)  22833   \n",
       "47            total_acc           3                        [34.0,inf)  17367   \n",
       "\n",
       "    count_distr   good    bad   badprob       woe    bin_iv  total_iv  \\\n",
       "0      0.237471  20830   4298  0.171044 -0.063836  0.000948  0.001936   \n",
       "1      0.149818  13020   2833  0.178704 -0.010742  0.000017  0.001936   \n",
       "2      0.377111  32691   7213  0.180759  0.003194  0.000004  0.001936   \n",
       "3      0.235600  20197   4733  0.189852  0.063434  0.000967  0.001936   \n",
       "4      0.270860  22263   6398  0.223230  0.267468  0.021052  0.057567   \n",
       "5      0.361726  31012   7264  0.189779  0.062965  0.001463  0.057567   \n",
       "6      0.252252  22749   3943  0.147722 -0.238171  0.013238  0.057567   \n",
       "7      0.115163  10714   1472  0.120794 -0.470521  0.021814  0.057567   \n",
       "8      0.164022  14509   2847  0.164035 -0.114095  0.002058  0.003491   \n",
       "9      0.390965  34005   7365  0.178028 -0.015360  0.000092  0.003491   \n",
       "10     0.281085  24186   5557  0.186834  0.043693  0.000544  0.003491   \n",
       "11     0.163928  14038   3308  0.190707  0.068984  0.000797  0.003491   \n",
       "12     0.859774  77248  13729  0.150906 -0.213102  0.036425  0.197250   \n",
       "13     0.140226   9490   5348  0.360426  0.940893  0.160825  0.197250   \n",
       "14     0.179247  17735   1232  0.064955 -1.152493  0.161218  0.399033   \n",
       "15     0.220044  20559   2725  0.117033 -0.506422  0.047696  0.399033   \n",
       "16     0.211511  18804   3577  0.159823 -0.145136  0.004251  0.399033   \n",
       "17     0.304550  24153   8073  0.250512  0.418525  0.060569  0.399033   \n",
       "18     0.084648   5487   3470  0.387406  1.056182  0.125300  0.399033   \n",
       "19     0.063431   6433    279  0.041567 -1.623576  0.096669  0.401817   \n",
       "20     0.126438  12342   1037  0.077510 -0.962267  0.084614  0.401817   \n",
       "21     0.364258  33382   5162  0.133925 -0.352284  0.040256  0.401817   \n",
       "22     0.275178  22707   6411  0.220173  0.249751  0.018549  0.401817   \n",
       "23     0.170694  11874   6188  0.342598  0.862669  0.161729  0.401817   \n",
       "24     0.263025  23409   4423  0.158918 -0.151894  0.005777  0.007708   \n",
       "25     0.736975  63329  14654  0.187913  0.050779  0.001931  0.007708   \n",
       "26     0.451930  39977   7844  0.164028 -0.114147  0.005675  0.010163   \n",
       "27     0.077494   6654   1546  0.188537  0.054861  0.000237  0.010163   \n",
       "28     0.470576  40107   9687  0.194542  0.093643  0.004251  0.010163   \n",
       "29     0.179247  17735   1232  0.064955 -1.152493  0.161218  0.378973   \n",
       "30     0.365052  33567   5061  0.131019 -0.377571  0.045950  0.378973   \n",
       "31     0.269829  22283   6269  0.219564  0.246201  0.017656  0.378973   \n",
       "32     0.185872  13153   6515  0.331249  0.811866  0.154149  0.378973   \n",
       "33     0.419647  38001   6404  0.144218 -0.266281  0.027273  0.044890   \n",
       "34     0.279932  23647   5974  0.201681  0.138589  0.005617  0.044890   \n",
       "35     0.300421  25090   6699  0.210733  0.193898  0.012001  0.044890   \n",
       "36     0.278911  25019   4494  0.152272 -0.202484  0.010706  0.024389   \n",
       "37     0.383944  33471   7156  0.176139 -0.028320  0.000305  0.024389   \n",
       "38     0.149431  12739   3073  0.194346  0.092395  0.001314  0.024389   \n",
       "39     0.187714  15509   4354  0.219202  0.244083  0.012065  0.024389   \n",
       "40     0.512933  45404   8872  0.163461 -0.118291  0.006908  0.018149   \n",
       "41     0.285829  24626   5619  0.185783  0.036760  0.000391  0.018149   \n",
       "42     0.145811  12163   3266  0.211679  0.199576  0.006182  0.018149   \n",
       "43     0.055427   4545   1320  0.225064  0.278013  0.004669  0.018149   \n",
       "44     0.431149  37020   8602  0.188549  0.054945  0.001325  0.003500   \n",
       "45     0.188943  16368   3625  0.181313  0.006935  0.000009  0.003500   \n",
       "46     0.215782  18847   3986  0.174572 -0.039157  0.000327  0.003500   \n",
       "47     0.164126  14503   2864  0.164910 -0.107728  0.001840  0.003500   \n",
       "\n",
       "                              breaks  is_special_values  \n",
       "0                          1%,%2%,%4              False  \n",
       "1                              6%,%3              False  \n",
       "2                             10%,%5              False  \n",
       "3                      7%,%8%,%0%,%9              False  \n",
       "4                            44000.0              False  \n",
       "5                            66000.0              False  \n",
       "6                            96000.0              False  \n",
       "7                                inf              False  \n",
       "8                                7.0              False  \n",
       "9                               11.0              False  \n",
       "10                              15.0              False  \n",
       "11                               inf              False  \n",
       "12                                36              False  \n",
       "13                                60              False  \n",
       "14            A1%,%A2%,%A3%,%A4%,%A5              False  \n",
       "15                      B1%,%B2%,%B3              False  \n",
       "16                      B4%,%B5%,%C1              False  \n",
       "17  C2%,%C3%,%C4%,%C5%,%D1%,%D2%,%D3              False  \n",
       "18  D4%,%D5%,%E1%,%E2%,%E3%,%E5%,%E4              False  \n",
       "19                               7.5              False  \n",
       "20                               9.5              False  \n",
       "21                              13.5              False  \n",
       "22                              16.5              False  \n",
       "23                               inf              False  \n",
       "24                       credit_card              False  \n",
       "25                debt_consolidation              False  \n",
       "26                          MORTGAGE              False  \n",
       "27                               OWN              False  \n",
       "28                              RENT              False  \n",
       "29                                 A              False  \n",
       "30                                 B              False  \n",
       "31                                 C              False  \n",
       "32                             D%,%E              False  \n",
       "33                      Not Verified              False  \n",
       "34                   Source Verified              False  \n",
       "35                          Verified              False  \n",
       "36                             260.0              False  \n",
       "37                             420.0              False  \n",
       "38                             520.0              False  \n",
       "39                               inf              False  \n",
       "40                               0.0              False  \n",
       "41                               1.0              False  \n",
       "42             5.0%,%2.0%,%4.0%,%6.0              False  \n",
       "43                   3.0%,%7.0%,%8.0              False  \n",
       "44                              21.0              False  \n",
       "45                              26.0              False  \n",
       "46                              34.0              False  \n",
       "47                               inf              False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bins)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 15:09:49,437 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-07-27 15:09:49,438 - INFO(validmind.vm_models.dataset): Inferring dataset types...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d60d8e04a94be1a43d34ef3825138f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p>Calculate the Weight of Evidence (WoE) and Information Value (IV) of features. T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.WOEIVTable import WOEIVTable\n",
    "\n",
    "# Update vm dataset and test context\n",
    "vm_df = vm.init_dataset(dataset=df_train_3, \n",
    "                              target_column=target_column)\n",
    "test_context_train_3 = TestContext(dataset=vm_df)\n",
    "\n",
    "# Run test\n",
    "metric = WOEIVTable(test_context_train_3)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "woe_iv_dic = metric.result.metric.value['woe_iv']\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Train Data II: Class Coarsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the original DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Feature': ['verification_status'] * 3 + ['total_acc_bucket'] * 6 + ['term'] * 2,\n",
    "    'Category': ['Not Verified', 'Source Verified', 'Verified', '[0.0, 9.0)', '[9.0, 18.0)', '[18.0, 27.0)', '[27.0, 36.0)', '[36.0, 45.0)', '[45.0, inf)', '36', '60'],\n",
    "    'WoE': [0.2663, -0.1386, -0.1939, -0.1030, -0.0516, -0.0150, 0.0524, 0.0898, 0.1414, 0.2131, -0.9409],\n",
    "    'IV': [0.0273, 0.0056, 0.0120, 0.0005, 0.0007, 0.0001, 0.0006, 0.0008, 0.0006, 0.0364, 0.1608]\n",
    "})\n",
    "\n",
    "def merge_bins(df, woe_diff=0.1):\n",
    "    while True:\n",
    "        # Group by 'Feature' and create a sorted list of unique WoE values\n",
    "        woe_diffs = df.groupby('Feature')['WoE'].apply(lambda x: sorted(x.unique())).apply(np.diff).reset_index()\n",
    "\n",
    "        # Calculate the minimum absolute WoE difference for each feature\n",
    "        woe_diffs['Min_WoE_Diff'] = woe_diffs['WoE'].apply(lambda x: np.min(np.abs(x)) if len(x) > 0 else np.inf)\n",
    "\n",
    "        # If the minimum WoE difference is >= woe_diff for all features, break the loop\n",
    "        if all(woe_diffs['Min_WoE_Diff'] >= woe_diff):\n",
    "            break\n",
    "\n",
    "        # Find the feature with the smallest WoE difference\n",
    "        feature = woe_diffs.loc[woe_diffs['Min_WoE_Diff'].idxmin(), 'Feature']\n",
    "\n",
    "        # Get the categories of the feature in the order of WoE values\n",
    "        categories = df.loc[df['Feature'] == feature, :].sort_values(by='WoE')['Category'].tolist()\n",
    "\n",
    "        # Find the pair of consecutive categories with the smallest WoE difference\n",
    "        pair = min(zip(categories, categories[1:]), key=lambda x: abs(df.loc[(df['Feature'] == feature) & (df['Category'] == x[0]), 'WoE'].values[0] - df.loc[(df['Feature'] == feature) & (df['Category'] == x[1]), 'WoE'].values[0]))\n",
    "\n",
    "        # Merge the pair of categories\n",
    "        df.loc[(df['Feature'] == feature) & (df['Category'].isin(pair)), 'Category'] = ', '.join(pair)\n",
    "\n",
    "        # Update the WoE value for the merged category to the average of the WoE values of the pair\n",
    "        df.loc[(df['Feature'] == feature) & (df['Category'] == ', '.join(pair)), 'WoE'] = df.loc[(df['Feature'] == feature) & (df['Category'].isin(pair)), 'WoE'].mean()\n",
    "\n",
    "    return df\n",
    "\n",
    "df_new = merge_bins(df)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bins(df, woe_diff=0.1):\n",
    "    df = df.sort_values(by='WoE').reset_index(drop=True)\n",
    "    merged = True\n",
    "    \n",
    "    while merged:\n",
    "        merged = False\n",
    "        df['WoE_Diff'] = df['WoE'].diff().abs()\n",
    "\n",
    "        for idx in range(df.shape[0] - 1):\n",
    "            if df.loc[idx, 'WoE_Diff'] < woe_diff:\n",
    "                merged = True\n",
    "                df.at[idx, 'All'] += df.at[idx + 1, 'All']\n",
    "                df.at[idx, 'Good'] += df.at[idx + 1, 'Good']\n",
    "                df.at[idx, 'Bad'] += df.at[idx + 1, 'Bad']\n",
    "                df.at[idx, 'Distr_Good'] += df.at[idx + 1, 'Distr_Good']\n",
    "                df.at[idx, 'Distr_Bad'] += df.at[idx + 1, 'Distr_Bad']\n",
    "                df.at[idx, 'WoE'] = np.log(df.at[idx, 'Distr_Good'] / df.at[idx, 'Distr_Bad'])\n",
    "                df.at[idx, 'IV'] = (df.at[idx, 'Distr_Good'] - df.at[idx, 'Distr_Bad']) * df.at[idx, 'WoE']\n",
    "                df = df.drop(idx + 1).reset_index(drop=True)\n",
    "                break\n",
    "\n",
    "    df = df.drop(columns='WoE_Diff')\n",
    "    df = df.sort_values(by='Feature').reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "woe_iv_df = pd.DataFrame(woe_iv_dic)\n",
    "woe_iv_df_coarsed = merge_bins(woe_iv_df)\n",
    "woe_iv_df_coarsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_iv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_mappings = {\n",
    "    'sub_grade': [['B2','B3','B4','B5','C3','D1'], \n",
    "                  ['C1','C2','C4','C5'], \n",
    "                  ['D3','D4','D5','E3','G4'], \n",
    "                  ['E1','E2','E4','E5','F1','F2','F3','F4','G1','G2','G3','G5','F5']],\n",
    "    'grade': [['F','G']],\n",
    "    'purpose': [['wedding','major_purchase'], \n",
    "                ['credit_card','car'], \n",
    "                ['debt_consolidation','other','vacation'], \n",
    "                ['medical','moving','house','educational'], \n",
    "                ['renewable_energy','small_business']],\n",
    "    'home_ownership': [['MORTGAGE','OWN','RENT']],\n",
    "    'annual_inc_bucket': [['[250, 1000)','[100, 150)','[150, 250)','[1000, 10000)'],\n",
    "                           ['[50, 75)','[40, 50)'],\n",
    "                           ['[10, 20)','[0, 10)']],\n",
    "    'emp_length_bucket': [['[2, 3)','[40, 50)','[3, 5)','[1, 2)','[0, 1)','[5, 8)','[8, 10)']],\n",
    "    'inq_last_6mths_bucket': [['[4, 5)','[1, 2)'],\n",
    "                              ['[5, 10)','[3, 4)']],\n",
    "    'installment_bucket': [['[300, 400)','[200, 300)','[0, 100)'],\n",
    "                           ['[400, 500)', '[500, 750)']],\n",
    "    'total_acc_bucket': [['[20, 25)','[30, 35)','[15, 20)','[45, 50)','[40, 45)','[35, 40)','[10, 15)','[5, 10)']],\n",
    "    'open_acc_bucket': [['[5, 8)','[8, 10)','[10, 100)','[4, 5)'], ['[1, 2)','[2, 3)']]\n",
    "}\n",
    "\n",
    "df_train_3 = class_coarsing(df_train_2, coarse_mappings)\n",
    "\n",
    "# Update df_test\n",
    "df_test_3 = class_coarsing(df_test_2, coarse_mappings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Train Data 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.data_validation.WOEIVPlots import WOEIVPlots\n",
    "\n",
    "# Update vm dataset and test context\n",
    "vm_df_train_3 = vm.init_dataset(dataset=df_train_3, \n",
    "                              target_column=target_column)\n",
    "test_context_train_3 = TestContext(dataset=vm_df_train_3)\n",
    "\n",
    "params = {\n",
    "    \"features\": None,\n",
    "    \"fig_height\": 500,\n",
    "    \"fig_height\": 500,\n",
    "}\n",
    "\n",
    "# Run test\n",
    "metric = WOEIVPlots(test_context_train_3, params=params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Train Data III: Feature Encoding with WoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Compute WoE and IV \n",
    "metric = WOEIVTable(test_context_train_3, params=params)\n",
    "metric.run()\n",
    "woe_iv_dic = metric.result.metric.value['woe_iv']\n",
    "woe_iv_df = pd.DataFrame(woe_iv_dic)\n",
    "check_categories(woe_iv_df, df_train_3)\n",
    "\n",
    "# Encode features with WoE\n",
    "df_train_4 = woe_encoder(woe_iv_df, df_train_3, target='default')\n",
    "\n",
    "# Update df_test\n",
    "df_test_4 = woe_encoder(woe_iv_df, df_test_3, target='default')\n",
    "\n",
    "# Add constant to X_train for intercept term\n",
    "y_train = df_train_4[target_column]\n",
    "X_train = df_train_4.drop(target_column, axis=1)\n",
    "X_train = sm.add_constant(X_train)\n",
    "df_train_4 = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Update df_test\n",
    "y_test = df_test_4[target_column]\n",
    "X_test = df_test_4.drop(target_column, axis=1)\n",
    "X_test = sm.add_constant(X_test)\n",
    "df_test_4 = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "model_fit_glm = model.fit()\n",
    "\n",
    "# Print out the statistics\n",
    "print(model_fit_glm.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Train Data 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['total_acc_bucket_coarse']\n",
    "df_train_5 = df_train_4.drop(columns = features_to_drop, axis=1)\n",
    "\n",
    "# Update df_test \n",
    "df_test_5 = df_test_4.drop(columns = features_to_drop, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_train and y_train\n",
    "y_train = df_train_5[target_column]\n",
    "X_train = df_train_5.drop(target_column, axis=1)\n",
    "\n",
    "# Update df_test\n",
    "y_test = df_test_5[target_column]\n",
    "X_test = df_test_5.drop(target_column, axis=1)\n",
    "\n",
    "# Define the model\n",
    "model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "model_fit_glm = model.fit()\n",
    "\n",
    "# Save the model and train dataset for PD development \n",
    "save_data = False\n",
    "if save_data:\n",
    "    save_model_and_df(model_fit_glm, df=df_train_5, base_filename='model_fit_glm_scorecard')\n",
    "\n",
    "# Print out the statistics\n",
    "print(model_fit_glm.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Model Fit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VM dataset\n",
    "vm_ds_train_5 = vm.init_dataset(dataset=df_train_5,\n",
    "                        target_column=target_column)\n",
    "vm_ds_test_5 = vm.init_dataset(dataset=df_test_5,\n",
    "                        target_column=target_column)\n",
    "\n",
    "# Create VM model\n",
    "vm_model_glm = vm.init_model(\n",
    "    model = model_fit_glm, \n",
    "    train_ds=vm_ds_train_5, \n",
    "    test_ds=vm_ds_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.model_validation.statsmodels.RegressionCoeffsPlot import RegressionCoeffsPlot\n",
    "\n",
    "test_context_model = TestContext(models = [vm_model_glm])\n",
    "\n",
    "metric = RegressionCoeffsPlot(test_context_model)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.model_validation.statsmodels.RegressionModelsCoeffs import RegressionModelsCoeffs\n",
    "\n",
    "metric = RegressionModelsCoeffs(test_context_model)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.model_validation.statsmodels.LogRegressionConfusionMatrix import LogRegressionConfusionMatrix\n",
    "\n",
    "test_context_model = TestContext(model= vm_model_glm)\n",
    "\n",
    "# Configure test parameters\n",
    "params = {\n",
    "    \"cut_off_threshold\": 0.5,\n",
    "}\n",
    "\n",
    "metric = LogRegressionConfusionMatrix(test_context_model, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.model_validation.statsmodels.RegressionROCCurve import RegressionROCCurve\n",
    "\n",
    "metric = RegressionROCCurve(test_context_model)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.model_validation.statsmodels.GINITable import GINITable\n",
    "\n",
    "metric = GINITable(test_context_model)\n",
    "metric.run()\n",
    "await metric.result.log() \n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.model_validation.statsmodels.LogisticRegPredictionHistogram import LogisticRegPredictionHistogram\n",
    "\n",
    "# Configure test parameters\n",
    "params = {\n",
    "    \"title\": \"Histogram of Probability of Default\",\n",
    "}\n",
    "\n",
    "metric = LogisticRegPredictionHistogram(test_context_model, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.model_validation.statsmodels.LogisticRegCumulativeProb import LogisticRegCumulativeProb\n",
    "\n",
    "# Configure test parameters\n",
    "params = {\n",
    "    \"title\": \"Cumulative Probability of Default\",\n",
    "}\n",
    "\n",
    "metric = LogisticRegCumulativeProb(test_context_model, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests.model_validation.statsmodels.ScorecardHistogram import ScorecardHistogram\n",
    "\n",
    "# Configure test parameters\n",
    "params = {\n",
    "    \"target_score\": 600,\n",
    "    \"target_odds\": 50,\n",
    "    \"pdo\": 20,\n",
    "    \"title\": \"Histogram of Credit Scores\",\n",
    "}\n",
    "\n",
    "metric = ScorecardHistogram(test_context_model, params)\n",
    "metric.run()\n",
    "await metric.result.log()\n",
    "metric.result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-framework",
   "language": "python",
   "name": "dev-framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

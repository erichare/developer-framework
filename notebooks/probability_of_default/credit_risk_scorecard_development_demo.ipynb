{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Scorecard Model Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Credit risk Scorecard** model created from the Lending Club dataset is instrumental in computing the Probability of Default (PD), a key factor in ECL calculations. This scorecard assesses several credit characteristics of potential borrowers, like their credit history, income, outstanding debts, and more, each of which is assigned a specific score. By combining these scores, we derive a total score for each borrower, which translates into an estimated Point-in-Time (PiT) PD. The PiT PD reflects the borrower's likelihood of default at a specific point in time, accounting for both current and foreseeable future conditions.\n",
    "\n",
    "Additionally, for a holistic view of credit risk, it's essential to estimate the Lifetime PD. The Lifetime PD, as the name suggests, predicts the borrower's likelihood of default throughout the life of the exposure, taking into account potential future changes in the economic and financial conditions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 14:32:02,428 - INFO(validmind.api_client): Connected to ValidMind. Project: [6] Credit Risk Scorecard - Initial Validation (clk00h0u800x9qjy67gduf5om)\n",
      "INFO: Connected to ValidMind. Project: [6] Credit Risk Scorecard - Initial Validation (clk00h0u800x9qjy67gduf5om)\n"
     ]
    }
   ],
   "source": [
    "from notebooks.probability_of_default.helpers.Developer import Developer\n",
    "from notebooks.probability_of_default.helpers.scorecard_tasks import *\n",
    "from notebooks.probability_of_default.helpers.model_development_tasks import *\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
    "  api_key = \"2494c3838f48efe590d531bfe225d90b\",\n",
    "  api_secret = \"4f692f8161f128414fef542cab2a4e74834c75d01b3a8e088a1834f2afcfe838\",\n",
    "  project = \"clk00h0u800x9qjy67gduf5om\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_column = \"default\"\n",
    "\n",
    "lending_club_url = \"https://vmai.s3.us-west-1.amazonaws.com/datasets/lending_club_loan_data_2007_2014.csv\"\n",
    "\n",
    "preliminary_features_to_drop = [\n",
    "    \"id\", \"member_id\", \"funded_amnt\", \"emp_title\", \"url\", \"desc\", \"application_type\",\n",
    "    \"title\", \"zip_code\", \"delinq_2yrs\", \"mths_since_last_delinq\", \"mths_since_last_record\",\n",
    "    \"revol_bal\", \"total_rec_prncp\", \"total_rec_late_fee\", \"recoveries\", \"out_prncp_inv\", \"out_prncp\", \n",
    "    \"collection_recovery_fee\", \"next_pymnt_d\", \"initial_list_status\", \"pub_rec\",\n",
    "    \"collections_12_mths_ex_med\", \"policy_code\", \"acc_now_delinq\", \"pymnt_plan\",\n",
    "    \"tot_coll_amt\", \"tot_cur_bal\", \"total_rev_hi_lim\", \"last_pymnt_d\", \"last_credit_pull_d\",\n",
    "    'earliest_cr_line', 'issue_d']\n",
    "\n",
    "final_features_to_drop = ['addr_state', 'total_rec_int', 'loan_amnt',\n",
    "                    'funded_amnt_inv', 'dti', 'revol_util', 'total_pymnt', \n",
    "                    'total_pymnt_inv', 'last_pymnt_amnt', \"inq_last_6mths\"]\n",
    "\n",
    "min_missing_percentage = 80\n",
    "\n",
    "iqr_threshold = 1.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Developer Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'remove_iqr_outliers'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the Developer class\n",
    "developer = Developer()\n",
    "\n",
    "# Register developer tasks\n",
    "developer.add_task(\n",
    "    task_id=\"import_raw_data\", \n",
    "    task=import_raw_data,\n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"drop_features\",\n",
    "    task=drop_features,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"add_default_definition\",\n",
    "    task=add_default_definition,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"convert_term_column\",\n",
    "    task=convert_term_column,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"convert_emp_length_column\",\n",
    "    task=convert_emp_length_column,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"convert_inq_last_6mths_column\",\n",
    "    task=convert_inq_last_6mths_column,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"data_split\",\n",
    "    task=data_split,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"drop_categories\",\n",
    "    task=drop_categories,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"convert_to_woe\",\n",
    "    task=convert_to_woe,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"add_constant\",\n",
    "    task=add_constant,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"train_model\",\n",
    "    task=train_model,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"remove_features_missing_values\",\n",
    "    task=remove_features_missing_values,  \n",
    ")\n",
    "\n",
    "developer.add_task(\n",
    "    task_id=\"remove_iqr_outliers\",\n",
    "    task=remove_iqr_outliers,  \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'import_raw_data'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing raw data from: https://vmai.s3.us-west-1.amazonaws.com/datasets/lending_club_loan_data_2007_2014.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanvalidmind/Dev/github/validmind-python/notebooks/probability_of_default/helpers/model_development_tasks.py:11: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_out = pd.read_csv(source)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported successfully with 466285 rows and 75 columns.\n"
     ]
    }
   ],
   "source": [
    "df_raw = developer.execute_task(\n",
    "    area_id = \"data_description\",\n",
    "    task_id = \"import_raw_data\", \n",
    "    inputs = [lending_club_url],\n",
    "    validation_tests = [\n",
    "        \"descriptive_statistics\", \n",
    "        \"missing_values_bar_plot\",\n",
    "        \"iqr_outliers_table\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'drop_features'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 33 columns.\n",
      "Columns remaining after dropping: 42\n"
     ]
    }
   ],
   "source": [
    "df_preparation = developer.execute_task(\n",
    "    area_id = \"data_preparation\",\n",
    "    task_id = \"drop_features\", \n",
    "    inputs = [df_raw, preliminary_features_to_drop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'add_default_definition'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 'loan_status' to target column...\n",
      "Removed 239071 rows with undefined 'loan_status' values.\n",
      "Converted 'loan_status' to 'default' and set its data type to integer.\n",
      "'loan_status' column has been removed from the DataFrame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanvalidmind/Dev/github/validmind-python/notebooks/probability_of_default/helpers/scorecard_tasks.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[default_column] = df[default_column].astype(int)\n",
      "/Users/juanvalidmind/Dev/github/validmind-python/notebooks/probability_of_default/helpers/scorecard_tasks.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=[\"loan_status\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_preparation = developer.execute_task(\n",
    "    area_id = \"data_preparation\",\n",
    "    task_id = \"add_default_definition\", \n",
    "    inputs = [df_preparation, default_column]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'remove_features_missing_values'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing missing values in the dataset...\n",
      "Found 18 features with more than 80% missing values.\n",
      "Dropping the following columns: mths_since_last_major_derog, annual_inc_joint, dti_joint, verification_status_joint, open_acc_6m, open_il_6m, open_il_12m, open_il_24m, mths_since_rcnt_il, total_bal_il, il_util, open_rv_12m, open_rv_24m, max_bal_bc, all_util, inq_fi, total_cu_tl, inq_last_12m\n"
     ]
    }
   ],
   "source": [
    "df_preparation = developer.execute_task(\n",
    "    area_id=\"data_preparation\",\n",
    "    task_id=\"remove_features_missing_values\", \n",
    "    inputs=[df_preparation, min_missing_percentage]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'convert_term_column'...\n",
      "\n",
      "INFO: Executing task 'convert_emp_length_column'...\n",
      "\n",
      "INFO: Executing task 'convert_inq_last_6mths_column'...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_preparation = developer.execute_task(\n",
    "    area_id=\"data_preparation\",\n",
    "    task_id=\"convert_term_column\", \n",
    "    inputs=[df_preparation]\n",
    ")\n",
    "\n",
    "df_preparation = developer.execute_task(\n",
    "    area_id=\"data_preparation\",\n",
    "    task_id=\"convert_emp_length_column\", \n",
    "    inputs=[df_preparation]\n",
    ")\n",
    "\n",
    "df_preparation = developer.execute_task(\n",
    "    area_id=\"data_preparation\",\n",
    "    task_id=\"convert_inq_last_6mths_column\", \n",
    "    inputs=[df_preparation]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'remove_iqr_outliers'...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_preparation = developer.execute_task(\n",
    "    area_id=\"data_preparation\",\n",
    "    task_id=\"remove_iqr_outliers\", \n",
    "    inputs=[df_preparation, default_column, iqr_threshold],\n",
    "    validation_tests=[\n",
    "        \"class_imbalance\",\n",
    "        \"missing_values_bar_plot\",\n",
    "        \"iqr_outliers_bar_plot\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'data_split'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 143111 rows and 23 columns.\n",
      "Test data has 35778 rows and 23 columns.\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = developer.execute_task(\n",
    "    area_id=\"data_sampling\",\n",
    "    task_id=\"data_split\", \n",
    "    inputs=[df_preparation, default_column],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'drop_categories'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows retained with purpose 'debt_consolidation' or 'credit_card': 111115\n",
      "Rows after removing grades 'F' or 'G': 109833\n",
      "Rows after removing sub_grades starting with 'F' or 'G': 109833\n",
      "Rows after removing home_ownership values 'OTHER', 'NONE', or 'ANY': 109746\n",
      "Total rows dropped: 33365\n",
      "Rows retained with purpose 'debt_consolidation' or 'credit_card': 27847\n",
      "Rows after removing grades 'F' or 'G': 27543\n",
      "Rows after removing sub_grades starting with 'F' or 'G': 27543\n",
      "Rows after removing home_ownership values 'OTHER', 'NONE', or 'ANY': 27523\n",
      "Total rows dropped: 8255\n"
     ]
    }
   ],
   "source": [
    "df_train = developer.execute_task(\n",
    "    area_id=\"exploratory_data_analysis\",\n",
    "    task_id=\"drop_categories\", \n",
    "    inputs=[df_train],\n",
    "  \n",
    ")\n",
    "\n",
    "df_test = drop_categories(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'drop_features'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 10 columns.\n",
      "Columns remaining after dropping: 14\n",
      "Dropped 10 columns.\n",
      "Columns remaining after dropping: 14\n"
     ]
    }
   ],
   "source": [
    "df_train_eda = developer.execute_task(\n",
    "    area_id=\"exploratory_data_analysis\",\n",
    "    task_id=\"drop_features\", \n",
    "    inputs=[df_train, final_features_to_drop],\n",
    "    validation_tests=[\n",
    "        \"high_cardinality\",\n",
    "        \"tabular_numerical_histograms\", \n",
    "        \"tabular_categorical_bar_plots\",\n",
    "        \"target_rate_bar_plots\",\n",
    "        \"chi_squared_features_table\", \n",
    "        \"anova_one_way_table\", \n",
    "        \"pearson_correlation_matrix\", \n",
    "        \"feature_target_correlation_plot\",\n",
    "        \"woe_bin_table\",\n",
    "        \"woe_bin_table\",   # with different parameters\n",
    "        \"woe_bin_plots\"]\n",
    ")\n",
    "\n",
    "df_test_eda = drop_features(df_test, final_features_to_drop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 14:32:57,983 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "INFO: Pandas dataset detected. Initializing VM Dataset instance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with breaks_adj: {'int_rate': [5, 10, 15]}\n",
      "Performing binning with breaks_adj: {'int_rate': [5, 10, 15]}\n",
      "[INFO] creating woe binning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanvalidmind/Library/Caches/pypoetry/virtualenvs/validmind-X_uvMH0R-py3.10/lib/python3.10/site-packages/scorecardpy/condition_fun.py:79: UserWarning: There are blank strings in 1 columns, which are replaced with NaN. \n",
      " (ColumnNames: emp_length)\n",
      "  warnings.warn('There are blank strings in {} columns, which are replaced with NaN. \\n (ColumnNames: {})'.format(\n"
     ]
    }
   ],
   "source": [
    "from validmind.vm_models.test_context import TestContext\n",
    "from validmind.tests.data_validation.WOEBinTable import WOEBinTable\n",
    "\n",
    "params = {\n",
    "    \"breaks_adj\": {\n",
    "        \"int_rate\": [5,10,15]}  \n",
    "     }\n",
    "\n",
    "vm_df = vm.init_dataset(dataset=df_train_eda, target_column=default_column)\n",
    "test_context = TestContext(dataset=vm_df)\n",
    "\n",
    "metric = WOEBinTable(test_context, params=params)\n",
    "metric.run()\n",
    "woe_dic = metric.result.metric.value['woe_iv']\n",
    "woe_df = pd.DataFrame(woe_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'convert_to_woe'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 13 features to WoE values.\n",
      "[INFO] converting into woe values ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanvalidmind/Library/Caches/pypoetry/virtualenvs/validmind-X_uvMH0R-py3.10/lib/python3.10/site-packages/scorecardpy/condition_fun.py:79: UserWarning: There are blank strings in 1 columns, which are replaced with NaN. \n",
      " (ColumnNames: emp_length)\n",
      "  warnings.warn('There are blank strings in {} columns, which are replaced with NaN. \\n (ColumnNames: {})'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted features to WoE values.\n",
      "Converting 13 features to WoE values.\n",
      "[INFO] converting into woe values ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanvalidmind/Library/Caches/pypoetry/virtualenvs/validmind-X_uvMH0R-py3.10/lib/python3.10/site-packages/scorecardpy/condition_fun.py:79: UserWarning: There are blank strings in 1 columns, which are replaced with NaN. \n",
      " (ColumnNames: emp_length)\n",
      "  warnings.warn('There are blank strings in {} columns, which are replaced with NaN. \\n (ColumnNames: {})'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted features to WoE values.\n"
     ]
    }
   ],
   "source": [
    "df_train_feateng = developer.execute_task(\n",
    "    area_id=\"feature_engineering\",\n",
    "    task_id=\"convert_to_woe\", \n",
    "    inputs=[df_train_eda, woe_df, default_column],\n",
    ")     \n",
    "\n",
    "df_test_feateng = convert_to_woe(df_test_eda, woe_df, default_column)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'add_constant'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added constant to dataframe. Number of columns went from 14 to 15.\n",
      "Added constant to dataframe. Number of columns went from 14 to 15.\n"
     ]
    }
   ],
   "source": [
    "df_train_feateng = developer.execute_task(\n",
    "    area_id=\"model_training\",\n",
    "    task_id=\"add_constant\", \n",
    "    inputs=[df_train_feateng]\n",
    ")\n",
    "\n",
    "df_test_feateng = add_constant(df_test_feateng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'train_model'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with 14 features and 109746 data points.\n",
      "Model trained successfully.\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:               109746\n",
      "Model:                            GLM   Df Residuals:                   109732\n",
      "Model Family:                Binomial   Df Model:                           13\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -47702.\n",
      "Date:                Mon, 14 Aug 2023   Deviance:                       95403.\n",
      "Time:                        14:33:08   Pearson chi2:                 1.10e+05\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.08209\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -1.4890      0.008   -178.123      0.000      -1.505      -1.473\n",
      "annual_inc_woe              1.1437      0.039     29.498      0.000       1.068       1.220\n",
      "verification_status_woe     0.2253      0.040      5.685      0.000       0.148       0.303\n",
      "Unnamed: 0_woe              0.5165      0.042     12.322      0.000       0.434       0.599\n",
      "total_acc_woe               1.1095      0.180      6.168      0.000       0.757       1.462\n",
      "installment_woe             1.4682      0.059     24.993      0.000       1.353       1.583\n",
      "term_woe                    0.6310      0.019     33.000      0.000       0.594       0.668\n",
      "sub_grade_woe               0.3757      0.035     10.749      0.000       0.307       0.444\n",
      "purpose_woe                 0.2176      0.099      2.199      0.028       0.024       0.412\n",
      "home_ownership_woe          0.6938      0.089      7.832      0.000       0.520       0.867\n",
      "int_rate_woe                0.1838      0.030      6.185      0.000       0.126       0.242\n",
      "open_acc_woe                1.7494      0.166     10.518      0.000       1.423       2.075\n",
      "grade_woe                   0.2405      0.036      6.627      0.000       0.169       0.312\n",
      "emp_length_woe              0.8153      0.068     11.971      0.000       0.682       0.949\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model_fit_candidate = developer.execute_task(\n",
    "    area_id=\"model_training\",\n",
    "    task_id=\"train_model\", \n",
    "    inputs=[df_train_feateng, default_column]\n",
    ")\n",
    "\n",
    "print(model_fit_candidate.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'drop_features'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 columns.\n",
      "Columns remaining after dropping: 15\n",
      "Dropped 0 columns.\n",
      "Columns remaining after dropping: 15\n"
     ]
    }
   ],
   "source": [
    "model_features_to_drop = []\n",
    "\n",
    "df_train_feateng = developer.execute_task(\n",
    "    area_id=\"model_training\",\n",
    "    task_id=\"drop_features\", \n",
    "    inputs=[df_train_feateng, model_features_to_drop]\n",
    ")\n",
    "\n",
    "df_test_feateng = drop_features(df_test_feateng, model_features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing task 'train_model'...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with 14 features and 109746 data points.\n",
      "Model trained successfully.\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:               109746\n",
      "Model:                            GLM   Df Residuals:                   109732\n",
      "Model Family:                Binomial   Df Model:                           13\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -47702.\n",
      "Date:                Mon, 14 Aug 2023   Deviance:                       95403.\n",
      "Time:                        14:33:08   Pearson chi2:                 1.10e+05\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.08209\n",
      "Covariance Type:            nonrobust                                         \n",
      "===========================================================================================\n",
      "                              coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------\n",
      "const                      -1.4890      0.008   -178.123      0.000      -1.505      -1.473\n",
      "annual_inc_woe              1.1437      0.039     29.498      0.000       1.068       1.220\n",
      "verification_status_woe     0.2253      0.040      5.685      0.000       0.148       0.303\n",
      "Unnamed: 0_woe              0.5165      0.042     12.322      0.000       0.434       0.599\n",
      "total_acc_woe               1.1095      0.180      6.168      0.000       0.757       1.462\n",
      "installment_woe             1.4682      0.059     24.993      0.000       1.353       1.583\n",
      "term_woe                    0.6310      0.019     33.000      0.000       0.594       0.668\n",
      "sub_grade_woe               0.3757      0.035     10.749      0.000       0.307       0.444\n",
      "purpose_woe                 0.2176      0.099      2.199      0.028       0.024       0.412\n",
      "home_ownership_woe          0.6938      0.089      7.832      0.000       0.520       0.867\n",
      "int_rate_woe                0.1838      0.030      6.185      0.000       0.126       0.242\n",
      "open_acc_woe                1.7494      0.166     10.518      0.000       1.423       2.075\n",
      "grade_woe                   0.2405      0.036      6.627      0.000       0.169       0.312\n",
      "emp_length_woe              0.8153      0.068     11.971      0.000       0.682       0.949\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model_fit_final = developer.execute_task(\n",
    "    area_id=\"model_training\",\n",
    "    task_id=\"train_model\", \n",
    "    inputs=[df_train_feateng, default_column],\n",
    "    validation_tests = [\"regression_coeffs_plot\", \n",
    "                        \"regression_models_coeffs\", \n",
    "                        \"log_regression_confusion_matrix\", \n",
    "                        \"regression_roc_curve\", \"gini_table\", \n",
    "                        \"logistic_reg_prediction_histogram\", \n",
    "                        \"logistic_reg_cumulative_prob\", \n",
    "                        \"scorecard_histogram\"]\n",
    ")\n",
    "\n",
    "print(model_fit_final.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area ID</th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "      <th>Validation Tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_description</td>\n",
       "      <td>import_raw_data</td>\n",
       "      <td>lending_club_url</td>\n",
       "      <td>df_raw</td>\n",
       "      <td>descriptive_statistics<br>missing_values_bar_plot<br>iqr_outliers_table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_preparation</td>\n",
       "      <td>drop_features</td>\n",
       "      <td>df_raw, preliminary_features_to_drop</td>\n",
       "      <td>df_preparation</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_preparation</td>\n",
       "      <td>add_default_definition</td>\n",
       "      <td>df_preparation, default_column</td>\n",
       "      <td>df_preparation</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_preparation</td>\n",
       "      <td>remove_features_missing_values</td>\n",
       "      <td>df_preparation, min_missing_percentage</td>\n",
       "      <td>df_preparation</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_preparation</td>\n",
       "      <td>convert_term_column</td>\n",
       "      <td>df_preparation</td>\n",
       "      <td>df_preparation</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data_preparation</td>\n",
       "      <td>convert_emp_length_column</td>\n",
       "      <td>df_preparation</td>\n",
       "      <td>df_preparation</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data_preparation</td>\n",
       "      <td>convert_inq_last_6mths_column</td>\n",
       "      <td>df_preparation</td>\n",
       "      <td>df_preparation</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data_preparation</td>\n",
       "      <td>remove_iqr_outliers</td>\n",
       "      <td>df_preparation, default_column, iqr_threshold</td>\n",
       "      <td>df_preparation</td>\n",
       "      <td>class_imbalance<br>missing_values_bar_plot<br>iqr_outliers_bar_plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data_sampling</td>\n",
       "      <td>data_split</td>\n",
       "      <td>df_preparation, default_column</td>\n",
       "      <td>df_train,df_test</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>exploratory_data_analysis</td>\n",
       "      <td>drop_categories</td>\n",
       "      <td>df_train</td>\n",
       "      <td>df_train</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>exploratory_data_analysis</td>\n",
       "      <td>drop_features</td>\n",
       "      <td>df_train, final_features_to_drop</td>\n",
       "      <td>df_train_eda</td>\n",
       "      <td>high_cardinality<br>tabular_numerical_histograms<br>tabular_categorical_bar_plots<br>target_rate_bar_plots<br>chi_squared_features_table<br>anova_one_way_table<br>pearson_correlation_matrix<br>feature_target_correlation_plot<br>woe_bin_table<br>woe_bin_table<br>woe_bin_plots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>feature_engineering</td>\n",
       "      <td>convert_to_woe</td>\n",
       "      <td>df_train_eda, woe_df, default_column</td>\n",
       "      <td>df_train_feateng</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model_training</td>\n",
       "      <td>add_constant</td>\n",
       "      <td>df_train_feateng</td>\n",
       "      <td>df_train_feateng</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model_training</td>\n",
       "      <td>train_model</td>\n",
       "      <td>df_train_feateng, default_column</td>\n",
       "      <td>model_fit_candidate</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>model_training</td>\n",
       "      <td>drop_features</td>\n",
       "      <td>df_train_feateng, model_features_to_drop</td>\n",
       "      <td>df_train_feateng</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>model_training</td>\n",
       "      <td>train_model</td>\n",
       "      <td>df_train_feateng, default_column</td>\n",
       "      <td>model_fit_final</td>\n",
       "      <td>regression_coeffs_plot<br>regression_models_coeffs<br>log_regression_confusion_matrix<br>regression_roc_curve<br>gini_table<br>logistic_reg_prediction_histogram<br>logistic_reg_cumulative_prob<br>scorecard_histogram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_validation = developer.show_validation_plan()\n",
    "display(HTML(df_validation.to_html(escape=False)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Datasets and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Saved 7 objects to datasets/scorecard_data_and_models.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['df_raw',\n",
       " 'df_preparation',\n",
       " 'df_train_eda',\n",
       " 'df_train_feateng',\n",
       " 'df_test_feateng',\n",
       " 'model_fit_final',\n",
       " 'df_validation']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_to_store = {\n",
    "    \"df_raw\": df_raw,\n",
    "    \"df_preparation\": df_preparation,\n",
    "    \"df_train_eda\": df_train_eda,\n",
    "    \"df_train_feateng\": df_train_feateng,\n",
    "    \"df_test_feateng\": df_test_feateng,\n",
    "    \"model_fit_final\": model_fit_final,\n",
    "    \"df_validation\": df_validation,\n",
    "}\n",
    "\n",
    "developer.save_objects_to_pickle(\n",
    "    filename=\"datasets/scorecard_data_and_models.pkl\", \n",
    "    objects_to_save=objects_to_store)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-framework",
   "language": "python",
   "name": "dev-framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ValidMind Introduction for Model Developers\n",
    "\n",
    "This interactive notebook guides you through the process of documenting a model with the ValidMind Developer Framework. It uses a binary classification model as an example, but the same principles apply to other model types.\n",
    "\n",
    "As part of the notebook, you will learn how to start documenting a model as a **Model Developer** persona. At this stage the assumption is that there has been a [Model Documentation template](https://docs.validmind.com/guide/swap-documentation-templates.html#view-current-templates) defined in the platform.\n",
    "\n",
    "## Overview of the Notebook\n",
    "\n",
    "1. Initializing the ValidMind Developer Framework:\n",
    "\n",
    "   ValidMind’s developer framework provides a rich collection of documentation tools and test suites, from documenting descriptions of your dataset to validation testing your models for weak spots and overfit areas.\n",
    "\n",
    "2. Start the model development process with raw data and run out-of-the box tests and add evidence to model documentation\n",
    "\n",
    "   In this stage the notebook will provide you details on how to access ValidMind's test repository to individual tests that you will use as building blocks to ensure a model is being built appropriately. The goal is to show how to run tests, investigate results and add tests / evidence to the documentation.\n",
    "\n",
    "   For a full list of out-of-box tests please refer to: https://docs.validmind.com/guide/test-descriptions.html\n",
    "\n",
    "3. Next we are going to build upon the previous step, but the focus here is implementation of Custom Tests\n",
    "\n",
    "   In this stage the notebook will provide details on how to implement custom tests. Usually, model developers have a lot of their own custom tests and it is important to include this within the model documentation. We will show how you how to include custom tests and then how they can be implemented within the documentation as additional evidence.\n",
    "\n",
    "4. The final part of the notebook will show you how to ensure completion of documentation\n",
    "\n",
    "   In this stage the notebook will provide details on how to ensure that model documentation and associated sections in the model documentation have been built out, and if there are any changes to testing due to additional data processing or data analysis requirements. The notebook will show how to update results for existing tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ValidMind at a glance\n",
    "\n",
    "ValidMind's platform enables organizations to identify, document, and manage model risks for all types of models, including AI/ML models, LLMs, and statistical models. As a model developer, you use the ValidMind Developer Framework to automate documentation and validation tests, and then use the ValidMind AI Risk Platform UI to collaborate on model documentation. Together, these products simplify model risk management, facilitate compliance with regulations and institutional standards, and enhance collaboration between yourself and model validators.\n",
    "\n",
    "If this is your first time trying out ValidMind, you can make use of the following resources alongside this notebook:\n",
    "\n",
    "- [Get started](https://docs.validmind.ai/guide/get-started.html) — The basics, including key concepts, and how our products work\n",
    "- [Get started with the ValidMind Developer Framework](https://docs.validmind.ai/guide/get-started-developer-framework.html) — The path for developers, more code samples, and our developer reference\n",
    "\n",
    "It is important to note that in order to connect to the Developer Framework you will have to access this through our API's using Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "::: {.callout-tip}\n",
    "\n",
    "### New to ValidMind?\n",
    "\n",
    "For access to all features available in this notebook, create a free ValidMind account.\n",
    "\n",
    "Signing up is FREE — [**Sign up now**](https://app.prod.validmind.ai)\n",
    ":::\n",
    "\n",
    "If you encounter errors due to missing modules in your Python environment, install the modules with `pip install`, and then re-run the notebook. For more help, refer to [Installing Python Modules](https://docs.python.org/3/installing/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initializing the ValidMind Developer Framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the client library\n",
    "\n",
    "Please note the following recommended Python versions to utilize:\n",
    "\n",
    "- Python version 3.7 > x <= 3.11\n",
    "\n",
    "The client library provides Python support for the ValidMind Developer Framework. To install it run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Users/andres/code/validmind-sdk/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register a new model in ValidMind UI and initialize the client library\n",
    "\n",
    "ValidMind generates a unique _code snippet_ for each registered model to connect with your developer environment. You initialize the client library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.\n",
    "\n",
    "Get your code snippet:\n",
    "\n",
    "1. In a browser, log into the [Platform UI](https://app.prod.validmind.ai).\n",
    "\n",
    "2. In the left sidebar, navigate to **Model Inventory** and click **+ Register new model**.\n",
    "\n",
    "3. Enter the model details and click **Continue**. ([Need more help?](https://docs.validmind.ai/guide/register-models-in-model-inventory.html))\n",
    "\n",
    "   For example, to register a model for use with this notebook, select:\n",
    "\n",
    "   - Documentation template: `Binary classification`\n",
    "   - Use case: `Marketing/Sales - Attrition/Churn Management`\n",
    "\n",
    "   You can fill in other options according to your preference.\n",
    "\n",
    "4. Go to **Getting Started** and click **Copy snippet to clipboard**.\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 17:44:32,501 - INFO(validmind.api_client): Connected to ValidMind. Project: [Int. Tests] Customer Churn - Initial Validation (cltnl29bz00051omgwepjgu1r)\n"
     ]
    }
   ],
   "source": [
    "# Replace with your code snippet\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "    api_host=\"https://api.prod.validmind.ai/api/v1/tracking\",\n",
    "    api_key=\"...\",\n",
    "    api_secret=\"...\",\n",
    "    project=\"...\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify & preview the documentation template\n",
    "\n",
    "Here we want to verify that we have connected with ValidMnd and that the appropriate template is selected. A template predefines sections for your model documentation and provides a general outline to follow, making the documentation process much easier.\n",
    "\n",
    "You will upload documentation and test results into this template later on. For now, take a look at the structure that the template provides with the `vm.preview_template()` function from the ValidMind library and note the empty sections:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccabb7083f8494293ee247ad2032692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Accordion(children=(HTML(value='<p>Empty Section</p>'), Accordion(children=(HTML(value='<p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vm.preview_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's observe the the list of all available tests in the ValidMind Developer Framework:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fb002 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fb002_row0_col0, #T_fb002_row0_col1, #T_fb002_row0_col2, #T_fb002_row0_col3, #T_fb002_row1_col0, #T_fb002_row1_col1, #T_fb002_row1_col2, #T_fb002_row1_col3, #T_fb002_row2_col0, #T_fb002_row2_col1, #T_fb002_row2_col2, #T_fb002_row2_col3, #T_fb002_row3_col0, #T_fb002_row3_col1, #T_fb002_row3_col2, #T_fb002_row3_col3, #T_fb002_row4_col0, #T_fb002_row4_col1, #T_fb002_row4_col2, #T_fb002_row4_col3, #T_fb002_row5_col0, #T_fb002_row5_col1, #T_fb002_row5_col2, #T_fb002_row5_col3, #T_fb002_row6_col0, #T_fb002_row6_col1, #T_fb002_row6_col2, #T_fb002_row6_col3, #T_fb002_row7_col0, #T_fb002_row7_col1, #T_fb002_row7_col2, #T_fb002_row7_col3, #T_fb002_row8_col0, #T_fb002_row8_col1, #T_fb002_row8_col2, #T_fb002_row8_col3, #T_fb002_row9_col0, #T_fb002_row9_col1, #T_fb002_row9_col2, #T_fb002_row9_col3, #T_fb002_row10_col0, #T_fb002_row10_col1, #T_fb002_row10_col2, #T_fb002_row10_col3, #T_fb002_row11_col0, #T_fb002_row11_col1, #T_fb002_row11_col2, #T_fb002_row11_col3, #T_fb002_row12_col0, #T_fb002_row12_col1, #T_fb002_row12_col2, #T_fb002_row12_col3, #T_fb002_row13_col0, #T_fb002_row13_col1, #T_fb002_row13_col2, #T_fb002_row13_col3, #T_fb002_row14_col0, #T_fb002_row14_col1, #T_fb002_row14_col2, #T_fb002_row14_col3, #T_fb002_row15_col0, #T_fb002_row15_col1, #T_fb002_row15_col2, #T_fb002_row15_col3, #T_fb002_row16_col0, #T_fb002_row16_col1, #T_fb002_row16_col2, #T_fb002_row16_col3, #T_fb002_row17_col0, #T_fb002_row17_col1, #T_fb002_row17_col2, #T_fb002_row17_col3, #T_fb002_row18_col0, #T_fb002_row18_col1, #T_fb002_row18_col2, #T_fb002_row18_col3, #T_fb002_row19_col0, #T_fb002_row19_col1, #T_fb002_row19_col2, #T_fb002_row19_col3, #T_fb002_row20_col0, #T_fb002_row20_col1, #T_fb002_row20_col2, #T_fb002_row20_col3, #T_fb002_row21_col0, #T_fb002_row21_col1, #T_fb002_row21_col2, #T_fb002_row21_col3, #T_fb002_row22_col0, #T_fb002_row22_col1, #T_fb002_row22_col2, #T_fb002_row22_col3, #T_fb002_row23_col0, #T_fb002_row23_col1, #T_fb002_row23_col2, #T_fb002_row23_col3, #T_fb002_row24_col0, #T_fb002_row24_col1, #T_fb002_row24_col2, #T_fb002_row24_col3, #T_fb002_row25_col0, #T_fb002_row25_col1, #T_fb002_row25_col2, #T_fb002_row25_col3, #T_fb002_row26_col0, #T_fb002_row26_col1, #T_fb002_row26_col2, #T_fb002_row26_col3, #T_fb002_row27_col0, #T_fb002_row27_col1, #T_fb002_row27_col2, #T_fb002_row27_col3, #T_fb002_row28_col0, #T_fb002_row28_col1, #T_fb002_row28_col2, #T_fb002_row28_col3, #T_fb002_row29_col0, #T_fb002_row29_col1, #T_fb002_row29_col2, #T_fb002_row29_col3, #T_fb002_row30_col0, #T_fb002_row30_col1, #T_fb002_row30_col2, #T_fb002_row30_col3, #T_fb002_row31_col0, #T_fb002_row31_col1, #T_fb002_row31_col2, #T_fb002_row31_col3, #T_fb002_row32_col0, #T_fb002_row32_col1, #T_fb002_row32_col2, #T_fb002_row32_col3, #T_fb002_row33_col0, #T_fb002_row33_col1, #T_fb002_row33_col2, #T_fb002_row33_col3, #T_fb002_row34_col0, #T_fb002_row34_col1, #T_fb002_row34_col2, #T_fb002_row34_col3, #T_fb002_row35_col0, #T_fb002_row35_col1, #T_fb002_row35_col2, #T_fb002_row35_col3, #T_fb002_row36_col0, #T_fb002_row36_col1, #T_fb002_row36_col2, #T_fb002_row36_col3, #T_fb002_row37_col0, #T_fb002_row37_col1, #T_fb002_row37_col2, #T_fb002_row37_col3, #T_fb002_row38_col0, #T_fb002_row38_col1, #T_fb002_row38_col2, #T_fb002_row38_col3, #T_fb002_row39_col0, #T_fb002_row39_col1, #T_fb002_row39_col2, #T_fb002_row39_col3, #T_fb002_row40_col0, #T_fb002_row40_col1, #T_fb002_row40_col2, #T_fb002_row40_col3, #T_fb002_row41_col0, #T_fb002_row41_col1, #T_fb002_row41_col2, #T_fb002_row41_col3, #T_fb002_row42_col0, #T_fb002_row42_col1, #T_fb002_row42_col2, #T_fb002_row42_col3, #T_fb002_row43_col0, #T_fb002_row43_col1, #T_fb002_row43_col2, #T_fb002_row43_col3, #T_fb002_row44_col0, #T_fb002_row44_col1, #T_fb002_row44_col2, #T_fb002_row44_col3, #T_fb002_row45_col0, #T_fb002_row45_col1, #T_fb002_row45_col2, #T_fb002_row45_col3, #T_fb002_row46_col0, #T_fb002_row46_col1, #T_fb002_row46_col2, #T_fb002_row46_col3, #T_fb002_row47_col0, #T_fb002_row47_col1, #T_fb002_row47_col2, #T_fb002_row47_col3, #T_fb002_row48_col0, #T_fb002_row48_col1, #T_fb002_row48_col2, #T_fb002_row48_col3, #T_fb002_row49_col0, #T_fb002_row49_col1, #T_fb002_row49_col2, #T_fb002_row49_col3, #T_fb002_row50_col0, #T_fb002_row50_col1, #T_fb002_row50_col2, #T_fb002_row50_col3, #T_fb002_row51_col0, #T_fb002_row51_col1, #T_fb002_row51_col2, #T_fb002_row51_col3, #T_fb002_row52_col0, #T_fb002_row52_col1, #T_fb002_row52_col2, #T_fb002_row52_col3, #T_fb002_row53_col0, #T_fb002_row53_col1, #T_fb002_row53_col2, #T_fb002_row53_col3, #T_fb002_row54_col0, #T_fb002_row54_col1, #T_fb002_row54_col2, #T_fb002_row54_col3, #T_fb002_row55_col0, #T_fb002_row55_col1, #T_fb002_row55_col2, #T_fb002_row55_col3, #T_fb002_row56_col0, #T_fb002_row56_col1, #T_fb002_row56_col2, #T_fb002_row56_col3, #T_fb002_row57_col0, #T_fb002_row57_col1, #T_fb002_row57_col2, #T_fb002_row57_col3, #T_fb002_row58_col0, #T_fb002_row58_col1, #T_fb002_row58_col2, #T_fb002_row58_col3, #T_fb002_row59_col0, #T_fb002_row59_col1, #T_fb002_row59_col2, #T_fb002_row59_col3, #T_fb002_row60_col0, #T_fb002_row60_col1, #T_fb002_row60_col2, #T_fb002_row60_col3, #T_fb002_row61_col0, #T_fb002_row61_col1, #T_fb002_row61_col2, #T_fb002_row61_col3, #T_fb002_row62_col0, #T_fb002_row62_col1, #T_fb002_row62_col2, #T_fb002_row62_col3, #T_fb002_row63_col0, #T_fb002_row63_col1, #T_fb002_row63_col2, #T_fb002_row63_col3, #T_fb002_row64_col0, #T_fb002_row64_col1, #T_fb002_row64_col2, #T_fb002_row64_col3, #T_fb002_row65_col0, #T_fb002_row65_col1, #T_fb002_row65_col2, #T_fb002_row65_col3, #T_fb002_row66_col0, #T_fb002_row66_col1, #T_fb002_row66_col2, #T_fb002_row66_col3, #T_fb002_row67_col0, #T_fb002_row67_col1, #T_fb002_row67_col2, #T_fb002_row67_col3, #T_fb002_row68_col0, #T_fb002_row68_col1, #T_fb002_row68_col2, #T_fb002_row68_col3, #T_fb002_row69_col0, #T_fb002_row69_col1, #T_fb002_row69_col2, #T_fb002_row69_col3, #T_fb002_row70_col0, #T_fb002_row70_col1, #T_fb002_row70_col2, #T_fb002_row70_col3, #T_fb002_row71_col0, #T_fb002_row71_col1, #T_fb002_row71_col2, #T_fb002_row71_col3, #T_fb002_row72_col0, #T_fb002_row72_col1, #T_fb002_row72_col2, #T_fb002_row72_col3, #T_fb002_row73_col0, #T_fb002_row73_col1, #T_fb002_row73_col2, #T_fb002_row73_col3, #T_fb002_row74_col0, #T_fb002_row74_col1, #T_fb002_row74_col2, #T_fb002_row74_col3, #T_fb002_row75_col0, #T_fb002_row75_col1, #T_fb002_row75_col2, #T_fb002_row75_col3, #T_fb002_row76_col0, #T_fb002_row76_col1, #T_fb002_row76_col2, #T_fb002_row76_col3, #T_fb002_row77_col0, #T_fb002_row77_col1, #T_fb002_row77_col2, #T_fb002_row77_col3, #T_fb002_row78_col0, #T_fb002_row78_col1, #T_fb002_row78_col2, #T_fb002_row78_col3, #T_fb002_row79_col0, #T_fb002_row79_col1, #T_fb002_row79_col2, #T_fb002_row79_col3, #T_fb002_row80_col0, #T_fb002_row80_col1, #T_fb002_row80_col2, #T_fb002_row80_col3, #T_fb002_row81_col0, #T_fb002_row81_col1, #T_fb002_row81_col2, #T_fb002_row81_col3, #T_fb002_row82_col0, #T_fb002_row82_col1, #T_fb002_row82_col2, #T_fb002_row82_col3, #T_fb002_row83_col0, #T_fb002_row83_col1, #T_fb002_row83_col2, #T_fb002_row83_col3, #T_fb002_row84_col0, #T_fb002_row84_col1, #T_fb002_row84_col2, #T_fb002_row84_col3, #T_fb002_row85_col0, #T_fb002_row85_col1, #T_fb002_row85_col2, #T_fb002_row85_col3, #T_fb002_row86_col0, #T_fb002_row86_col1, #T_fb002_row86_col2, #T_fb002_row86_col3, #T_fb002_row87_col0, #T_fb002_row87_col1, #T_fb002_row87_col2, #T_fb002_row87_col3, #T_fb002_row88_col0, #T_fb002_row88_col1, #T_fb002_row88_col2, #T_fb002_row88_col3, #T_fb002_row89_col0, #T_fb002_row89_col1, #T_fb002_row89_col2, #T_fb002_row89_col3, #T_fb002_row90_col0, #T_fb002_row90_col1, #T_fb002_row90_col2, #T_fb002_row90_col3, #T_fb002_row91_col0, #T_fb002_row91_col1, #T_fb002_row91_col2, #T_fb002_row91_col3, #T_fb002_row92_col0, #T_fb002_row92_col1, #T_fb002_row92_col2, #T_fb002_row92_col3, #T_fb002_row93_col0, #T_fb002_row93_col1, #T_fb002_row93_col2, #T_fb002_row93_col3, #T_fb002_row94_col0, #T_fb002_row94_col1, #T_fb002_row94_col2, #T_fb002_row94_col3, #T_fb002_row95_col0, #T_fb002_row95_col1, #T_fb002_row95_col2, #T_fb002_row95_col3, #T_fb002_row96_col0, #T_fb002_row96_col1, #T_fb002_row96_col2, #T_fb002_row96_col3, #T_fb002_row97_col0, #T_fb002_row97_col1, #T_fb002_row97_col2, #T_fb002_row97_col3, #T_fb002_row98_col0, #T_fb002_row98_col1, #T_fb002_row98_col2, #T_fb002_row98_col3, #T_fb002_row99_col0, #T_fb002_row99_col1, #T_fb002_row99_col2, #T_fb002_row99_col3, #T_fb002_row100_col0, #T_fb002_row100_col1, #T_fb002_row100_col2, #T_fb002_row100_col3, #T_fb002_row101_col0, #T_fb002_row101_col1, #T_fb002_row101_col2, #T_fb002_row101_col3, #T_fb002_row102_col0, #T_fb002_row102_col1, #T_fb002_row102_col2, #T_fb002_row102_col3, #T_fb002_row103_col0, #T_fb002_row103_col1, #T_fb002_row103_col2, #T_fb002_row103_col3, #T_fb002_row104_col0, #T_fb002_row104_col1, #T_fb002_row104_col2, #T_fb002_row104_col3, #T_fb002_row105_col0, #T_fb002_row105_col1, #T_fb002_row105_col2, #T_fb002_row105_col3, #T_fb002_row106_col0, #T_fb002_row106_col1, #T_fb002_row106_col2, #T_fb002_row106_col3, #T_fb002_row107_col0, #T_fb002_row107_col1, #T_fb002_row107_col2, #T_fb002_row107_col3, #T_fb002_row108_col0, #T_fb002_row108_col1, #T_fb002_row108_col2, #T_fb002_row108_col3, #T_fb002_row109_col0, #T_fb002_row109_col1, #T_fb002_row109_col2, #T_fb002_row109_col3, #T_fb002_row110_col0, #T_fb002_row110_col1, #T_fb002_row110_col2, #T_fb002_row110_col3, #T_fb002_row111_col0, #T_fb002_row111_col1, #T_fb002_row111_col2, #T_fb002_row111_col3, #T_fb002_row112_col0, #T_fb002_row112_col1, #T_fb002_row112_col2, #T_fb002_row112_col3, #T_fb002_row113_col0, #T_fb002_row113_col1, #T_fb002_row113_col2, #T_fb002_row113_col3, #T_fb002_row114_col0, #T_fb002_row114_col1, #T_fb002_row114_col2, #T_fb002_row114_col3, #T_fb002_row115_col0, #T_fb002_row115_col1, #T_fb002_row115_col2, #T_fb002_row115_col3, #T_fb002_row116_col0, #T_fb002_row116_col1, #T_fb002_row116_col2, #T_fb002_row116_col3, #T_fb002_row117_col0, #T_fb002_row117_col1, #T_fb002_row117_col2, #T_fb002_row117_col3, #T_fb002_row118_col0, #T_fb002_row118_col1, #T_fb002_row118_col2, #T_fb002_row118_col3, #T_fb002_row119_col0, #T_fb002_row119_col1, #T_fb002_row119_col2, #T_fb002_row119_col3, #T_fb002_row120_col0, #T_fb002_row120_col1, #T_fb002_row120_col2, #T_fb002_row120_col3, #T_fb002_row121_col0, #T_fb002_row121_col1, #T_fb002_row121_col2, #T_fb002_row121_col3, #T_fb002_row122_col0, #T_fb002_row122_col1, #T_fb002_row122_col2, #T_fb002_row122_col3, #T_fb002_row123_col0, #T_fb002_row123_col1, #T_fb002_row123_col2, #T_fb002_row123_col3, #T_fb002_row124_col0, #T_fb002_row124_col1, #T_fb002_row124_col2, #T_fb002_row124_col3, #T_fb002_row125_col0, #T_fb002_row125_col1, #T_fb002_row125_col2, #T_fb002_row125_col3, #T_fb002_row126_col0, #T_fb002_row126_col1, #T_fb002_row126_col2, #T_fb002_row126_col3, #T_fb002_row127_col0, #T_fb002_row127_col1, #T_fb002_row127_col2, #T_fb002_row127_col3, #T_fb002_row128_col0, #T_fb002_row128_col1, #T_fb002_row128_col2, #T_fb002_row128_col3, #T_fb002_row129_col0, #T_fb002_row129_col1, #T_fb002_row129_col2, #T_fb002_row129_col3, #T_fb002_row130_col0, #T_fb002_row130_col1, #T_fb002_row130_col2, #T_fb002_row130_col3, #T_fb002_row131_col0, #T_fb002_row131_col1, #T_fb002_row131_col2, #T_fb002_row131_col3, #T_fb002_row132_col0, #T_fb002_row132_col1, #T_fb002_row132_col2, #T_fb002_row132_col3, #T_fb002_row133_col0, #T_fb002_row133_col1, #T_fb002_row133_col2, #T_fb002_row133_col3, #T_fb002_row134_col0, #T_fb002_row134_col1, #T_fb002_row134_col2, #T_fb002_row134_col3, #T_fb002_row135_col0, #T_fb002_row135_col1, #T_fb002_row135_col2, #T_fb002_row135_col3, #T_fb002_row136_col0, #T_fb002_row136_col1, #T_fb002_row136_col2, #T_fb002_row136_col3, #T_fb002_row137_col0, #T_fb002_row137_col1, #T_fb002_row137_col2, #T_fb002_row137_col3, #T_fb002_row138_col0, #T_fb002_row138_col1, #T_fb002_row138_col2, #T_fb002_row138_col3, #T_fb002_row139_col0, #T_fb002_row139_col1, #T_fb002_row139_col2, #T_fb002_row139_col3, #T_fb002_row140_col0, #T_fb002_row140_col1, #T_fb002_row140_col2, #T_fb002_row140_col3, #T_fb002_row141_col0, #T_fb002_row141_col1, #T_fb002_row141_col2, #T_fb002_row141_col3, #T_fb002_row142_col0, #T_fb002_row142_col1, #T_fb002_row142_col2, #T_fb002_row142_col3, #T_fb002_row143_col0, #T_fb002_row143_col1, #T_fb002_row143_col2, #T_fb002_row143_col3, #T_fb002_row144_col0, #T_fb002_row144_col1, #T_fb002_row144_col2, #T_fb002_row144_col3, #T_fb002_row145_col0, #T_fb002_row145_col1, #T_fb002_row145_col2, #T_fb002_row145_col3, #T_fb002_row146_col0, #T_fb002_row146_col1, #T_fb002_row146_col2, #T_fb002_row146_col3, #T_fb002_row147_col0, #T_fb002_row147_col1, #T_fb002_row147_col2, #T_fb002_row147_col3, #T_fb002_row148_col0, #T_fb002_row148_col1, #T_fb002_row148_col2, #T_fb002_row148_col3, #T_fb002_row149_col0, #T_fb002_row149_col1, #T_fb002_row149_col2, #T_fb002_row149_col3, #T_fb002_row150_col0, #T_fb002_row150_col1, #T_fb002_row150_col2, #T_fb002_row150_col3, #T_fb002_row151_col0, #T_fb002_row151_col1, #T_fb002_row151_col2, #T_fb002_row151_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fb002\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_fb002_level0_col0\" class=\"col_heading level0 col0\" >Test Type</th>\n",
       "      <th id=\"T_fb002_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_fb002_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_fb002_level0_col3\" class=\"col_heading level0 col3\" >ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row0_col0\" class=\"data row0 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row0_col1\" class=\"data row0 col1\" >Bias</td>\n",
       "      <td id=\"T_fb002_row0_col2\" class=\"data row0 col2\" >Evaluates bias in a Large Language Model based on the order and distribution of exemplars in a prompt....</td>\n",
       "      <td id=\"T_fb002_row0_col3\" class=\"data row0 col3\" >validmind.prompt_validation.Bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row1_col0\" class=\"data row1 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row1_col1\" class=\"data row1 col1\" >Clarity</td>\n",
       "      <td id=\"T_fb002_row1_col2\" class=\"data row1 col2\" >Evaluates and scores the clarity of prompts in a Large Language Model based on specified guidelines....</td>\n",
       "      <td id=\"T_fb002_row1_col3\" class=\"data row1 col3\" >validmind.prompt_validation.Clarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row2_col0\" class=\"data row2 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row2_col1\" class=\"data row2 col1\" >Specificity</td>\n",
       "      <td id=\"T_fb002_row2_col2\" class=\"data row2 col2\" >Evaluates and scores the specificity of prompts provided to a Large Language Model (LLM), based on clarity,...</td>\n",
       "      <td id=\"T_fb002_row2_col3\" class=\"data row2 col3\" >validmind.prompt_validation.Specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row3_col0\" class=\"data row3 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row3_col1\" class=\"data row3 col1\" >Robustness</td>\n",
       "      <td id=\"T_fb002_row3_col2\" class=\"data row3 col2\" >Assesses the robustness of prompts provided to a Large Language Model under varying conditions and contexts....</td>\n",
       "      <td id=\"T_fb002_row3_col3\" class=\"data row3 col3\" >validmind.prompt_validation.Robustness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row4_col0\" class=\"data row4 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row4_col1\" class=\"data row4 col1\" >Negative Instruction</td>\n",
       "      <td id=\"T_fb002_row4_col2\" class=\"data row4 col2\" >Evaluates and grades the use of affirmative, proactive language over negative instructions in LLM prompts....</td>\n",
       "      <td id=\"T_fb002_row4_col3\" class=\"data row4 col3\" >validmind.prompt_validation.NegativeInstruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row5_col0\" class=\"data row5 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row5_col1\" class=\"data row5 col1\" >Conciseness</td>\n",
       "      <td id=\"T_fb002_row5_col2\" class=\"data row5 col2\" >Analyzes and grades the conciseness of prompts provided to a Large Language Model....</td>\n",
       "      <td id=\"T_fb002_row5_col3\" class=\"data row5 col3\" >validmind.prompt_validation.Conciseness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row6_col0\" class=\"data row6 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row6_col1\" class=\"data row6 col1\" >Delimitation</td>\n",
       "      <td id=\"T_fb002_row6_col2\" class=\"data row6 col2\" >Evaluates the proper use of delimiters in prompts provided to Large Language Models....</td>\n",
       "      <td id=\"T_fb002_row6_col3\" class=\"data row6 col3\" >validmind.prompt_validation.Delimitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row7_col0\" class=\"data row7 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row7_col1\" class=\"data row7 col1\" >Bert Score</td>\n",
       "      <td id=\"T_fb002_row7_col2\" class=\"data row7 col2\" >Evaluates text generation models' performance by calculating precision, recall, and F1 score based on BERT...</td>\n",
       "      <td id=\"T_fb002_row7_col3\" class=\"data row7 col3\" >validmind.model_validation.BertScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row8_col0\" class=\"data row8 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row8_col1\" class=\"data row8 col1\" >Regard Score</td>\n",
       "      <td id=\"T_fb002_row8_col2\" class=\"data row8 col2\" >**Purpose:**...</td>\n",
       "      <td id=\"T_fb002_row8_col3\" class=\"data row8 col3\" >validmind.model_validation.RegardScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row9_col0\" class=\"data row9 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row9_col1\" class=\"data row9 col1\" >Bleu Score</td>\n",
       "      <td id=\"T_fb002_row9_col2\" class=\"data row9 col2\" >Assesses translation quality by comparing machine-translated sentences with human-translated ones using BLEU score....</td>\n",
       "      <td id=\"T_fb002_row9_col3\" class=\"data row9 col3\" >validmind.model_validation.BleuScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row10_col0\" class=\"data row10 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row10_col1\" class=\"data row10 col1\" >Contextual Recall</td>\n",
       "      <td id=\"T_fb002_row10_col2\" class=\"data row10 col2\" >Evaluates a Natural Language Generation model's ability to generate contextually relevant and factually correct...</td>\n",
       "      <td id=\"T_fb002_row10_col3\" class=\"data row10 col3\" >validmind.model_validation.ContextualRecall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row11_col0\" class=\"data row11 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row11_col1\" class=\"data row11 col1\" >Meteor Score</td>\n",
       "      <td id=\"T_fb002_row11_col2\" class=\"data row11 col2\" >Computes and visualizes the METEOR score for each text generation instance, assessing translation quality....</td>\n",
       "      <td id=\"T_fb002_row11_col3\" class=\"data row11 col3\" >validmind.model_validation.MeteorScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row12_col0\" class=\"data row12 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row12_col1\" class=\"data row12 col1\" >Regard Histogram</td>\n",
       "      <td id=\"T_fb002_row12_col2\" class=\"data row12 col2\" >**Purpose:**...</td>\n",
       "      <td id=\"T_fb002_row12_col3\" class=\"data row12 col3\" >validmind.model_validation.RegardHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row13_col0\" class=\"data row13 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row13_col1\" class=\"data row13 col1\" >Toxicity Histogram</td>\n",
       "      <td id=\"T_fb002_row13_col2\" class=\"data row13 col2\" >**Purpose:**...</td>\n",
       "      <td id=\"T_fb002_row13_col3\" class=\"data row13 col3\" >validmind.model_validation.ToxicityHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row14_col0\" class=\"data row14 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row14_col1\" class=\"data row14 col1\" >Rouge Metrics</td>\n",
       "      <td id=\"T_fb002_row14_col2\" class=\"data row14 col2\" >Evaluates the quality of machine-generated text using various ROUGE metrics, and visualizes the results....</td>\n",
       "      <td id=\"T_fb002_row14_col3\" class=\"data row14 col3\" >validmind.model_validation.RougeMetrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row15_col0\" class=\"data row15 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row15_col1\" class=\"data row15 col1\" >Model Metadata</td>\n",
       "      <td id=\"T_fb002_row15_col2\" class=\"data row15 col2\" >Extracts and summarizes critical metadata from a machine learning model instance for comprehensive analysis....</td>\n",
       "      <td id=\"T_fb002_row15_col3\" class=\"data row15 col3\" >validmind.model_validation.ModelMetadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row16_col0\" class=\"data row16 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row16_col1\" class=\"data row16 col1\" >Bert Score Aggregate</td>\n",
       "      <td id=\"T_fb002_row16_col2\" class=\"data row16 col2\" >Evaluates the aggregate performance of text generation models by computing the average precision, recall,...</td>\n",
       "      <td id=\"T_fb002_row16_col3\" class=\"data row16 col3\" >validmind.model_validation.BertScoreAggregate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row17_col0\" class=\"data row17 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row17_col1\" class=\"data row17 col1\" >Cluster Size Distribution</td>\n",
       "      <td id=\"T_fb002_row17_col2\" class=\"data row17 col2\" >Compares and visualizes the distribution of cluster sizes in model predictions and actual data for assessing...</td>\n",
       "      <td id=\"T_fb002_row17_col3\" class=\"data row17 col3\" >validmind.model_validation.ClusterSizeDistribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row18_col0\" class=\"data row18 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row18_col1\" class=\"data row18 col1\" >Token Disparity</td>\n",
       "      <td id=\"T_fb002_row18_col2\" class=\"data row18 col2\" >Assess and visualize token count disparity between model's predicted and actual dataset....</td>\n",
       "      <td id=\"T_fb002_row18_col3\" class=\"data row18 col3\" >validmind.model_validation.TokenDisparity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row19_col0\" class=\"data row19 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row19_col1\" class=\"data row19 col1\" >Toxicity Score</td>\n",
       "      <td id=\"T_fb002_row19_col2\" class=\"data row19 col2\" >**Purpose:**...</td>\n",
       "      <td id=\"T_fb002_row19_col3\" class=\"data row19 col3\" >validmind.model_validation.ToxicityScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row20_col0\" class=\"data row20 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row20_col1\" class=\"data row20 col1\" >Self Check NLI Score</td>\n",
       "      <td id=\"T_fb002_row20_col2\" class=\"data row20 col2\" >Evaluates text generation models' performance by quantifying the level of hallucination in generated texts compared to reference texts....</td>\n",
       "      <td id=\"T_fb002_row20_col3\" class=\"data row20 col3\" >validmind.model_validation.SelfCheckNLIScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row21_col0\" class=\"data row21 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row21_col1\" class=\"data row21 col1\" >Rouge Metrics Aggregate</td>\n",
       "      <td id=\"T_fb002_row21_col2\" class=\"data row21 col2\" >Evaluates the average quality of machine-generated text using various ROUGE metrics and visualizes the aggregated results....</td>\n",
       "      <td id=\"T_fb002_row21_col3\" class=\"data row21 col3\" >validmind.model_validation.RougeMetricsAggregate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row22_col0\" class=\"data row22 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row22_col1\" class=\"data row22 col1\" >Embeddings Visualization D</td>\n",
       "      <td id=\"T_fb002_row22_col2\" class=\"data row22 col2\" >Visualizes 2D representation of text embeddings generated by a model using t-SNE technique....</td>\n",
       "      <td id=\"T_fb002_row22_col3\" class=\"data row22 col3\" >validmind.model_validation.embeddings.EmbeddingsVisualization2D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row23_col0\" class=\"data row23 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row23_col1\" class=\"data row23 col1\" >Stability Analysis Random Noise</td>\n",
       "      <td id=\"T_fb002_row23_col2\" class=\"data row23 col2\" >Evaluate robustness of embeddings models to random noise introduced by using...</td>\n",
       "      <td id=\"T_fb002_row23_col3\" class=\"data row23 col3\" >validmind.model_validation.embeddings.StabilityAnalysisRandomNoise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row24_col0\" class=\"data row24 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row24_col1\" class=\"data row24 col1\" >Cosine Similarity Distribution</td>\n",
       "      <td id=\"T_fb002_row24_col2\" class=\"data row24 col2\" >Assesses the similarity between predicted text embeddings from a model using a Cosine Similarity distribution...</td>\n",
       "      <td id=\"T_fb002_row24_col3\" class=\"data row24 col3\" >validmind.model_validation.embeddings.CosineSimilarityDistribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row25_col0\" class=\"data row25 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row25_col1\" class=\"data row25 col1\" >Stability Analysis Translation</td>\n",
       "      <td id=\"T_fb002_row25_col2\" class=\"data row25 col2\" >Evaluate robustness of embeddings models to noise introduced by translating...</td>\n",
       "      <td id=\"T_fb002_row25_col3\" class=\"data row25 col3\" >validmind.model_validation.embeddings.StabilityAnalysisTranslation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row26_col0\" class=\"data row26 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row26_col1\" class=\"data row26 col1\" >Cluster Distribution</td>\n",
       "      <td id=\"T_fb002_row26_col2\" class=\"data row26 col2\" >Assesses the distribution of text embeddings across clusters produced by a model using KMeans clustering....</td>\n",
       "      <td id=\"T_fb002_row26_col3\" class=\"data row26 col3\" >validmind.model_validation.embeddings.ClusterDistribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row27_col0\" class=\"data row27 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row27_col1\" class=\"data row27 col1\" >Stability Analysis</td>\n",
       "      <td id=\"T_fb002_row27_col2\" class=\"data row27 col2\" >Base class for embeddings stability analysis tests</td>\n",
       "      <td id=\"T_fb002_row27_col3\" class=\"data row27 col3\" >validmind.model_validation.embeddings.StabilityAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row28_col0\" class=\"data row28 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row28_col1\" class=\"data row28 col1\" >Stability Analysis Keyword</td>\n",
       "      <td id=\"T_fb002_row28_col2\" class=\"data row28 col2\" >Evaluate robustness of embeddings models to keyword swaps on the test dataset...</td>\n",
       "      <td id=\"T_fb002_row28_col3\" class=\"data row28 col3\" >validmind.model_validation.embeddings.StabilityAnalysisKeyword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row29_col0\" class=\"data row29 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row29_col1\" class=\"data row29 col1\" >Stability Analysis Synonyms</td>\n",
       "      <td id=\"T_fb002_row29_col2\" class=\"data row29 col2\" >Evaluates the stability of text embeddings models when words in test data are replaced by their synonyms randomly....</td>\n",
       "      <td id=\"T_fb002_row29_col3\" class=\"data row29 col3\" >validmind.model_validation.embeddings.StabilityAnalysisSynonyms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row30_col0\" class=\"data row30 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row30_col1\" class=\"data row30 col1\" >Descriptive Analytics</td>\n",
       "      <td id=\"T_fb002_row30_col2\" class=\"data row30 col2\" >Evaluates statistical properties of text embeddings in an ML model via mean, median, and standard deviation...</td>\n",
       "      <td id=\"T_fb002_row30_col3\" class=\"data row30 col3\" >validmind.model_validation.embeddings.DescriptiveAnalytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row31_col0\" class=\"data row31 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row31_col1\" class=\"data row31 col1\" >Regression Models Performance Comparison</td>\n",
       "      <td id=\"T_fb002_row31_col2\" class=\"data row31 col2\" >Compares and evaluates the performance of multiple regression models using five different metrics: MAE, MSE, RMSE,...</td>\n",
       "      <td id=\"T_fb002_row31_col3\" class=\"data row31 col3\" >validmind.model_validation.sklearn.RegressionModelsPerformanceComparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row32_col0\" class=\"data row32 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row32_col1\" class=\"data row32 col1\" >Adjusted Mutual Information</td>\n",
       "      <td id=\"T_fb002_row32_col2\" class=\"data row32 col2\" >Evaluates clustering model performance by measuring mutual information between true and predicted labels, adjusting...</td>\n",
       "      <td id=\"T_fb002_row32_col3\" class=\"data row32 col3\" >validmind.model_validation.sklearn.AdjustedMutualInformation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row33_col0\" class=\"data row33 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row33_col1\" class=\"data row33 col1\" >Silhouette Plot</td>\n",
       "      <td id=\"T_fb002_row33_col2\" class=\"data row33 col2\" >Calculates and visualizes Silhouette Score, assessing degree of data point suitability to its cluster in ML models....</td>\n",
       "      <td id=\"T_fb002_row33_col3\" class=\"data row33 col3\" >validmind.model_validation.sklearn.SilhouettePlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row34_col0\" class=\"data row34 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row34_col1\" class=\"data row34 col1\" >Robustness Diagnosis</td>\n",
       "      <td id=\"T_fb002_row34_col2\" class=\"data row34 col2\" >Evaluates the robustness of a machine learning model by injecting Gaussian noise to input data and measuring...</td>\n",
       "      <td id=\"T_fb002_row34_col3\" class=\"data row34 col3\" >validmind.model_validation.sklearn.RobustnessDiagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row35_col0\" class=\"data row35 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row35_col1\" class=\"data row35 col1\" >Adjusted Rand Index</td>\n",
       "      <td id=\"T_fb002_row35_col2\" class=\"data row35 col2\" >Measures the similarity between two data clusters using the Adjusted Rand Index (ARI) metric in clustering machine...</td>\n",
       "      <td id=\"T_fb002_row35_col3\" class=\"data row35 col3\" >validmind.model_validation.sklearn.AdjustedRandIndex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row36_col0\" class=\"data row36 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row36_col1\" class=\"data row36 col1\" >SHAP Global Importance</td>\n",
       "      <td id=\"T_fb002_row36_col2\" class=\"data row36 col2\" >Evaluates and visualizes global feature importance using SHAP values for model explanation and risk identification....</td>\n",
       "      <td id=\"T_fb002_row36_col3\" class=\"data row36 col3\" >validmind.model_validation.sklearn.SHAPGlobalImportance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row37_col0\" class=\"data row37 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row37_col1\" class=\"data row37 col1\" >Confusion Matrix</td>\n",
       "      <td id=\"T_fb002_row37_col2\" class=\"data row37 col2\" >Evaluates and visually represents the classification ML model's predictive performance using a Confusion Matrix...</td>\n",
       "      <td id=\"T_fb002_row37_col3\" class=\"data row37 col3\" >validmind.model_validation.sklearn.ConfusionMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row38_col0\" class=\"data row38 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row38_col1\" class=\"data row38 col1\" >Homogeneity Score</td>\n",
       "      <td id=\"T_fb002_row38_col2\" class=\"data row38 col2\" >Assesses clustering homogeneity by comparing true and predicted labels, scoring from 0 (heterogeneous) to 1...</td>\n",
       "      <td id=\"T_fb002_row38_col3\" class=\"data row38 col3\" >validmind.model_validation.sklearn.HomogeneityScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row39_col0\" class=\"data row39 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row39_col1\" class=\"data row39 col1\" >Completeness Score</td>\n",
       "      <td id=\"T_fb002_row39_col2\" class=\"data row39 col2\" >Evaluates a clustering model's capacity to categorize instances from a single class into the same cluster....</td>\n",
       "      <td id=\"T_fb002_row39_col3\" class=\"data row39 col3\" >validmind.model_validation.sklearn.CompletenessScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row40_col0\" class=\"data row40 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row40_col1\" class=\"data row40 col1\" >Overfit Diagnosis</td>\n",
       "      <td id=\"T_fb002_row40_col2\" class=\"data row40 col2\" >Detects and visualizes overfit regions in an ML model by comparing performance on training and test datasets....</td>\n",
       "      <td id=\"T_fb002_row40_col3\" class=\"data row40 col3\" >validmind.model_validation.sklearn.OverfitDiagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row41_col0\" class=\"data row41 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row41_col1\" class=\"data row41 col1\" >Cluster Performance Metrics</td>\n",
       "      <td id=\"T_fb002_row41_col2\" class=\"data row41 col2\" >Evaluates the performance of clustering machine learning models using multiple established metrics....</td>\n",
       "      <td id=\"T_fb002_row41_col3\" class=\"data row41 col3\" >validmind.model_validation.sklearn.ClusterPerformanceMetrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row42_col0\" class=\"data row42 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row42_col1\" class=\"data row42 col1\" >Permutation Feature Importance</td>\n",
       "      <td id=\"T_fb002_row42_col2\" class=\"data row42 col2\" >Assesses the significance of each feature in a model by evaluating the impact on model performance when feature...</td>\n",
       "      <td id=\"T_fb002_row42_col3\" class=\"data row42 col3\" >validmind.model_validation.sklearn.PermutationFeatureImportance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row43_col0\" class=\"data row43 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row43_col1\" class=\"data row43 col1\" >Fowlkes Mallows Score</td>\n",
       "      <td id=\"T_fb002_row43_col2\" class=\"data row43 col2\" >Evaluates the similarity between predicted and actual cluster assignments in a model using the Fowlkes-Mallows...</td>\n",
       "      <td id=\"T_fb002_row43_col3\" class=\"data row43 col3\" >validmind.model_validation.sklearn.FowlkesMallowsScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row44_col0\" class=\"data row44 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row44_col1\" class=\"data row44 col1\" >Minimum ROCAUC Score</td>\n",
       "      <td id=\"T_fb002_row44_col2\" class=\"data row44 col2\" >Validates model by checking if the ROC AUC score meets or surpasses a specified threshold....</td>\n",
       "      <td id=\"T_fb002_row44_col3\" class=\"data row44 col3\" >validmind.model_validation.sklearn.MinimumROCAUCScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row45_col0\" class=\"data row45 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row45_col1\" class=\"data row45 col1\" >Cluster Cosine Similarity</td>\n",
       "      <td id=\"T_fb002_row45_col2\" class=\"data row45 col2\" >Measures the intra-cluster similarity of a clustering model using cosine similarity....</td>\n",
       "      <td id=\"T_fb002_row45_col3\" class=\"data row45 col3\" >validmind.model_validation.sklearn.ClusterCosineSimilarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row46_col0\" class=\"data row46 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row46_col1\" class=\"data row46 col1\" >Precision Recall Curve</td>\n",
       "      <td id=\"T_fb002_row46_col2\" class=\"data row46 col2\" >Evaluates the precision-recall trade-off for binary classification models and visualizes the Precision-Recall curve....</td>\n",
       "      <td id=\"T_fb002_row46_col3\" class=\"data row46 col3\" >validmind.model_validation.sklearn.PrecisionRecallCurve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row47_col0\" class=\"data row47 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row47_col1\" class=\"data row47 col1\" >Classifier Performance</td>\n",
       "      <td id=\"T_fb002_row47_col2\" class=\"data row47 col2\" >Evaluates performance of binary or multiclass classification models using precision, recall, F1-Score, accuracy,...</td>\n",
       "      <td id=\"T_fb002_row47_col3\" class=\"data row47 col3\" >validmind.model_validation.sklearn.ClassifierPerformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row48_col0\" class=\"data row48 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row48_col1\" class=\"data row48 col1\" >V Measure</td>\n",
       "      <td id=\"T_fb002_row48_col2\" class=\"data row48 col2\" >Evaluates homogeneity and completeness of a clustering model using the V Measure Score....</td>\n",
       "      <td id=\"T_fb002_row48_col3\" class=\"data row48 col3\" >validmind.model_validation.sklearn.VMeasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row49_col0\" class=\"data row49 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row49_col1\" class=\"data row49 col1\" >Minimum Score</td>\n",
       "      <td id=\"T_fb002_row49_col2\" class=\"data row49 col2\" >Evaluates if the model's F1 score on the validation set meets a predefined minimum threshold....</td>\n",
       "      <td id=\"T_fb002_row49_col3\" class=\"data row49 col3\" >validmind.model_validation.sklearn.MinimumF1Score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row50_col0\" class=\"data row50 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row50_col1\" class=\"data row50 col1\" >ROC Curve</td>\n",
       "      <td id=\"T_fb002_row50_col2\" class=\"data row50 col2\" >Evaluates binary classification model performance by generating and plotting the Receiver Operating Characteristic...</td>\n",
       "      <td id=\"T_fb002_row50_col3\" class=\"data row50 col3\" >validmind.model_validation.sklearn.ROCCurve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row51_col0\" class=\"data row51 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row51_col1\" class=\"data row51 col1\" >Regression Square</td>\n",
       "      <td id=\"T_fb002_row51_col2\" class=\"data row51 col2\" >**Purpose**: The purpose of the RegressionR2Square Metric test is to measure the overall goodness-of-fit of a...</td>\n",
       "      <td id=\"T_fb002_row51_col3\" class=\"data row51 col3\" >validmind.model_validation.sklearn.RegressionR2Square</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row52_col0\" class=\"data row52 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row52_col1\" class=\"data row52 col1\" >Regression Errors</td>\n",
       "      <td id=\"T_fb002_row52_col2\" class=\"data row52 col2\" >**Purpose**: This metric is used to measure the performance of a regression model. It gauges the model's accuracy...</td>\n",
       "      <td id=\"T_fb002_row52_col3\" class=\"data row52 col3\" >validmind.model_validation.sklearn.RegressionErrors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row53_col0\" class=\"data row53 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row53_col1\" class=\"data row53 col1\" >Cluster Performance</td>\n",
       "      <td id=\"T_fb002_row53_col2\" class=\"data row53 col2\" >Evaluates and compares a clustering model's performance on training and testing datasets using multiple defined...</td>\n",
       "      <td id=\"T_fb002_row53_col3\" class=\"data row53 col3\" >validmind.model_validation.sklearn.ClusterPerformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row54_col0\" class=\"data row54 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row54_col1\" class=\"data row54 col1\" >Training Test Degradation</td>\n",
       "      <td id=\"T_fb002_row54_col2\" class=\"data row54 col2\" >Tests if model performance degradation between training and test datasets exceeds a predefined threshold....</td>\n",
       "      <td id=\"T_fb002_row54_col3\" class=\"data row54 col3\" >validmind.model_validation.sklearn.TrainingTestDegradation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row55_col0\" class=\"data row55 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row55_col1\" class=\"data row55 col1\" >Hyper Parameters Tuning</td>\n",
       "      <td id=\"T_fb002_row55_col2\" class=\"data row55 col2\" >Exerts exhaustive grid search to identify optimal hyperparameters for the model, improving performance....</td>\n",
       "      <td id=\"T_fb002_row55_col3\" class=\"data row55 col3\" >validmind.model_validation.sklearn.HyperParametersTuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row56_col0\" class=\"data row56 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row56_col1\" class=\"data row56 col1\" >K Means Clusters Optimization</td>\n",
       "      <td id=\"T_fb002_row56_col2\" class=\"data row56 col2\" >Optimizes the number of clusters in K-means models using Elbow and Silhouette methods....</td>\n",
       "      <td id=\"T_fb002_row56_col3\" class=\"data row56 col3\" >validmind.model_validation.sklearn.KMeansClustersOptimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row57_col0\" class=\"data row57 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row57_col1\" class=\"data row57 col1\" >Models Performance Comparison</td>\n",
       "      <td id=\"T_fb002_row57_col2\" class=\"data row57 col2\" >Evaluates and compares the performance of multiple Machine Learning models using various metrics like accuracy,...</td>\n",
       "      <td id=\"T_fb002_row57_col3\" class=\"data row57 col3\" >validmind.model_validation.sklearn.ModelsPerformanceComparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row58_col0\" class=\"data row58 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row58_col1\" class=\"data row58 col1\" >Weakspots Diagnosis</td>\n",
       "      <td id=\"T_fb002_row58_col2\" class=\"data row58 col2\" >Identifies and visualizes weak spots in a machine learning model's performance across various sections of the...</td>\n",
       "      <td id=\"T_fb002_row58_col3\" class=\"data row58 col3\" >validmind.model_validation.sklearn.WeakspotsDiagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row59_col0\" class=\"data row59 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row59_col1\" class=\"data row59 col1\" >Population Stability Index</td>\n",
       "      <td id=\"T_fb002_row59_col2\" class=\"data row59 col2\" >Evaluates the Population Stability Index (PSI) to quantify the stability of an ML model's predictions across...</td>\n",
       "      <td id=\"T_fb002_row59_col3\" class=\"data row59 col3\" >validmind.model_validation.sklearn.PopulationStabilityIndex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row60_col0\" class=\"data row60 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row60_col1\" class=\"data row60 col1\" >Minimum Accuracy</td>\n",
       "      <td id=\"T_fb002_row60_col2\" class=\"data row60 col2\" >Checks if the model's prediction accuracy meets or surpasses a specified threshold....</td>\n",
       "      <td id=\"T_fb002_row60_col3\" class=\"data row60 col3\" >validmind.model_validation.sklearn.MinimumAccuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row61_col0\" class=\"data row61 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row61_col1\" class=\"data row61 col1\" >Regression Models Coeffs</td>\n",
       "      <td id=\"T_fb002_row61_col2\" class=\"data row61 col2\" >Compares feature importance by evaluating and contrasting coefficients of different regression models....</td>\n",
       "      <td id=\"T_fb002_row61_col3\" class=\"data row61 col3\" >validmind.model_validation.statsmodels.RegressionModelsCoeffs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row62_col0\" class=\"data row62 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row62_col1\" class=\"data row62 col1\" >Box Pierce</td>\n",
       "      <td id=\"T_fb002_row62_col2\" class=\"data row62 col2\" >Detects autocorrelation in time-series data through the Box-Pierce test to validate model performance....</td>\n",
       "      <td id=\"T_fb002_row62_col3\" class=\"data row62 col3\" >validmind.model_validation.statsmodels.BoxPierce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row63_col0\" class=\"data row63 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row63_col1\" class=\"data row63 col1\" >Regression Coeffs Plot</td>\n",
       "      <td id=\"T_fb002_row63_col2\" class=\"data row63 col2\" >Visualizes regression coefficients with 95% confidence intervals to assess predictor variables' impact on response...</td>\n",
       "      <td id=\"T_fb002_row63_col3\" class=\"data row63 col3\" >validmind.model_validation.statsmodels.RegressionCoeffsPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row64_col0\" class=\"data row64 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row64_col1\" class=\"data row64 col1\" >Regression Model Sensitivity Plot</td>\n",
       "      <td id=\"T_fb002_row64_col2\" class=\"data row64 col2\" >Tests the sensitivity of a regression model to variations in independent variables by applying shocks and...</td>\n",
       "      <td id=\"T_fb002_row64_col3\" class=\"data row64 col3\" >validmind.model_validation.statsmodels.RegressionModelSensitivityPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row65_col0\" class=\"data row65 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row65_col1\" class=\"data row65 col1\" >Regression Models Performance</td>\n",
       "      <td id=\"T_fb002_row65_col2\" class=\"data row65 col2\" >Evaluates and compares regression models' performance using R-squared, Adjusted R-squared, and MSE metrics....</td>\n",
       "      <td id=\"T_fb002_row65_col3\" class=\"data row65 col3\" >validmind.model_validation.statsmodels.RegressionModelsPerformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row66_col0\" class=\"data row66 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row66_col1\" class=\"data row66 col1\" >Zivot Andrews Arch</td>\n",
       "      <td id=\"T_fb002_row66_col2\" class=\"data row66 col2\" >Evaluates the order of integration and stationarity of time series data using Zivot-Andrews unit root test....</td>\n",
       "      <td id=\"T_fb002_row66_col3\" class=\"data row66 col3\" >validmind.model_validation.statsmodels.ZivotAndrewsArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row67_col0\" class=\"data row67 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row67_col1\" class=\"data row67 col1\" >Regression Model Outsample Comparison</td>\n",
       "      <td id=\"T_fb002_row67_col2\" class=\"data row67 col2\" >Computes MSE and RMSE for multiple regression models using out-of-sample test to assess model's prediction accuracy...</td>\n",
       "      <td id=\"T_fb002_row67_col3\" class=\"data row67 col3\" >validmind.model_validation.statsmodels.RegressionModelOutsampleComparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row68_col0\" class=\"data row68 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row68_col1\" class=\"data row68 col1\" >Regression Model Forecast Plot Levels</td>\n",
       "      <td id=\"T_fb002_row68_col2\" class=\"data row68 col2\" >Compares and visualizes forecasted and actual values of regression models on both raw and transformed datasets....</td>\n",
       "      <td id=\"T_fb002_row68_col3\" class=\"data row68 col3\" >validmind.model_validation.statsmodels.RegressionModelForecastPlotLevels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row69_col0\" class=\"data row69 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row69_col1\" class=\"data row69 col1\" >Log Regression Confusion Matrix</td>\n",
       "      <td id=\"T_fb002_row69_col2\" class=\"data row69 col2\" >Generates a confusion matrix for logistic regression model performance, utilizing thresholded probabilities for...</td>\n",
       "      <td id=\"T_fb002_row69_col3\" class=\"data row69 col3\" >validmind.model_validation.statsmodels.LogRegressionConfusionMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row70_col0\" class=\"data row70 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row70_col1\" class=\"data row70 col1\" >PD Rating Class Plot</td>\n",
       "      <td id=\"T_fb002_row70_col2\" class=\"data row70 col2\" >Assesses and visualizes credit risk distribution across different rating classes within a dataset via default...</td>\n",
       "      <td id=\"T_fb002_row70_col3\" class=\"data row70 col3\" >validmind.model_validation.statsmodels.PDRatingClassPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row71_col0\" class=\"data row71 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row71_col1\" class=\"data row71 col1\" >Scorecard Histogram</td>\n",
       "      <td id=\"T_fb002_row71_col2\" class=\"data row71 col2\" >Creates histograms of credit scores, from both default and non-default instances, generated by a credit-risk model....</td>\n",
       "      <td id=\"T_fb002_row71_col3\" class=\"data row71 col3\" >validmind.model_validation.statsmodels.ScorecardHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row72_col0\" class=\"data row72 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row72_col1\" class=\"data row72 col1\" >Feature Importance And Significance</td>\n",
       "      <td id=\"T_fb002_row72_col2\" class=\"data row72 col2\" >Evaluates and visualizes the statistical significance and feature importance using regression and decision tree...</td>\n",
       "      <td id=\"T_fb002_row72_col3\" class=\"data row72 col3\" >validmind.model_validation.statsmodels.FeatureImportanceAndSignificance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row73_col0\" class=\"data row73 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row73_col1\" class=\"data row73 col1\" >L Jung Box</td>\n",
       "      <td id=\"T_fb002_row73_col2\" class=\"data row73 col2\" >Assesses autocorrelations in dataset features by performing a Ljung-Box test on each feature....</td>\n",
       "      <td id=\"T_fb002_row73_col3\" class=\"data row73 col3\" >validmind.model_validation.statsmodels.LJungBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row74_col0\" class=\"data row74 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row74_col1\" class=\"data row74 col1\" >Logistic Reg Prediction Histogram</td>\n",
       "      <td id=\"T_fb002_row74_col2\" class=\"data row74 col2\" >Generates and visualizes histograms of the Probability of Default predictions for both positive and negative...</td>\n",
       "      <td id=\"T_fb002_row74_col3\" class=\"data row74 col3\" >validmind.model_validation.statsmodels.LogisticRegPredictionHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row75_col0\" class=\"data row75 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row75_col1\" class=\"data row75 col1\" >Jarque Bera</td>\n",
       "      <td id=\"T_fb002_row75_col2\" class=\"data row75 col2\" >Assesses normality of dataset features in an ML model using the Jarque-Bera test....</td>\n",
       "      <td id=\"T_fb002_row75_col3\" class=\"data row75 col3\" >validmind.model_validation.statsmodels.JarqueBera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row76_col0\" class=\"data row76 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row76_col1\" class=\"data row76 col1\" >Phillips Perron Arch</td>\n",
       "      <td id=\"T_fb002_row76_col2\" class=\"data row76 col2\" >Executes Phillips-Perron test to assess the stationarity of time series data in each ML model feature....</td>\n",
       "      <td id=\"T_fb002_row76_col3\" class=\"data row76 col3\" >validmind.model_validation.statsmodels.PhillipsPerronArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row77_col0\" class=\"data row77 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row77_col1\" class=\"data row77 col1\" >Kolmogorov Smirnov</td>\n",
       "      <td id=\"T_fb002_row77_col2\" class=\"data row77 col2\" >Executes a feature-wise Kolmogorov-Smirnov test to evaluate alignment with normal distribution in datasets....</td>\n",
       "      <td id=\"T_fb002_row77_col3\" class=\"data row77 col3\" >validmind.model_validation.statsmodels.KolmogorovSmirnov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row78_col0\" class=\"data row78 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row78_col1\" class=\"data row78 col1\" >Residuals Visual Inspection</td>\n",
       "      <td id=\"T_fb002_row78_col2\" class=\"data row78 col2\" >Provides a comprehensive visual analysis of residuals for regression models utilizing various plot types....</td>\n",
       "      <td id=\"T_fb002_row78_col3\" class=\"data row78 col3\" >validmind.model_validation.statsmodels.ResidualsVisualInspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row79_col0\" class=\"data row79 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row79_col1\" class=\"data row79 col1\" >Shapiro Wilk</td>\n",
       "      <td id=\"T_fb002_row79_col2\" class=\"data row79 col2\" >Evaluates feature-wise normality of training data using the Shapiro-Wilk test....</td>\n",
       "      <td id=\"T_fb002_row79_col3\" class=\"data row79 col3\" >validmind.model_validation.statsmodels.ShapiroWilk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row80_col0\" class=\"data row80 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row80_col1\" class=\"data row80 col1\" >Scorecard Bucket Histogram</td>\n",
       "      <td id=\"T_fb002_row80_col2\" class=\"data row80 col2\" >Evaluates and visualizes distribution of risk categories in a classification model's scores, useful in credit risk...</td>\n",
       "      <td id=\"T_fb002_row80_col3\" class=\"data row80 col3\" >validmind.model_validation.statsmodels.ScorecardBucketHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row81_col0\" class=\"data row81 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row81_col1\" class=\"data row81 col1\" >Regression Model Insample Comparison</td>\n",
       "      <td id=\"T_fb002_row81_col2\" class=\"data row81 col2\" >Evaluates and compares in-sample performance of multiple regression models using R-Squared, Adjusted R-Squared,...</td>\n",
       "      <td id=\"T_fb002_row81_col3\" class=\"data row81 col3\" >validmind.model_validation.statsmodels.RegressionModelInsampleComparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row82_col0\" class=\"data row82 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row82_col1\" class=\"data row82 col1\" >Regression Feature Significance</td>\n",
       "      <td id=\"T_fb002_row82_col2\" class=\"data row82 col2\" >Assesses and visualizes the statistical significance of features in a set of regression models....</td>\n",
       "      <td id=\"T_fb002_row82_col3\" class=\"data row82 col3\" >validmind.model_validation.statsmodels.RegressionFeatureSignificance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row83_col0\" class=\"data row83 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row83_col1\" class=\"data row83 col1\" >Regression Model Summary</td>\n",
       "      <td id=\"T_fb002_row83_col2\" class=\"data row83 col2\" >Evaluates regression model performance using metrics including R-Squared, Adjusted R-Squared, MSE, and RMSE....</td>\n",
       "      <td id=\"T_fb002_row83_col3\" class=\"data row83 col3\" >validmind.model_validation.statsmodels.RegressionModelSummary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row84_col0\" class=\"data row84 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row84_col1\" class=\"data row84 col1\" >KPSS</td>\n",
       "      <td id=\"T_fb002_row84_col2\" class=\"data row84 col2\" >Executes KPSS unit root test to validate stationarity of time-series data in machine learning model....</td>\n",
       "      <td id=\"T_fb002_row84_col3\" class=\"data row84 col3\" >validmind.model_validation.statsmodels.KPSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row85_col0\" class=\"data row85 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row85_col1\" class=\"data row85 col1\" >Lilliefors</td>\n",
       "      <td id=\"T_fb002_row85_col2\" class=\"data row85 col2\" >Assesses the normality of feature distributions in an ML model's training dataset using the Lilliefors test....</td>\n",
       "      <td id=\"T_fb002_row85_col3\" class=\"data row85 col3\" >validmind.model_validation.statsmodels.Lilliefors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row86_col0\" class=\"data row86 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row86_col1\" class=\"data row86 col1\" >Logistic Reg Cumulative Prob</td>\n",
       "      <td id=\"T_fb002_row86_col2\" class=\"data row86 col2\" >Visualizes cumulative probabilities of positive and negative classes for both training and testing in logistic...</td>\n",
       "      <td id=\"T_fb002_row86_col3\" class=\"data row86 col3\" >validmind.model_validation.statsmodels.LogisticRegCumulativeProb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row87_col0\" class=\"data row87 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row87_col1\" class=\"data row87 col1\" >Runs Test</td>\n",
       "      <td id=\"T_fb002_row87_col2\" class=\"data row87 col2\" >Executes Runs Test on ML model to detect non-random patterns in output data sequence....</td>\n",
       "      <td id=\"T_fb002_row87_col3\" class=\"data row87 col3\" >validmind.model_validation.statsmodels.RunsTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row88_col0\" class=\"data row88 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row88_col1\" class=\"data row88 col1\" >Scorecard Probabilities Histogram</td>\n",
       "      <td id=\"T_fb002_row88_col2\" class=\"data row88 col2\" >Evaluates risk classification of a model by visualizing the distribution of default probability across score...</td>\n",
       "      <td id=\"T_fb002_row88_col3\" class=\"data row88 col3\" >validmind.model_validation.statsmodels.ScorecardProbabilitiesHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row89_col0\" class=\"data row89 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row89_col1\" class=\"data row89 col1\" >DFGLS Arch</td>\n",
       "      <td id=\"T_fb002_row89_col2\" class=\"data row89 col2\" >Executes Dickey-Fuller GLS metric to determine order of integration and check stationarity in time series data....</td>\n",
       "      <td id=\"T_fb002_row89_col3\" class=\"data row89 col3\" >validmind.model_validation.statsmodels.DFGLSArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row90_col0\" class=\"data row90 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row90_col1\" class=\"data row90 col1\" >Auto ARIMA</td>\n",
       "      <td id=\"T_fb002_row90_col2\" class=\"data row90 col2\" >Evaluates ARIMA models for time-series forecasting, ranking them using Bayesian and Akaike Information Criteria....</td>\n",
       "      <td id=\"T_fb002_row90_col3\" class=\"data row90 col3\" >validmind.model_validation.statsmodels.AutoARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row91_col0\" class=\"data row91 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row91_col1\" class=\"data row91 col1\" >ADF Test</td>\n",
       "      <td id=\"T_fb002_row91_col2\" class=\"data row91 col2\" >Assesses the stationarity of time series data using the Augmented Dickey-Fuller (ADF) test....</td>\n",
       "      <td id=\"T_fb002_row91_col3\" class=\"data row91 col3\" >validmind.model_validation.statsmodels.ADFTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row92_col0\" class=\"data row92 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row92_col1\" class=\"data row92 col1\" >GINI Table</td>\n",
       "      <td id=\"T_fb002_row92_col2\" class=\"data row92 col2\" >Evaluates classification model performance using AUC, GINI, and KS metrics for training and test datasets....</td>\n",
       "      <td id=\"T_fb002_row92_col3\" class=\"data row92 col3\" >validmind.model_validation.statsmodels.GINITable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row93_col0\" class=\"data row93 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row93_col1\" class=\"data row93 col1\" >Regression Model Forecast Plot</td>\n",
       "      <td id=\"T_fb002_row93_col2\" class=\"data row93 col2\" >Generates plots to visually compare the forecasted outcomes of one or more regression models against actual...</td>\n",
       "      <td id=\"T_fb002_row93_col3\" class=\"data row93 col3\" >validmind.model_validation.statsmodels.RegressionModelForecastPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row94_col0\" class=\"data row94 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row94_col1\" class=\"data row94 col1\" >ADF</td>\n",
       "      <td id=\"T_fb002_row94_col2\" class=\"data row94 col2\" >Assesses the stationarity of a time series dataset using the Augmented Dickey-Fuller (ADF) test....</td>\n",
       "      <td id=\"T_fb002_row94_col3\" class=\"data row94 col3\" >validmind.model_validation.statsmodels.ADF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row95_col0\" class=\"data row95 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row95_col1\" class=\"data row95 col1\" >Durbin Watson Test</td>\n",
       "      <td id=\"T_fb002_row95_col2\" class=\"data row95 col2\" >Assesses autocorrelation in time series data features using the Durbin-Watson statistic....</td>\n",
       "      <td id=\"T_fb002_row95_col3\" class=\"data row95 col3\" >validmind.model_validation.statsmodels.DurbinWatsonTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row96_col0\" class=\"data row96 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row96_col1\" class=\"data row96 col1\" >Missing Values Risk</td>\n",
       "      <td id=\"T_fb002_row96_col2\" class=\"data row96 col2\" >Assesses and quantifies the risk related to missing values in a dataset used for training an ML model....</td>\n",
       "      <td id=\"T_fb002_row96_col3\" class=\"data row96 col3\" >validmind.data_validation.MissingValuesRisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row97_col0\" class=\"data row97 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row97_col1\" class=\"data row97 col1\" >IQR Outliers Table</td>\n",
       "      <td id=\"T_fb002_row97_col2\" class=\"data row97 col2\" >Determines and summarizes outliers in numerical features using Interquartile Range method....</td>\n",
       "      <td id=\"T_fb002_row97_col3\" class=\"data row97 col3\" >validmind.data_validation.IQROutliersTable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row98_col0\" class=\"data row98 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row98_col1\" class=\"data row98 col1\" >Bivariate Features Bar Plots</td>\n",
       "      <td id=\"T_fb002_row98_col2\" class=\"data row98 col2\" >Generates visual bar plots to analyze the relationship between paired features within categorical data in the model....</td>\n",
       "      <td id=\"T_fb002_row98_col3\" class=\"data row98 col3\" >validmind.data_validation.BivariateFeaturesBarPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row99_col0\" class=\"data row99 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row99_col1\" class=\"data row99 col1\" >Skewness</td>\n",
       "      <td id=\"T_fb002_row99_col2\" class=\"data row99 col2\" >Evaluates the skewness of numerical data in a machine learning model and checks if it falls below a set maximum...</td>\n",
       "      <td id=\"T_fb002_row99_col3\" class=\"data row99 col3\" >validmind.data_validation.Skewness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row100_col0\" class=\"data row100 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row100_col1\" class=\"data row100 col1\" >Duplicates</td>\n",
       "      <td id=\"T_fb002_row100_col2\" class=\"data row100 col2\" >Tests dataset for duplicate entries, ensuring model reliability via data quality verification....</td>\n",
       "      <td id=\"T_fb002_row100_col3\" class=\"data row100 col3\" >validmind.data_validation.Duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row101_col0\" class=\"data row101 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row101_col1\" class=\"data row101 col1\" >Missing Values Bar Plot</td>\n",
       "      <td id=\"T_fb002_row101_col2\" class=\"data row101 col2\" >Creates a bar plot showcasing the percentage of missing values in each column of the dataset with risk...</td>\n",
       "      <td id=\"T_fb002_row101_col3\" class=\"data row101 col3\" >validmind.data_validation.MissingValuesBarPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row102_col0\" class=\"data row102 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row102_col1\" class=\"data row102 col1\" >Dataset Description</td>\n",
       "      <td id=\"T_fb002_row102_col2\" class=\"data row102 col2\" >Provides comprehensive analysis and statistical summaries of each field in a machine learning model's dataset....</td>\n",
       "      <td id=\"T_fb002_row102_col3\" class=\"data row102 col3\" >validmind.data_validation.DatasetDescription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row103_col0\" class=\"data row103 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row103_col1\" class=\"data row103 col1\" >Scatter Plot</td>\n",
       "      <td id=\"T_fb002_row103_col2\" class=\"data row103 col2\" >Creates a scatter plot matrix to visually analyze feature relationships, patterns, and outliers in a dataset....</td>\n",
       "      <td id=\"T_fb002_row103_col3\" class=\"data row103 col3\" >validmind.data_validation.ScatterPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row104_col0\" class=\"data row104 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row104_col1\" class=\"data row104 col1\" >Time Series Outliers</td>\n",
       "      <td id=\"T_fb002_row104_col2\" class=\"data row104 col2\" >Identifies and visualizes outliers in time-series data using z-score method....</td>\n",
       "      <td id=\"T_fb002_row104_col3\" class=\"data row104 col3\" >validmind.data_validation.TimeSeriesOutliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row105_col0\" class=\"data row105 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row105_col1\" class=\"data row105 col1\" >Tabular Categorical Bar Plots</td>\n",
       "      <td id=\"T_fb002_row105_col2\" class=\"data row105 col2\" >Generates and visualizes bar plots for each category in categorical features to evaluate dataset's composition....</td>\n",
       "      <td id=\"T_fb002_row105_col3\" class=\"data row105 col3\" >validmind.data_validation.TabularCategoricalBarPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row106_col0\" class=\"data row106 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row106_col1\" class=\"data row106 col1\" >Auto Stationarity</td>\n",
       "      <td id=\"T_fb002_row106_col2\" class=\"data row106 col2\" >Automates Augmented Dickey-Fuller test to assess stationarity across multiple time series in a DataFrame....</td>\n",
       "      <td id=\"T_fb002_row106_col3\" class=\"data row106 col3\" >validmind.data_validation.AutoStationarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row107_col0\" class=\"data row107 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row107_col1\" class=\"data row107 col1\" >Descriptive Statistics</td>\n",
       "      <td id=\"T_fb002_row107_col2\" class=\"data row107 col2\" >Performs a detailed descriptive statistical analysis of both numerical and categorical data within a model's...</td>\n",
       "      <td id=\"T_fb002_row107_col3\" class=\"data row107 col3\" >validmind.data_validation.DescriptiveStatistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row108_col0\" class=\"data row108 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row108_col1\" class=\"data row108 col1\" >ANOVA One Way Table</td>\n",
       "      <td id=\"T_fb002_row108_col2\" class=\"data row108 col2\" >Applies one-way ANOVA (Analysis of Variance) to identify statistically significant numerical features in the...</td>\n",
       "      <td id=\"T_fb002_row108_col3\" class=\"data row108 col3\" >validmind.data_validation.ANOVAOneWayTable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row109_col0\" class=\"data row109 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row109_col1\" class=\"data row109 col1\" >Target Rate Bar Plots</td>\n",
       "      <td id=\"T_fb002_row109_col2\" class=\"data row109 col2\" >Generates bar plots visualizing the default rates of categorical features for a classification machine learning...</td>\n",
       "      <td id=\"T_fb002_row109_col3\" class=\"data row109 col3\" >validmind.data_validation.TargetRateBarPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row110_col0\" class=\"data row110 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row110_col1\" class=\"data row110 col1\" >Pearson Correlation Matrix</td>\n",
       "      <td id=\"T_fb002_row110_col2\" class=\"data row110 col2\" >Evaluates linear dependency between numerical variables in a dataset via a Pearson Correlation coefficient heat map....</td>\n",
       "      <td id=\"T_fb002_row110_col3\" class=\"data row110 col3\" >validmind.data_validation.PearsonCorrelationMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row111_col0\" class=\"data row111 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row111_col1\" class=\"data row111 col1\" >Feature Target Correlation Plot</td>\n",
       "      <td id=\"T_fb002_row111_col2\" class=\"data row111 col2\" >Visualizes the correlation between input features and model's target output in a color-coded horizontal bar plot....</td>\n",
       "      <td id=\"T_fb002_row111_col3\" class=\"data row111 col3\" >validmind.data_validation.FeatureTargetCorrelationPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row112_col0\" class=\"data row112 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row112_col1\" class=\"data row112 col1\" >Tabular Numerical Histograms</td>\n",
       "      <td id=\"T_fb002_row112_col2\" class=\"data row112 col2\" >Generates histograms for each numerical feature in a dataset to provide visual insights into data distribution and...</td>\n",
       "      <td id=\"T_fb002_row112_col3\" class=\"data row112 col3\" >validmind.data_validation.TabularNumericalHistograms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row113_col0\" class=\"data row113 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row113_col1\" class=\"data row113 col1\" >Isolation Forest Outliers</td>\n",
       "      <td id=\"T_fb002_row113_col2\" class=\"data row113 col2\" >Detects outliers in a dataset using the Isolation Forest algorithm and visualizes results through scatter plots....</td>\n",
       "      <td id=\"T_fb002_row113_col3\" class=\"data row113 col3\" >validmind.data_validation.IsolationForestOutliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row114_col0\" class=\"data row114 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row114_col1\" class=\"data row114 col1\" >Chi Squared Features Table</td>\n",
       "      <td id=\"T_fb002_row114_col2\" class=\"data row114 col2\" >Executes Chi-Squared test for each categorical feature against a target column to assess significant association....</td>\n",
       "      <td id=\"T_fb002_row114_col3\" class=\"data row114 col3\" >validmind.data_validation.ChiSquaredFeaturesTable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row115_col0\" class=\"data row115 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row115_col1\" class=\"data row115 col1\" >High Cardinality</td>\n",
       "      <td id=\"T_fb002_row115_col2\" class=\"data row115 col2\" >Assesses the number of unique values in categorical columns to detect high cardinality and potential overfitting....</td>\n",
       "      <td id=\"T_fb002_row115_col3\" class=\"data row115 col3\" >validmind.data_validation.HighCardinality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row116_col0\" class=\"data row116 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row116_col1\" class=\"data row116 col1\" >Missing Values</td>\n",
       "      <td id=\"T_fb002_row116_col2\" class=\"data row116 col2\" >Evaluates dataset quality by ensuring missing value ratio across all features does not exceed a set threshold....</td>\n",
       "      <td id=\"T_fb002_row116_col3\" class=\"data row116 col3\" >validmind.data_validation.MissingValues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row117_col0\" class=\"data row117 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row117_col1\" class=\"data row117 col1\" >Default Ratesby Risk Band Plot</td>\n",
       "      <td id=\"T_fb002_row117_col2\" class=\"data row117 col2\" >Generates a bar plot showcasing the distribution of default rates across different risk bands in a dataset....</td>\n",
       "      <td id=\"T_fb002_row117_col3\" class=\"data row117 col3\" >validmind.data_validation.DefaultRatesbyRiskBandPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row118_col0\" class=\"data row118 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row118_col1\" class=\"data row118 col1\" >Rolling Stats Plot</td>\n",
       "      <td id=\"T_fb002_row118_col2\" class=\"data row118 col2\" >This test evaluates the stationarity of time series data by plotting its rolling mean and standard deviation....</td>\n",
       "      <td id=\"T_fb002_row118_col3\" class=\"data row118 col3\" >validmind.data_validation.RollingStatsPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row119_col0\" class=\"data row119 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row119_col1\" class=\"data row119 col1\" >Tabular Description Tables</td>\n",
       "      <td id=\"T_fb002_row119_col2\" class=\"data row119 col2\" >Summarizes key descriptive statistics for numerical, categorical, and datetime variables in a dataset....</td>\n",
       "      <td id=\"T_fb002_row119_col3\" class=\"data row119 col3\" >validmind.data_validation.TabularDescriptionTables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row120_col0\" class=\"data row120 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row120_col1\" class=\"data row120 col1\" >Auto MA</td>\n",
       "      <td id=\"T_fb002_row120_col2\" class=\"data row120 col2\" >Automatically selects the optimal Moving Average (MA) order for each variable in a time series dataset based on...</td>\n",
       "      <td id=\"T_fb002_row120_col3\" class=\"data row120 col3\" >validmind.data_validation.AutoMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row121_col0\" class=\"data row121 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row121_col1\" class=\"data row121 col1\" >Unique Rows</td>\n",
       "      <td id=\"T_fb002_row121_col2\" class=\"data row121 col2\" >Verifies the diversity of the dataset by ensuring that the count of unique rows exceeds a prescribed threshold....</td>\n",
       "      <td id=\"T_fb002_row121_col3\" class=\"data row121 col3\" >validmind.data_validation.UniqueRows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row122_col0\" class=\"data row122 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row122_col1\" class=\"data row122 col1\" >Too Many Zero Values</td>\n",
       "      <td id=\"T_fb002_row122_col2\" class=\"data row122 col2\" >Identifies numerical columns in a dataset that contain an excessive number of zero values, defined by a threshold...</td>\n",
       "      <td id=\"T_fb002_row122_col3\" class=\"data row122 col3\" >validmind.data_validation.TooManyZeroValues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row123_col0\" class=\"data row123 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row123_col1\" class=\"data row123 col1\" >High Pearson Correlation</td>\n",
       "      <td id=\"T_fb002_row123_col2\" class=\"data row123 col2\" >Identifies highly correlated feature pairs in a dataset suggesting feature redundancy or multicollinearity....</td>\n",
       "      <td id=\"T_fb002_row123_col3\" class=\"data row123 col3\" >validmind.data_validation.HighPearsonCorrelation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row124_col0\" class=\"data row124 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row124_col1\" class=\"data row124 col1\" >AC Fand PACF Plot</td>\n",
       "      <td id=\"T_fb002_row124_col2\" class=\"data row124 col2\" >Analyzes time series data using Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots to...</td>\n",
       "      <td id=\"T_fb002_row124_col3\" class=\"data row124 col3\" >validmind.data_validation.ACFandPACFPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row125_col0\" class=\"data row125 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row125_col1\" class=\"data row125 col1\" >Bivariate Histograms</td>\n",
       "      <td id=\"T_fb002_row125_col2\" class=\"data row125 col2\" >Generates bivariate histograms for paired features, aiding in visual inspection of categorical variables'...</td>\n",
       "      <td id=\"T_fb002_row125_col3\" class=\"data row125 col3\" >validmind.data_validation.BivariateHistograms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row126_col0\" class=\"data row126 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row126_col1\" class=\"data row126 col1\" >WOE Bin Table</td>\n",
       "      <td id=\"T_fb002_row126_col2\" class=\"data row126 col2\" >Calculates and assesses the Weight of Evidence (WoE) and Information Value (IV) of each feature in a ML model....</td>\n",
       "      <td id=\"T_fb002_row126_col3\" class=\"data row126 col3\" >validmind.data_validation.WOEBinTable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row127_col0\" class=\"data row127 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row127_col1\" class=\"data row127 col1\" >Heatmap Feature Correlations</td>\n",
       "      <td id=\"T_fb002_row127_col2\" class=\"data row127 col2\" >Creates a heatmap to visually represent correlation patterns between pairs of numerical features in a dataset....</td>\n",
       "      <td id=\"T_fb002_row127_col3\" class=\"data row127 col3\" >validmind.data_validation.HeatmapFeatureCorrelations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row128_col0\" class=\"data row128 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row128_col1\" class=\"data row128 col1\" >Time Series Frequency</td>\n",
       "      <td id=\"T_fb002_row128_col2\" class=\"data row128 col2\" >Evaluates consistency of time series data frequency and generates a frequency plot....</td>\n",
       "      <td id=\"T_fb002_row128_col3\" class=\"data row128 col3\" >validmind.data_validation.TimeSeriesFrequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row129_col0\" class=\"data row129 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row129_col1\" class=\"data row129 col1\" >Dataset Split</td>\n",
       "      <td id=\"T_fb002_row129_col2\" class=\"data row129 col2\" >Evaluates and visualizes the distribution proportions among training, testing, and validation datasets of an ML...</td>\n",
       "      <td id=\"T_fb002_row129_col3\" class=\"data row129 col3\" >validmind.data_validation.DatasetSplit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row130_col0\" class=\"data row130 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row130_col1\" class=\"data row130 col1\" >Spread Plot</td>\n",
       "      <td id=\"T_fb002_row130_col2\" class=\"data row130 col2\" >Visualizes the spread relationship between pairs of time-series variables in a dataset, thereby aiding in...</td>\n",
       "      <td id=\"T_fb002_row130_col3\" class=\"data row130 col3\" >validmind.data_validation.SpreadPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row131_col0\" class=\"data row131 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row131_col1\" class=\"data row131 col1\" >Time Series Line Plot</td>\n",
       "      <td id=\"T_fb002_row131_col2\" class=\"data row131 col2\" >Generates and analyses time-series data through line plots revealing trends, patterns, anomalies over time....</td>\n",
       "      <td id=\"T_fb002_row131_col3\" class=\"data row131 col3\" >validmind.data_validation.TimeSeriesLinePlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row132_col0\" class=\"data row132 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row132_col1\" class=\"data row132 col1\" >Pi T Credit Scores Histogram</td>\n",
       "      <td id=\"T_fb002_row132_col2\" class=\"data row132 col2\" >Generates a histogram visualization for observed and predicted credit default scores....</td>\n",
       "      <td id=\"T_fb002_row132_col3\" class=\"data row132 col3\" >validmind.data_validation.PiTCreditScoresHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row133_col0\" class=\"data row133 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row133_col1\" class=\"data row133 col1\" >Auto Seasonality</td>\n",
       "      <td id=\"T_fb002_row133_col2\" class=\"data row133 col2\" >Automatically identifies and quantifies optimal seasonality in time series data to improve forecasting model...</td>\n",
       "      <td id=\"T_fb002_row133_col3\" class=\"data row133 col3\" >validmind.data_validation.AutoSeasonality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row134_col0\" class=\"data row134 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row134_col1\" class=\"data row134 col1\" >Bivariate Scatter Plots</td>\n",
       "      <td id=\"T_fb002_row134_col2\" class=\"data row134 col2\" >Generates bivariate scatterplots to visually inspect relationships between pairs of predictor variables in machine...</td>\n",
       "      <td id=\"T_fb002_row134_col3\" class=\"data row134 col3\" >validmind.data_validation.BivariateScatterPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row135_col0\" class=\"data row135 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row135_col1\" class=\"data row135 col1\" >Engle Granger Coint</td>\n",
       "      <td id=\"T_fb002_row135_col2\" class=\"data row135 col2\" >Validates co-integration in pairs of time series data using the Engle-Granger test and classifies them as...</td>\n",
       "      <td id=\"T_fb002_row135_col3\" class=\"data row135 col3\" >validmind.data_validation.EngleGrangerCoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row136_col0\" class=\"data row136 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row136_col1\" class=\"data row136 col1\" >Time Series Missing Values</td>\n",
       "      <td id=\"T_fb002_row136_col2\" class=\"data row136 col2\" >Validates time-series data quality by confirming the count of missing values is below a certain threshold....</td>\n",
       "      <td id=\"T_fb002_row136_col3\" class=\"data row136 col3\" >validmind.data_validation.TimeSeriesMissingValues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row137_col0\" class=\"data row137 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row137_col1\" class=\"data row137 col1\" >Time Series Histogram</td>\n",
       "      <td id=\"T_fb002_row137_col2\" class=\"data row137 col2\" >Visualizes distribution of time-series data using histograms and Kernel Density Estimation (KDE) lines....</td>\n",
       "      <td id=\"T_fb002_row137_col3\" class=\"data row137 col3\" >validmind.data_validation.TimeSeriesHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row138_col0\" class=\"data row138 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row138_col1\" class=\"data row138 col1\" >Lagged Correlation Heatmap</td>\n",
       "      <td id=\"T_fb002_row138_col2\" class=\"data row138 col2\" >Assesses and visualizes correlation between target variable and lagged independent variables in a time-series...</td>\n",
       "      <td id=\"T_fb002_row138_col3\" class=\"data row138 col3\" >validmind.data_validation.LaggedCorrelationHeatmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row139_col0\" class=\"data row139 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row139_col1\" class=\"data row139 col1\" >Seasonal Decompose</td>\n",
       "      <td id=\"T_fb002_row139_col2\" class=\"data row139 col2\" >Decomposes dataset features into observed, trend, seasonal, and residual components to identify patterns and...</td>\n",
       "      <td id=\"T_fb002_row139_col3\" class=\"data row139 col3\" >validmind.data_validation.SeasonalDecompose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row140_col0\" class=\"data row140 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row140_col1\" class=\"data row140 col1\" >WOE Bin Plots</td>\n",
       "      <td id=\"T_fb002_row140_col2\" class=\"data row140 col2\" >Generates visualizations of Weight of Evidence (WoE) and Information Value (IV) for understanding predictive power...</td>\n",
       "      <td id=\"T_fb002_row140_col3\" class=\"data row140 col3\" >validmind.data_validation.WOEBinPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row141_col0\" class=\"data row141 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row141_col1\" class=\"data row141 col1\" >Class Imbalance</td>\n",
       "      <td id=\"T_fb002_row141_col2\" class=\"data row141 col2\" >Evaluates and quantifies class distribution imbalance in a dataset used by a machine learning model....</td>\n",
       "      <td id=\"T_fb002_row141_col3\" class=\"data row141 col3\" >validmind.data_validation.ClassImbalance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row142_col0\" class=\"data row142 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row142_col1\" class=\"data row142 col1\" >IQR Outliers Bar Plot</td>\n",
       "      <td id=\"T_fb002_row142_col2\" class=\"data row142 col2\" >Visualizes outlier distribution across percentiles in numerical data using Interquartile Range (IQR) method....</td>\n",
       "      <td id=\"T_fb002_row142_col3\" class=\"data row142 col3\" >validmind.data_validation.IQROutliersBarPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row143_col0\" class=\"data row143 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row143_col1\" class=\"data row143 col1\" >Pi TPD Histogram</td>\n",
       "      <td id=\"T_fb002_row143_col2\" class=\"data row143 col2\" >Assesses credit risk prediction accuracy of a model by comparing actual and predicted defaults at a chosen point in...</td>\n",
       "      <td id=\"T_fb002_row143_col3\" class=\"data row143 col3\" >validmind.data_validation.PiTPDHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row144_col0\" class=\"data row144 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row144_col1\" class=\"data row144 col1\" >Auto AR</td>\n",
       "      <td id=\"T_fb002_row144_col2\" class=\"data row144 col2\" >Automatically identifies the optimal Autoregressive (AR) order for a time series using BIC and AIC criteria....</td>\n",
       "      <td id=\"T_fb002_row144_col3\" class=\"data row144 col3\" >validmind.data_validation.AutoAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row145_col0\" class=\"data row145 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row145_col1\" class=\"data row145 col1\" >Tabular Date Time Histograms</td>\n",
       "      <td id=\"T_fb002_row145_col2\" class=\"data row145 col2\" >Generates histograms to provide graphical insight into the distribution of time intervals in model's datetime data....</td>\n",
       "      <td id=\"T_fb002_row145_col3\" class=\"data row145 col3\" >validmind.data_validation.TabularDateTimeHistograms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row146_col0\" class=\"data row146 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row146_col1\" class=\"data row146 col1\" >Punctuations</td>\n",
       "      <td id=\"T_fb002_row146_col2\" class=\"data row146 col2\" >Analyzes and visualizes the frequency distribution of punctuation usage in a given text dataset....</td>\n",
       "      <td id=\"T_fb002_row146_col3\" class=\"data row146 col3\" >validmind.data_validation.nlp.Punctuations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row147_col0\" class=\"data row147 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row147_col1\" class=\"data row147 col1\" >Common Words</td>\n",
       "      <td id=\"T_fb002_row147_col2\" class=\"data row147 col2\" >Identifies and visualizes the 40 most frequent non-stopwords in a specified text column within a dataset....</td>\n",
       "      <td id=\"T_fb002_row147_col3\" class=\"data row147 col3\" >validmind.data_validation.nlp.CommonWords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row148_col0\" class=\"data row148 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row148_col1\" class=\"data row148 col1\" >Hashtags</td>\n",
       "      <td id=\"T_fb002_row148_col2\" class=\"data row148 col2\" >Assesses hashtag frequency in a text column, highlighting usage trends and potential dataset bias or spam....</td>\n",
       "      <td id=\"T_fb002_row148_col3\" class=\"data row148 col3\" >validmind.data_validation.nlp.Hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row149_col0\" class=\"data row149 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row149_col1\" class=\"data row149 col1\" >Mentions</td>\n",
       "      <td id=\"T_fb002_row149_col2\" class=\"data row149 col2\" >Calculates and visualizes frequencies of '@' prefixed mentions in a text-based dataset for NLP model analysis....</td>\n",
       "      <td id=\"T_fb002_row149_col3\" class=\"data row149 col3\" >validmind.data_validation.nlp.Mentions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row150_col0\" class=\"data row150 col0\" >Metric</td>\n",
       "      <td id=\"T_fb002_row150_col1\" class=\"data row150 col1\" >Text Description</td>\n",
       "      <td id=\"T_fb002_row150_col2\" class=\"data row150 col2\" >Performs comprehensive textual analysis on a dataset using NLTK, evaluating various parameters and generating...</td>\n",
       "      <td id=\"T_fb002_row150_col3\" class=\"data row150 col3\" >validmind.data_validation.nlp.TextDescription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_fb002_row151_col0\" class=\"data row151 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_fb002_row151_col1\" class=\"data row151 col1\" >Stop Words</td>\n",
       "      <td id=\"T_fb002_row151_col2\" class=\"data row151 col2\" >Evaluates and visualizes the frequency of English stop words in a text dataset against a defined threshold....</td>\n",
       "      <td id=\"T_fb002_row151_col3\" class=\"data row151 col3\" >validmind.data_validation.nlp.StopWords</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10665f550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.tests.list_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start the model development process with raw data and run out-of-the box tests and add evidence to model documentation\n",
    "\n",
    "In this section we will provide details on how to understand individual tests available in ValidMind, how you can access each test, run it and change parameters if necessary. You will be using an example dataset provided by ValidMind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from validmind.datasets.classification import customer_churn as demo_dataset\n",
    "\n",
    "df_raw = demo_dataset.load_data()\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some data quality assessments by running a few individual tests related to data assessment. You will be using the `vm.tests.list_tests()` function above in combination with `vm.tests.list_tags()` and `vm.tests.list_task_types()` to find which prebuilt tests are relevant for data quality assessment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anomaly_detection',\n",
       " 'binary_classification',\n",
       " 'categorical_data',\n",
       " 'correlation',\n",
       " 'credit_risk',\n",
       " 'data_distribution',\n",
       " 'data_quality',\n",
       " 'feature_importance',\n",
       " 'few_shot',\n",
       " 'forecasting',\n",
       " 'frequency_analysis',\n",
       " 'kmeans',\n",
       " 'llm',\n",
       " 'logistic_regression',\n",
       " 'model_comparison',\n",
       " 'model_diagnosis',\n",
       " 'model_interpretation',\n",
       " 'model_metadata',\n",
       " 'model_performance',\n",
       " 'model_selection',\n",
       " 'multiclass_classification',\n",
       " 'nlp',\n",
       " 'numerical_data',\n",
       " 'regard_histogram',\n",
       " 'regard_score',\n",
       " 'risk_analysis',\n",
       " 'seasonality',\n",
       " 'senstivity_analysis',\n",
       " 'sklearn',\n",
       " 'stationarity',\n",
       " 'statistical_test',\n",
       " 'statsmodels',\n",
       " 'tabular_data',\n",
       " 'text_data',\n",
       " 'text_embeddings',\n",
       " 'time_series_data',\n",
       " 'toxicity_histogram',\n",
       " 'toxicity_line_plot',\n",
       " 'unit_root_test',\n",
       " 'visualization',\n",
       " 'zero_shot']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of available tags\n",
    "sorted(vm.tests.list_tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classification',\n",
       " 'clustering',\n",
       " 'feature_extraction',\n",
       " 'regression',\n",
       " 'text_classification',\n",
       " 'text_summarization']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of available task types\n",
    "sorted(vm.tests.list_task_types())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass `tags` and `task_types` as parameters to the `vm.tests.list_tests()` function to filter the tests based on the tags and task types. For example, to find tests related to tabular data quality for classification models, you can call `list_tests()` like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5b849 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5b849_row0_col0, #T_5b849_row0_col1, #T_5b849_row0_col2, #T_5b849_row0_col3, #T_5b849_row1_col0, #T_5b849_row1_col1, #T_5b849_row1_col2, #T_5b849_row1_col3, #T_5b849_row2_col0, #T_5b849_row2_col1, #T_5b849_row2_col2, #T_5b849_row2_col3, #T_5b849_row3_col0, #T_5b849_row3_col1, #T_5b849_row3_col2, #T_5b849_row3_col3, #T_5b849_row4_col0, #T_5b849_row4_col1, #T_5b849_row4_col2, #T_5b849_row4_col3, #T_5b849_row5_col0, #T_5b849_row5_col1, #T_5b849_row5_col2, #T_5b849_row5_col3, #T_5b849_row6_col0, #T_5b849_row6_col1, #T_5b849_row6_col2, #T_5b849_row6_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5b849\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5b849_level0_col0\" class=\"col_heading level0 col0\" >Test Type</th>\n",
       "      <th id=\"T_5b849_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_5b849_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_5b849_level0_col3\" class=\"col_heading level0 col3\" >ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5b849_row0_col0\" class=\"data row0 col0\" >Metric</td>\n",
       "      <td id=\"T_5b849_row0_col1\" class=\"data row0 col1\" >Missing Values Risk</td>\n",
       "      <td id=\"T_5b849_row0_col2\" class=\"data row0 col2\" >Assesses and quantifies the risk related to missing values in a dataset used for training an ML model....</td>\n",
       "      <td id=\"T_5b849_row0_col3\" class=\"data row0 col3\" >validmind.data_validation.MissingValuesRisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b849_row1_col0\" class=\"data row1 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_5b849_row1_col1\" class=\"data row1 col1\" >Skewness</td>\n",
       "      <td id=\"T_5b849_row1_col2\" class=\"data row1 col2\" >Evaluates the skewness of numerical data in a machine learning model and checks if it falls below a set maximum...</td>\n",
       "      <td id=\"T_5b849_row1_col3\" class=\"data row1 col3\" >validmind.data_validation.Skewness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b849_row2_col0\" class=\"data row2 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_5b849_row2_col1\" class=\"data row2 col1\" >Duplicates</td>\n",
       "      <td id=\"T_5b849_row2_col2\" class=\"data row2 col2\" >Tests dataset for duplicate entries, ensuring model reliability via data quality verification....</td>\n",
       "      <td id=\"T_5b849_row2_col3\" class=\"data row2 col3\" >validmind.data_validation.Duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b849_row3_col0\" class=\"data row3 col0\" >Metric</td>\n",
       "      <td id=\"T_5b849_row3_col1\" class=\"data row3 col1\" >Missing Values Bar Plot</td>\n",
       "      <td id=\"T_5b849_row3_col2\" class=\"data row3 col2\" >Creates a bar plot showcasing the percentage of missing values in each column of the dataset with risk...</td>\n",
       "      <td id=\"T_5b849_row3_col3\" class=\"data row3 col3\" >validmind.data_validation.MissingValuesBarPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b849_row4_col0\" class=\"data row4 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_5b849_row4_col1\" class=\"data row4 col1\" >High Cardinality</td>\n",
       "      <td id=\"T_5b849_row4_col2\" class=\"data row4 col2\" >Assesses the number of unique values in categorical columns to detect high cardinality and potential overfitting....</td>\n",
       "      <td id=\"T_5b849_row4_col3\" class=\"data row4 col3\" >validmind.data_validation.HighCardinality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b849_row5_col0\" class=\"data row5 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_5b849_row5_col1\" class=\"data row5 col1\" >Missing Values</td>\n",
       "      <td id=\"T_5b849_row5_col2\" class=\"data row5 col2\" >Evaluates dataset quality by ensuring missing value ratio across all features does not exceed a set threshold....</td>\n",
       "      <td id=\"T_5b849_row5_col3\" class=\"data row5 col3\" >validmind.data_validation.MissingValues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b849_row6_col0\" class=\"data row6 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_5b849_row6_col1\" class=\"data row6 col1\" >High Pearson Correlation</td>\n",
       "      <td id=\"T_5b849_row6_col2\" class=\"data row6 col2\" >Identifies highly correlated feature pairs in a dataset suggesting feature redundancy or multicollinearity....</td>\n",
       "      <td id=\"T_5b849_row6_col3\" class=\"data row6 col3\" >validmind.data_validation.HighPearsonCorrelation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x381bc71f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.tests.list_tests(task=\"classification\", tags=[\"tabular_data\", \"data_quality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the ValidMind datasets\n",
    "\n",
    "Now we assume we have identified some tests we want to run with regards to the data we are intending to use. The next step is to connect your data with a ValidMind dataset object. This step is always necessary every time you want to connect a dataset to documentation and produce tests through ValidMind. You only need to do it one time per dataset.\n",
    "\n",
    "You can initialize a ValidMind dataset object using the [`init_dataset`](https://docs.validmind.ai/validmind/validmind.html#init_dataset) function from the ValidMind (`vm`) module.\n",
    "\n",
    "This function takes a number of arguments:\n",
    "\n",
    "- `dataset` — the raw dataset that you want to provide as input to tests\n",
    "- `input_id` - a unique identifier that allows tracking what inputs are used when running each individual test\n",
    "- `target_column` — a required argument if tests require access to true values. This is the name of the target column in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 17:44:35,072 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n"
     ]
    }
   ],
   "source": [
    "# vm_raw_dataset is now a VMDataset object that you can pass to any ValidMind test\n",
    "vm_raw_dataset = vm.init_dataset(\n",
    "    dataset=df_raw,\n",
    "    input_id=\"raw_dataset\",\n",
    "    target_column=\"Exited\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run some tabular data tests\n",
    "\n",
    "Individual tests can be easily run by calling the `run_test` function provided by the `validmind.tests` module. The function takes the following arguments:\n",
    "\n",
    "- `test_id`: The ID of the test to run. To find a particular test and get its ID, refer to the [explore_tests](../how_to/explore_tests.ipynb) notebook. Look above for example after running 'vm.test_suites.describe_suite' as column 'Test ID' will contain the id.\n",
    "- `params`: A dictionary of parameters for the test. These will override any `default_params` set in the test definition. Refer to the [explore_tests](../how_to/explore_tests.ipynb) notebook to find the default parameters for a test. See below for examples.\n",
    "\n",
    "The inputs expected by a test can also be found in the test definition. Let's take `validmind.data_validation.DescriptiveStatistics` as an example. Note that the output of the `describe_test()` function below shows that this test expects a `dataset` as input:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b40223d557498db16f8c251508236a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<div>\\n  <h2>Descriptive Statistics</h2>\\n  <p>Performs a detailed descriptive statistical analy…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vm.tests.describe_test(\"validmind.data_validation.DescriptiveStatistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run a few tests to assess the quality of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f62b149c8f4bae93bc91724d5cda15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1>Descriptive Statistics</h1>'), HTML(value=\"<p>Performs a detailed descriptive s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = vm.tests.run_test(\n",
    "    test_id=\"validmind.data_validation.DescriptiveStatistics\",\n",
    "    inputs={\"dataset\": vm_raw_dataset},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e33ef52b0494abda4bc5ee2cb39111a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h1>Class Imbalance ❌</h1>\\n            <p>Evaluates and quantifies c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test2 = vm.tests.run_test(\n",
    "    test_id=\"validmind.data_validation.ClassImbalance\",\n",
    "    inputs={\"dataset\": vm_raw_dataset},\n",
    "    params={\"min_percent_threshold\": 30},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the class imbalance test did not pass accordig to the value of `min_percent_threshold` we have set. Here is how you can re-run the test on some processed data to address this data quality issue. In this case we apply a very simple rebalance technique to the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_raw_new = df_raw.sample(frac=1)  # Create a copy of the raw dataset\n",
    "\n",
    "# Create a balanced dataset with the same number of exited and not exited customers\n",
    "exited_df = df_raw_new.loc[df_raw_new[\"Exited\"] == 1]\n",
    "not_exited_df = df_raw_new.loc[df_raw_new[\"Exited\"] == 0].sample(n=exited_df.shape[0])\n",
    "\n",
    "new_df = pd.concat([exited_df, not_exited_df])\n",
    "new_df_raw = new_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new raw dataset you can re-run the individual test to see if it passes the class imbalance test requirement. Remember to register new VM dataset object since that is the type of input required by `run_test()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 17:44:35,781 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n"
     ]
    }
   ],
   "source": [
    "# Register new data and now 'vm_raw_dataset_new' is the new dataset object of interest\n",
    "vm_raw_dataset_new = vm.init_dataset(\n",
    "    dataset=new_df_raw,\n",
    "    input_id=\"new_df_raw\",\n",
    "    target_column=\"Exited\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e09471f23984e89ad863ad92c29da87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h1>Class Imbalance ✅</h1>\\n            <p>Evaluates and quantifies c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = vm.tests.run_test(\n",
    "    test_id=\"validmind.data_validation.ClassImbalance\",\n",
    "    inputs={\"dataset\": vm_raw_dataset_new},\n",
    "    params={\"min_percent_threshold\": 30},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize Test Output\n",
    "\n",
    "Below is an example on how you can utilize the output from a ValidMind test for futher use, for example, if you want to remove highly correlated features then the below shows how you can get a pearson's correlation matrix, use the output to reduce the feature list for modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83a4c3db151455ea59862959eb3bc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h1>High Pearson Correlation ❌</h1>\\n            <p>Identifies highly…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_results = vm.tests.run_test(\n",
    "    test_id=\"validmind.data_validation.HighPearsonCorrelation\",\n",
    "    params={\"max_threshold\": 0.3},\n",
    "    inputs={\"dataset\": vm_raw_dataset_new},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we want to remove highly correlated features from the dataset. `corr_results` is an object of type `ThresholdTestResult` and we can inspects its individual `results` to get access to the features that failed the test. In general, all ValidMind tests can return two different types of results:\n",
    "\n",
    "- [MetricResult](https://docs.validmind.ai/validmind/validmind/vm_models.html#MetricResult): most metrics return this type of result\n",
    "- [ThresholdTestResult](https://docs.validmind.ai/validmind/validmind/vm_models.html#ThresholdTest): metrics that compare a metric to a threshold return this type of result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThresholdTestResults(test_name='validmind.data_validation.HighPearsonCorrelation', ref_id='87207a93-6793-4cbd-8748-75906217c61a', params={'max_threshold': 0.3}, passed=False, results=[ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.3482965246830813}]}, test_name=None, column='Age', passed=False), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.17604797085379387}]}, test_name=None, column='Balance', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'IsActiveMember', 'correlation': -0.16782323772864946}]}, test_name=None, column='Exited', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.1449288023288548}]}, test_name=None, column='Balance', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.05855318704540857}]}, test_name=None, column='Exited', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'Tenure', 'correlation': 0.04177732330989858}]}, test_name=None, column='EstimatedSalary', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'EstimatedSalary', 'correlation': -0.03970402896113289}]}, test_name=None, column='CreditScore', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': 0.036344324015295595}]}, test_name=None, column='IsActiveMember', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'IsActiveMember', 'correlation': -0.03311632526716834}]}, test_name=None, column='HasCrCard', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.030543086117390872}]}, test_name=None, column='Age', passed=True)], summary=ResultSummary(results=[ResultTable(data=[{'Columns': '(Age, Exited)', 'Coefficient': 0.3482965246830813, 'Pass/Fail': 'Fail'}, {'Columns': '(Balance, NumOfProducts)', 'Coefficient': -0.17604797085379387, 'Pass/Fail': 'Pass'}, {'Columns': '(Exited, IsActiveMember)', 'Coefficient': -0.16782323772864946, 'Pass/Fail': 'Pass'}, {'Columns': '(Balance, Exited)', 'Coefficient': 0.1449288023288548, 'Pass/Fail': 'Pass'}, {'Columns': '(Exited, NumOfProducts)', 'Coefficient': -0.05855318704540857, 'Pass/Fail': 'Pass'}, {'Columns': '(EstimatedSalary, Tenure)', 'Coefficient': 0.04177732330989858, 'Pass/Fail': 'Pass'}, {'Columns': '(CreditScore, EstimatedSalary)', 'Coefficient': -0.03970402896113289, 'Pass/Fail': 'Pass'}, {'Columns': '(IsActiveMember, NumOfProducts)', 'Coefficient': 0.036344324015295595, 'Pass/Fail': 'Pass'}, {'Columns': '(HasCrCard, IsActiveMember)', 'Coefficient': -0.03311632526716834, 'Pass/Fail': 'Pass'}, {'Columns': '(Age, NumOfProducts)', 'Coefficient': -0.030543086117390872, 'Pass/Fail': 'Pass'}], type='table', metadata=ResultTableMetadata(title='High Pearson Correlation Results for Dataset'))]))\n",
      "test_name:  validmind.data_validation.HighPearsonCorrelation\n",
      "params:  {'max_threshold': 0.3}\n",
      "passed:  False\n",
      "results:  [ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.3482965246830813}]}, test_name=None, column='Age', passed=False), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.17604797085379387}]}, test_name=None, column='Balance', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'IsActiveMember', 'correlation': -0.16782323772864946}]}, test_name=None, column='Exited', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.1449288023288548}]}, test_name=None, column='Balance', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.05855318704540857}]}, test_name=None, column='Exited', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'Tenure', 'correlation': 0.04177732330989858}]}, test_name=None, column='EstimatedSalary', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'EstimatedSalary', 'correlation': -0.03970402896113289}]}, test_name=None, column='CreditScore', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': 0.036344324015295595}]}, test_name=None, column='IsActiveMember', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'IsActiveMember', 'correlation': -0.03311632526716834}]}, test_name=None, column='HasCrCard', passed=True), ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.030543086117390872}]}, test_name=None, column='Age', passed=True)]\n"
     ]
    }
   ],
   "source": [
    "print(corr_results.test_results)\n",
    "print(\"test_name: \", corr_results.test_results.test_name)\n",
    "print(\"params: \", corr_results.test_results.params)\n",
    "print(\"passed: \", corr_results.test_results.passed)\n",
    "print(\"results: \", corr_results.test_results.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the `results` and extract a list of features that failed the test:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.3482965246830813}]}, test_name=None, column='Age', passed=False),\n",
       " ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.17604797085379387}]}, test_name=None, column='Balance', passed=True),\n",
       " ThresholdTestResult(values={'correlations': [{'column': 'IsActiveMember', 'correlation': -0.16782323772864946}]}, test_name=None, column='Exited', passed=True),\n",
       " ThresholdTestResult(values={'correlations': [{'column': 'Exited', 'correlation': 0.1449288023288548}]}, test_name=None, column='Balance', passed=True),\n",
       " ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.05855318704540857}]}, test_name=None, column='Exited', passed=True),\n",
       " ThresholdTestResult(values={'correlations': [{'column': 'Tenure', 'correlation': 0.04177732330989858}]}, test_name=None, column='EstimatedSalary', passed=True),\n",
       " ThresholdTestResult(values={'correlations': [{'column': 'EstimatedSalary', 'correlation': -0.03970402896113289}]}, test_name=None, column='CreditScore', passed=True),\n",
       " ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': 0.036344324015295595}]}, test_name=None, column='IsActiveMember', passed=True),\n",
       " ThresholdTestResult(values={'correlations': [{'column': 'IsActiveMember', 'correlation': -0.03311632526716834}]}, test_name=None, column='HasCrCard', passed=True),\n",
       " ThresholdTestResult(values={'correlations': [{'column': 'NumOfProducts', 'correlation': -0.030543086117390872}]}, test_name=None, column='Age', passed=True)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_results.test_results.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the highly correlated features and create a new VM dataset object. Note the use of different `input_id`s. This allows tracking the inputs used when running each individual test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_correlation_features = [\n",
    "    result.column\n",
    "    for result in corr_results.test_results.results\n",
    "    if result.passed == False\n",
    "]\n",
    "high_correlation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 17:44:59,039 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n"
     ]
    }
   ],
   "source": [
    "# Remove the highly correlated features from the dataset\n",
    "new_df_raw.drop(columns=high_correlation_features, inplace=True)\n",
    "\n",
    "# Re-initialize the dataset object\n",
    "vm_raw_dataset_new = vm.init_dataset(\n",
    "    dataset=new_df_raw,\n",
    "    input_id=\"new_df_raw_no_age\",\n",
    "    target_column=\"Exited\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-running the test with the reduced feature set should pass the test. You can also plot the correlation matrix to visualize the new correlation between features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6a41d6eac94abbbab4ef4425f608df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h1>High Pearson Correlation ✅</h1>\\n            <p>Identifies highly…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_results = vm.tests.run_test(\n",
    "    test_id=\"validmind.data_validation.HighPearsonCorrelation\",\n",
    "    params={\"max_threshold\": 0.3},\n",
    "    inputs={\"dataset\": vm_raw_dataset_new},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944d7a476bcf4ee8be5fa8926e8717cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1>Pearson Correlation Matrix</h1>'), HTML(value=\"<p>Evaluates linear dependency b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_results = vm.tests.run_test(\n",
    "    test_id=\"validmind.data_validation.PearsonCorrelationMatrix\",\n",
    "    inputs={\"dataset\": vm_raw_dataset_new},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documenting the results based on two datasets\n",
    "\n",
    "We have now done some analysis on two different datasets and we should able to document why certain things were done to the raw data with testing to support it. Every test result returned by the `run_test()` function has a `.log()` method that can be used to log the test results to ValidMind. When logging individual results to ValidMind you will need to manually add those results in a specific section of the model documentation.\n",
    "\n",
    "When using `run_documentation_tests()`, it's possible to automatically populate a section with the results of all tests that were registered in the documentation template.\n",
    "\n",
    "To populate the data preparation section of the documentatio, you will now complete the following steps:\n",
    "\n",
    "1. Run `run_documentation_tests()` using `vm_raw_dataset_new` as input\n",
    "2. Log the individual result high correlation test using `vm_raw_dataset` (no data cleanup)\n",
    "3. Log the individual result high correlation test using `vm_raw_dataset_new` (balanced classes and reduced features)\n",
    "\n",
    "After adding test driven blocks for steps #2 and #3 you will be able to explain the changes made to the raw data by editing the default description of the test result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run `run_documentation_tests()` using `vm_raw_dataset_new` as input\n",
    "\n",
    "`run_documentation_tests()` allows you to run multiple tests at once and log the results to the documentation. The function takes the following arguments:\n",
    "\n",
    "- `inputs`: any inputs to be passed to the tests\n",
    "- `config`: a dictionary `<test_id>:<test_config>` that allows configuring each test individually. Each test config has the following form:\n",
    "  - `params`: individual test parameters\n",
    "  - `inputs`: individual test inputs. When passed, this overrides any inputs passed from the `run_documentation_tests()` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7df8e68c9d42eba2f31972728a24cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Running test suite...'), IntProgress(value=0, max=26)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02afeb31e731457ab9cc189f68e54432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Test Suite Results: <i style=\"color: #DE257E\">Binary Classification V2</i></h2>…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_config = {\n",
    "    \"validmind.data_validation.ClassImbalance\": {\n",
    "        \"params\": {\"min_percent_threshold\": 30},\n",
    "    },\n",
    "    \"validmind.data_validation.HighPearsonCorrelation\": {\n",
    "        \"params\": {\"max_threshold\": 0.3},\n",
    "    },\n",
    "}\n",
    "\n",
    "tests_suite = vm.run_documentation_tests(\n",
    "    inputs={\n",
    "        \"dataset\": vm_raw_dataset_new,\n",
    "    },\n",
    "    config=test_config,\n",
    "    section=[\"data_preparation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log the individual result high correlation test using `vm_raw_dataset` (no data cleanup)\n",
    "\n",
    "Here you can use a custom `result_id` to tag the individual result with a unique identifier. This `result_id` can be appended to `test_id` with a `:` separator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e4c8344f6d42e8829d0d1ff1cd0eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h1>High Pearson Correlation Vm Raw Dataset ❌</h1>\\n            <p>Id…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = vm.tests.run_test(\n",
    "    test_id=\"validmind.data_validation.HighPearsonCorrelation:vm_raw_dataset\",\n",
    "    params={\"max_threshold\": 0.3},\n",
    "    inputs={\"dataset\": vm_raw_dataset},\n",
    ")\n",
    "result.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log the individual result high correlation test using `vm_raw_dataset_new` (balanced classes and reduced features)\n",
    "\n",
    "Repeat the same process as above but with the new dataset, using a new `result_id`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822668964b694313b7d7b62dc4dbf7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h1>High Pearson Correlation Vm Raw Dataset New ✅</h1>\\n            <…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = vm.tests.run_test(\n",
    "    test_id=\"validmind.data_validation.HighPearsonCorrelation:vm_raw_dataset_new\",\n",
    "    params={\"max_threshold\": 0.3},\n",
    "    inputs={\n",
    "        \"dataset\": vm_raw_dataset_new,\n",
    "    },\n",
    ")\n",
    "result.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add individual test results to model documentation\n",
    "\n",
    "You can now visit the documentation page for the model you connected to at the beginning of this notebook and add a new content block in the relevant section.\n",
    "\n",
    "To do this, go to the documentation page of your model and navigate to the `Data Preparation` -> `Correlations and Interactions` section. Then hover after the \"Pearson Correlation Matrix\" content block to reveal the `+` button as shown in the screenshot below.\n",
    "\n",
    "![screenshot showing insert button for test-driven blocks](../images/insert-test-driven-block.png)\n",
    "\n",
    "Click on the `+` button and select `Test-Driven Block`. This will open a dialog where you can select `Threshold Test` as the type of the test-driven content block, and then select the `High Pearson Correlation Vm Raw Dataset Test` metric. This will show a preview of the result and it should match the results shown above.\n",
    "\n",
    "![screenshot showing the selected test result in the dialog](../images/selecting-high-pearson-correlation-test.png)\n",
    "\n",
    "Finally, click on the `Insert block` button to add the test result to the documentation. You'll now see two individual results for the high correlation test in the `Correlations and Interactions` section of the documentation. To finalize the documentation, you can edit the test result's description block to explain the changes made to the raw data and the reasons behind them as we can see in the screenshot below.\n",
    "\n",
    "![screenshot showing the high pearson correlation block](../images/high-pearson-correlation-block.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing\n",
    "\n",
    "We have focused so far on the data assessment and pre-processing that usually occurs prior to any models being built. Now we are going to assume we have built a model and now we want to incorporate some model results in our documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a simple model based on lastest new_df_raw\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data out\n",
    "X = new_df_raw.drop(\"Class\", axis=1)\n",
    "y = new_df_raw[\"Class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Support Vector Classifier\n",
    "svc_params = {\"C\": [0.5, 0.7, 0.9, 1], \"kernel\": [\"rbf\", \"poly\", \"sigmoid\", \"linear\"]}\n",
    "grid_svc = GridSearchCV(SVC(), svc_params)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "# SVC best estimator\n",
    "svc = grid_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to ValidMind structure we add the Target with the Model Inputs, so let's combine test and train into two datasets:\n",
    "# I need to redo the X_train, X_test, y_train, y_test  as we need it to be overall train and test\n",
    "TRAIN = X_train\n",
    "TRAIN[\"Class\"] = y_train\n",
    "TEST = X_test\n",
    "TEST[\"Class\"] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, always remember to connect the datasets with ValidMind but in addition we will also connect the model to ValidMind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the two new datasets as test and training\n",
    "\n",
    "vm_train_ds = vm.init_dataset(\n",
    "    input_id=\"train_dataset_final\",\n",
    "    dataset=TRAIN,\n",
    "    target_column=\"Class\",\n",
    ")\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    input_id=\"test_dataset_final\",\n",
    "    dataset=TEST,\n",
    "    target_column=\"Class\",\n",
    ")\n",
    "\n",
    "\n",
    "# Register the model\n",
    "vm_model = vm.init_model(svc, input_id=\"svc_model_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign predictions to the datasets\n",
    "\n",
    "Once the Model has been registered with the corresponding train and test we can use these datasets directly together with the model to assign predictions. We can now use the `assign_predictions()` method from the `Dataset` object to link existing predictions to any model. If no prediction values are passed, the method will compute predictions automatically:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds.assign_predictions(model=vm_model)\n",
    "vm_test_ds.assign_predictions(model=vm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we focus on running the tests within the model development section of the model documentation. After running this function, only the tests associated with this section will be executed, and the corresponding section in the model documentation will be updated. In the example below, model development and model diagnosis sections are being run and where the train and test datasets are linked with the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this and observe in the output the sections being filled.\n",
    "results = vm.run_documentation_tests(\n",
    "    section=[\"model_development\", \"model_diagnosis\"],\n",
    "    inputs={\n",
    "        \"dataset\": vm_raw_dataset_new,\n",
    "        \"model\": vm_model,\n",
    "        \"datasets\": (vm_train_ds, vm_test_ds),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the entire suite of tests\n",
    "\n",
    "Here you will observe how you can run all the tests that have been pre-defined in the documentation template, e.g. under Model Diagnosis section certain tests have been mapped in setting up the appropriate documentation template.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_suite = vm.run_documentation_tests(\n",
    "    inputs={\n",
    "        \"dataset\": vm_raw_dataset_new,\n",
    "        \"model\": vm_model,\n",
    "        \"datasets\": (vm_train_ds, vm_test_ds),\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Custom Metrics and Threshold Tests Implementation\n",
    "\n",
    "[PLACEHOLDER - DO WE NEED TO ADD JOHN's NEW PROCESS HERE with Custom Metric function decorator? https://github.com/validmind/developer-framework/blob/john6797/sc-3718/create-decorator-for-registering-one-off/notebooks/code_samples/custom_tests/implementing_custom_tests.ipynb]\n",
    "\n",
    "This next session assumes that Model Developers already have a repository of custom made tests and analysis that is critical to include in the documentation. In this sub-section we will provide details on how to easily implement your custom tests in ValidMind before showing how to use the test.\n",
    "\n",
    "[PLACEHOLDER HERE ON OVERVIEW IMAGE ON HOW PROCESS LOOKS LIKE]\n",
    "\n",
    "Custom metrics offer added flexibility by extending the default metrics provided by ValidMind, enabling you to document any type of model or use case. Both metrics and threshold tests assess models but they differ in approach: _metrics_ measure a range of dataset or model behaviors, while _threshold tests_ yield a pass or fail result based on specific criteria. These instructions include the code required to:\n",
    "\n",
    "- Create a metric class signature\n",
    "- Implement a custom metric\n",
    "- Test the custom metric\n",
    "- Add a `summary()` method to the custom metric\n",
    "- Add figures to a metric\n",
    "\n",
    "As a reminder we are utilizing the previous steps in the future steps. More specifically:\n",
    "\n",
    "- `vm_model` is the Support Vector Classifier model object from ValidMind\n",
    "- `vm_raw_dataset_new` is the final pre-processed dataset object used for training and testing of model\n",
    "- `vm_train_ds` & `vm_test_ds` are the two dataset objects used to train and test the model\n",
    "\n",
    "Finally, recall that predictions have been assigned through `assign_predictions`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register external test providers (custom test)\n",
    "\n",
    "We will now declare a local filesystem test provider that allows loading tests from a local folder. Fror this to work we just need to specify the root folder under which the provider class will look for tests. For this demo, it is the `./tests/` directory.\n",
    "\n",
    "[PLACEHOLDER FOR TEAM TO ADD MORE DETAILS ON THE FLOW HERE]  \n",
    "WE NEED HOW THE CODE SHOULD BE STRUCTURED AND GOAL: MAKE IT AS EASY AS POSSIBLE\n",
    "CAN WE ADD MULTIPLE TESTS IN THE PYTHON FILE?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import LocalTestProvider\n",
    "\n",
    "# First we are going define a name so that we can always refer back and find our custom tests. In this example \"gbc_test_provides\" is the identifier\n",
    "gbc_namespace = \"gbc_test_provider\"\n",
    "\n",
    "# Setting up the connection to where the custom testing code lives.\n",
    "local_test_provider = LocalTestProvider(root_folder=\"./tests/\")\n",
    "\n",
    "# Now let's register the test under the name we defined above\n",
    "vm.tests.register_test_provider(\n",
    "    namespace=gbc_namespace,\n",
    "    test_provider=local_test_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing & Executing Custom Test in Model Documentation\n",
    "\n",
    "Let's now build a sample custom test that includes the outputs from a demo function called `get_marginal_bad_rates`. Inside the `tests/` directory next to this notebook you will find a file called `MarginalBadRateTest.py`. This file contains the custom test definition that we will run in the next cell. If you open that file you'll see how we invoke the `get_marginal_bad_rates` function from the `run()` method provided by the test interface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The custom test is found by searching for the name space created above with the Python file name 'MarginalBadRateTest'\n",
    "# This runs the test on the dataset object 'vm_train_ds' with model object 'vm_model'\n",
    "test = vm.tests.run_test(\n",
    "    test_id=f\"{gbc_namespace}.MarginalBadRateTest\",\n",
    "    inputs={\n",
    "        \"dataset\": vm_train_ds,\n",
    "        \"model\": vm_model,\n",
    "    },\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the parameters and implement in Model Documentation\n",
    "\n",
    "Note how we have defined the following property in the custom test class (i.e. parameter in custom test):\n",
    "\n",
    "```python\n",
    "default_params = {\"bins\": 10}\n",
    "```\n",
    "\n",
    "This allows you to pass parameters to the test when running it. Let's try to re-running the test with 15 bins instead. In this custom test the bins affecting the figures and table output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This test is run exactly the same as before but now you can see an additional line; 'params={\"bins\":15}' which will overwrite default bin value of 10\n",
    "\n",
    "test = vm.tests.run_test(\n",
    "    test_id=f\"{gbc_namespace}.MarginalBadRateTest\",\n",
    "    inputs={\n",
    "        \"dataset\": vm_train_ds,\n",
    "        \"model\": vm_model,\n",
    "    },\n",
    "    params={\"bins\": 15},\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using another dataset\n",
    "\n",
    "The inputs to the test can also can be changed. Let's try to re-run the test with the test dataset instead of the training dataset.\n",
    "\n",
    "[PLACEHOLDER CAN WE IMPLEMENT TWO DATASET RESULTS FOR ONE TEST RUN?]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    test_id=f\"{zopa_namespace}.MarginalBadRateTest\",\n",
    "    inputs={\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporate Custom Test in Model Documentation [PLACEHOLDER TEAM - IS there a way to incorporate the test programatically without going to UI?]\n",
    "\n",
    "Now, let's try visualizing these results in the ValidMind dashboard. Since we have called `test.log()` when running these tests their results are automatically logged to the ValidMind platform.\n",
    "\n",
    "Go to the ValidMind UI, select your model in the registry and go to the documentation page of your model and navigate to the `Model Development` -> `Model Evaluation` section. Then hover between any existing content block to reveal the `+` button as shown in the screenshot below.\n",
    "\n",
    "![screenshot showing insert button for test-driven blocks](images/insert-test-driven-block.png)\n",
    "\n",
    "Click on the `+` button and select `Test-Driven Block`. This will open a dialog where you can select `Metric` as the type of the test-driven content block, and then select the `GBC Test Provider Marginal Bad Rate Test` metric. This will show a preview of the composite metric and it should match the results shown above.\n",
    "\n",
    "![screenshot showing the selected composite metric in the dialog](images/selecting-bad-rates-metric.png)\n",
    "\n",
    "Finally, click on the `Insert block` button to add the composite metric to the documentation. You'll see the composite metric displayed in the documentation and now anytime you run `run_documentation_tests()`, the `Model Performance` composite metric will be run as part of the test suite. Let's go ahead and connect to the documentation project and run the tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Finalize Testing and Documentation\n",
    "\n",
    "In this section we will show how to finalize the testing and documentation by showing the following items:\n",
    "\n",
    "1. How to run documentation and update the configuration so we can implement custom tests and additional tests in documentation sections\n",
    "2. How to overwrite individual tests with new data or new model\n",
    "3. How to go deeper in the configuration of parameters for model diagnosis testing\n",
    "4. MORE? (specific to model development persona....)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Programtically change the documentation configuration\n",
    "\n",
    "Below you will observe how you can first preview the current configuration using the `vm.get_test_suite().get_default_config()` interface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "project_test_suite = vm.get_test_suite()\n",
    "config = project_test_suite.get_default_config()\n",
    "print(\"Suite Config: \\n\", json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Updating config\n",
    "\n",
    "The test configuration can be updated to fit with your use case and requirements but below you can see examples where several datasets are provided.\n",
    "\n",
    "[PLACEHOLDER CAN WE PROVIDE EXAMPLES ON HOW TO ADD A TEST IN A SECTION - PREFERABLY A CUSTOM TET?]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"validmind.data_validation.DatasetSplit\": {\n",
    "        \"inputs\": {\"datasets\": (vm_train_ds, vm_test_ds)},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.PopulationStabilityIndex\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"datasets\": (vm_train_ds, vm_test_ds)},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.ConfusionMatrix\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"dataset\": vm_test_ds},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.ClassifierPerformance:in_sample\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"dataset\": vm_train_ds},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.ClassifierPerformance:out_of_sample\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"dataset\": vm_test_ds},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.PrecisionRecallCurve\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"dataset\": vm_test_ds},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.ROCCurve\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"dataset\": vm_test_ds},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.TrainingTestDegradation\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"datasets\": (vm_train_ds, vm_test_ds)},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.MinimumAccuracy\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"dataset\": vm_test_ds},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.MinimumF1Score\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"dataset\": vm_test_ds},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.MinimumROCAUCScore\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"dataset\": vm_test_ds},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.PermutationFeatureImportance\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"dataset\": vm_test_ds},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.SHAPGlobalImportance\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"dataset\": vm_test_ds},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.WeakspotsDiagnosis\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"datasets\": (vm_train_ds, vm_test_ds)},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.OverfitDiagnosis\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"datasets\": (vm_train_ds, vm_test_ds)},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.RobustnessDiagnosis\": {\n",
    "        \"inputs\": {\"model\": vm_model, \"datasets\": (vm_train_ds, vm_test_ds)},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run documentation tests\n",
    "\n",
    "You can now run all documentation tests and pass an extra `config` parameter that overrides input and parameter configuration for the tests specified in the object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_suite = vm.run_documentation_tests(\n",
    "    inputs={\n",
    "        \"dataset\": vm_raw_ds,\n",
    "        \"model\": vm_model,\n",
    "        \"datasets\": (vm_train_ds, vm_test_ds),\n",
    "    },\n",
    "    config=config,\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Overwrite a test that has been docmented\n",
    "\n",
    "In this example we are showing how you can easily overwrite a test results. For example, let's assume you did some inital testing and logged results but for some reason you had to change the data used for model training and testing and as a consequence updated tests have to be implemented\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Configure parameters for model diagnosis tests\n",
    "\n",
    "Each test has its default parameters and their values depending on the use case you are trying to solve. ValidMind's developer framework exposes these parameters at the user level so that they can be adjusted based on requirements.\n",
    "\n",
    "The config can be applied to a specific test to override the default configuration parameters.\n",
    "\n",
    "The format of the config is:\n",
    "\n",
    "```\n",
    "config = {\n",
    "    \"<test1_id>\": {\n",
    "        \"<default_param_1>\": value,\n",
    "        \"<default_param_2>\": value,\n",
    "    },\n",
    "     \"<test2_id>\": {\n",
    "        \"<default_param_1>\": value,\n",
    "        \"<default_param_2>\": value,\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "Users can input the configuration to `run_documentation_tests()` and `run_test_suite()` using **`config`**, allowing fine-tuning the suite according to the specific configuration requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the example below we are making the test more specific for certain columns. For example, in test Weak Spot Diagnosis I only want to perform this test on Age and Balance features.\n",
    "\n",
    "config = {\n",
    "    \"validmind.model_validation.sklearn.OverfitDiagnosis\": {\n",
    "        \"params\": {\n",
    "            \"cut_off_percentage\": 3,\n",
    "            \"feature_columns\": [\"Age\", \"Balance\", \"Tenure\", \"NumOfProducts\"],\n",
    "        },\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.WeakspotsDiagnosis\": {\n",
    "        \"params\": {\n",
    "            \"features_columns\": [\"Age\", \"Balance\"],\n",
    "            \"accuracy_gap_threshold\": 85,\n",
    "        },\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.RobustnessDiagnosis\": {\n",
    "        \"params\": {\n",
    "            \"features_columns\": [\"Balance\", \"Tenure\"],\n",
    "            \"scaling_factor_std_dev_list\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "            \"accuracy_decay_threshold\": 4,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "full_suite = vm.run_documentation_tests(\n",
    "    inputs={\n",
    "        \"dataset\": vm_train_ds,\n",
    "        \"datasets\": (vm_train_ds, vm_test_ds),\n",
    "        \"model\": vm_model,\n",
    "    },\n",
    "    config=config,\n",
    "    section=\"model_diagnosis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "You can look at the results of this test plan right in the notebook where you ran the code, as you would expect. But there is a better way: view the test results as part of your model documentation right in the ValidMind Platform UI:\n",
    "\n",
    "1. In the [Platform UI](https://app.prod.validmind.ai), go to the **Documentation** page for the model you registered earlier.\n",
    "\n",
    "2. Expand **Model Development**\n",
    "\n",
    "What you can see now is a more easily consumable version of the model diagnosis tests you just performed, along with other parts of your model documentation that still need to be completed.\n",
    "\n",
    "If you want to learn more about where you are in the model documentation process, take a look at <a href=\"https://docs.validmind.ai/guide/get-started-developer-framework.html#how-do-i-use-the-framework\"> How do I use the framework? </a>.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

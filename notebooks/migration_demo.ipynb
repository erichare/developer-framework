{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick hack to load local library code\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Load API key and secret from environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import validmind as vm\n",
    "\n",
    "# For test environment use api_host=\"https://api.dev.vm.validmind.ai/api/v1/tracking\"\n",
    "vm.init(\n",
    "    # project=\"cl2r3k1ri000009jweny7ba1g\"\n",
    "    project=\"cl1jyv16o000809lg98gi9tie\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas dataset detected. Initializing VM Dataset instance...\n",
      "Inferring dataset types...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"notebooks/datasets/bank_customer_churn.csv\")\n",
    "\n",
    "vm_dataset = vm.init_dataset(\n",
    "    dataset=df,\n",
    "    target_column=\"Exited\",\n",
    "    class_labels={\n",
    "        \"0\": \"Did not exit\",\n",
    "        \"1\": \"Exited\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test plan 'tabular_dataset'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0fe1ba48774a4792e618f981b376ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending results of test plan execution 'tabular_dataset' to ValidMind...\n",
      "|-- Running sub test plan - tabular_dataset_description\n",
      "Running test plan 'tabular_dataset_description'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4876e7947214a5f99c1bfd7b1dbc548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DatasetMetadata: dataset_metadata\n",
      "Running Metric: dataset_description\n",
      "Running Metric: dataset_correlations\n",
      "Sending results of test plan execution 'tabular_dataset_description' to ValidMind...\n",
      "Successfully logged dataset metadata and statistics.\n",
      "Successfully logged metrics\n",
      "|-- Running sub test plan - tabular_data_quality\n",
      "Running test plan 'tabular_data_quality'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcc09a4f8314921abbc243d74495b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ThresholdTest: class_imbalance\n",
      "Running ThresholdTest: duplicates\n",
      "Running ThresholdTest: cardinality\n",
      "Running ThresholdTest: pearson_correlation\n",
      "Running ThresholdTest: missing\n",
      "Running ThresholdTest: skewness\n",
      "Running ThresholdTest: unique\n",
      "Running ThresholdTest: zeros\n",
      "Sending results of test plan execution 'tabular_data_quality' to ValidMind...\n",
      "Successfully logged test results for test: class_imbalance\n",
      "Successfully logged test results for test: duplicates\n",
      "Successfully logged test results for test: cardinality\n",
      "Successfully logged test results for test: pearson_correlation\n",
      "Successfully logged test results for test: missing\n",
      "Successfully logged test results for test: skewness\n",
      "Successfully logged test results for test: unique\n",
      "Successfully logged test results for test: zeros\n"
     ]
    }
   ],
   "source": [
    "dataset_tests = vm.test_plans.TabularDataset(\n",
    "    dataset=vm_dataset,\n",
    ")\n",
    "\n",
    "dataset_tests.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"RowNumber\", \"CustomerId\", \"Surname\", \"CreditScore\"], axis=1, inplace=True)\n",
    "\n",
    "genders = {\"Male\": 0, \"Female\": 1}\n",
    "df.replace({\"Gender\": genders}, inplace=True)\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(df[\"Geography\"], prefix=\"Geography\")], axis=1)\n",
    "df.drop(\"Geography\", axis=1, inplace=True)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.20)\n",
    "\n",
    "# This guarantees a 60/20/20 split\n",
    "train_ds, val_ds = train_test_split(train_df, test_size=0.25)\n",
    "\n",
    "# For training\n",
    "x_train = train_ds.drop(\"Exited\", axis=1)\n",
    "y_train = train_ds.loc[:, \"Exited\"].astype(int)\n",
    "x_val = val_ds.drop(\"Exited\", axis=1)\n",
    "y_val = val_ds.loc[:, \"Exited\"].astype(int)\n",
    "\n",
    "# For testing\n",
    "x_test = test_df.drop(\"Exited\", axis=1)\n",
    "y_test = test_df.loc[:, \"Exited\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=10, enable_categorical=False,\n",
       "              eval_metric=['error', 'logloss', 'auc'], gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=6,\n",
       "              max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(early_stopping_rounds=10)\n",
    "model.set_params(\n",
    "    eval_metric=[\"error\", \"logloss\", \"auc\"],\n",
    ")\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas dataset detected. Initializing VM Dataset instance...\n",
      "Inferring dataset types...\n",
      "Pandas dataset detected. Initializing VM Dataset instance...\n",
      "Inferring dataset types...\n"
     ]
    }
   ],
   "source": [
    "vm_model = vm.init_model(model)\n",
    "vm_train_ds = vm.init_dataset(dataset=train_ds, type=\"generic\", target_column=\"Exited\")\n",
    "vm_test_ds = vm.init_dataset(dataset=test_df, type=\"generic\", target_column=\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test plan 'sklearn_classifier'...\n",
      "Generating predictions train dataset...\n",
      "Generating predictions test dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853f907ce6224e87a4ff551f53d3a73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending results of test plan execution 'sklearn_classifier' to ValidMind...\n",
      "|-- Running sub test plan - sklearn_classifier_metrics\n",
      "Running test plan 'sklearn_classifier_metrics'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059ea808e3024e46b1f19174680c807f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ModelMetadata: model_metadata\n",
      "Running Metric: accuracy\n",
      "Running Metric: confusion_matrix\n",
      "Running Metric: f1_score\n",
      "Running Metric: pfi\n",
      "Running Metric: pr_curve\n",
      "Running Metric: precision\n",
      "Running Metric: recall\n",
      "Running Metric: roc_auc\n",
      "Running Metric: roc_curve\n",
      "Running Metric: csi\n",
      "Running Metric: psi\n",
      "Running SHAPGlobalImportance: shap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending results of test plan execution 'sklearn_classifier_metrics' to ValidMind...\n",
      "Successfully logged metrics\n",
      "|-- Running sub test plan - sklearn_classifier_validation\n",
      "Running test plan 'sklearn_classifier_validation'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be4e72dc2e74f9f96c76e9dfd9e4af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ThresholdTest: accuracy_score\n",
      "Running ThresholdTest: f1_score\n",
      "Running ThresholdTest: roc_auc_score\n",
      "Running ThresholdTest: training_test_degradation\n",
      "Sending results of test plan execution 'sklearn_classifier_validation' to ValidMind...\n",
      "Successfully logged test results for test: accuracy_score\n",
      "Successfully logged test results for test: f1_score\n",
      "Successfully logged test results for test: roc_auc_score\n",
      "Successfully logged test results for test: training_test_degradation\n"
     ]
    }
   ],
   "source": [
    "model_metrics = vm.test_plans.SKLearnClassifier(\n",
    "    model=vm_model,\n",
    "    train_ds=vm_train_ds,\n",
    "    test_ds=vm_test_ds,\n",
    ")\n",
    "\n",
    "model_metrics.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-Jp3s24zK-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5507f2e99c1cac96073e07e686bb64d511c5f1c7216ba7fc4306f43af6557f44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

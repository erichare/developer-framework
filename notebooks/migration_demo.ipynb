{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick hack to load local library code\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Load API key and secret from environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import validmind as vm\n",
    "\n",
    "# For test environment use api_host=\"https://api.dev.vm.validmind.ai/api/v1/tracking\"\n",
    "vm.init(\n",
    "    # project=\"cl2r3k1ri000009jweny7ba1g\"\n",
    "    project=\"cl1jyv16o000809lg98gi9tie\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas dataset detected. Initializing VM Dataset instance...\n",
      "Inferring dataset types...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"notebooks/datasets/bank_customer_churn.csv\")\n",
    "\n",
    "vm_dataset = vm.init_dataset(\n",
    "    dataset=df,\n",
    "    target_column=\"Exited\",\n",
    "    class_labels={\n",
    "        \"0\": \"Did not exit\",\n",
    "        \"1\": \"Exited\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test plan 'generic_tabular_dataset'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:00<00:00, 69.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test - ThresholdTest : class_imbalance\n",
      "Running test - ThresholdTest : duplicates\n",
      "Running test - ThresholdTest : cardinality\n",
      "Running test - ThresholdTest : pearson_correlation\n",
      "Running test - ThresholdTest : missing\n",
      "Running test - ThresholdTest : skewness\n",
      "Running test - ThresholdTest : unique\n",
      "Running test - ThresholdTest : zeros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 54.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending results of test plan execution 'generic_tabular_dataset' to ValidMind...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged test results for test: class_imbalance\n",
      "Successfully logged test results for test: duplicates\n",
      "Successfully logged test results for test: cardinality\n",
      "Successfully logged test results for test: pearson_correlation\n",
      "Successfully logged test results for test: missing\n",
      "Successfully logged test results for test: skewness\n",
      "Successfully logged test results for test: unique\n",
      "Successfully logged test results for test: zeros\n"
     ]
    }
   ],
   "source": [
    "dataset_tests = vm.test_plans.GenericTabularDatasetTestPlan(\n",
    "    dataset=vm_dataset,\n",
    ")\n",
    "\n",
    "dataset_tests.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"RowNumber\", \"CustomerId\", \"Surname\", \"CreditScore\"], axis=1, inplace=True)\n",
    "\n",
    "genders = {\"Male\": 0, \"Female\": 1}\n",
    "df.replace({\"Gender\": genders}, inplace=True)\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(df[\"Geography\"], prefix=\"Geography\")], axis=1)\n",
    "df.drop(\"Geography\", axis=1, inplace=True)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.20)\n",
    "\n",
    "# This guarantees a 60/20/20 split\n",
    "train_ds, val_ds = train_test_split(train_df, test_size=0.25)\n",
    "\n",
    "# For training\n",
    "x_train = train_ds.drop(\"Exited\", axis=1)\n",
    "y_train = train_ds.loc[:, \"Exited\"].astype(int)\n",
    "x_val = val_ds.drop(\"Exited\", axis=1)\n",
    "y_val = val_ds.loc[:, \"Exited\"].astype(int)\n",
    "\n",
    "# For testing\n",
    "x_test = test_df.drop(\"Exited\", axis=1)\n",
    "y_test = test_df.loc[:, \"Exited\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=10, enable_categorical=False,\n",
       "              eval_metric=['error', 'logloss', 'auc'], gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_to_onehot=4, max_delta_step=0, max_depth=6,\n",
       "              max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(early_stopping_rounds=10)\n",
    "model.set_params(\n",
    "    eval_metric=[\"error\", \"logloss\", \"auc\"],\n",
    ")\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas dataset detected. Initializing VM Dataset instance...\n",
      "Inferring dataset types...\n",
      "Pandas dataset detected. Initializing VM Dataset instance...\n",
      "Inferring dataset types...\n"
     ]
    }
   ],
   "source": [
    "vm_model = vm.init_model(model)\n",
    "vm_train_ds = vm.init_dataset(dataset=train_ds, target_column=\"Exited\")\n",
    "vm_test_ds = vm.init_dataset(dataset=test_df, target_column=\"Exited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test plan 'sklearn_classifier_metrics'...\n",
      "Generating predictions train dataset...\n",
      "Generating predictions test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test - Metric : accuracy\n",
      "Running test - Metric : confusion_matrix\n",
      "Running test - Metric : f1_score\n",
      "Running test - Metric : pfi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test - Metric : csi\n",
      "Running test - Metric : psi\n",
      "Sending results of test plan execution 'sklearn_classifier_metrics' to ValidMind...\n",
      "Successfully logged metrics\n"
     ]
    }
   ],
   "source": [
    "model_metrics = vm.test_plans.SKLearnClassifierMetricsTestPlan(\n",
    "    model=vm_model,\n",
    "    train_ds=vm_train_ds,\n",
    "    test_ds=vm_test_ds,\n",
    ")\n",
    "\n",
    "model_metrics.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-Jp3s24zK-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5507f2e99c1cac96073e07e686bb64d511c5f1c7216ba7fc4306f43af6557f44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

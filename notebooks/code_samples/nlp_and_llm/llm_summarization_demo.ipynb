{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization Using LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"https://api.prod.validmind.ai/api/v1/tracking\",\n",
    "  api_key = \"...\",\n",
    "  api_secret = \"...\",\n",
    "  project = \"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first install the `datasets` library from huggingface\n",
    "%pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sample dataset from the library\n",
    "from validmind.datasets.nlp import cnn_dailymail\n",
    "\n",
    "print(\n",
    "    f\"Loaded demo dataset with: \\n\\n\\t• Target column: '{cnn_dailymail.target_column}' \"\n",
    "    f\"\\n\\t• Input text column: {cnn_dailymail.text_column} \"\n",
    "    f\"\\n\\t• Prediction columns: '{cnn_dailymail.t5_prediction}', '{cnn_dailymail.gpt_35_prediction_column}'\"\n",
    ")\n",
    "\n",
    "\n",
    "train_df, test_df = cnn_dailymail.load_data(source=\"offline\", dataset_size=\"100k\")\n",
    "\n",
    "# Display the first few rows of the dataframe to check the loaded data.\n",
    "cnn_dailymail.display_nice(train_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.models import FoundationModel, Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    raise Exception(\"OPENAI_API_KEY not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "model = OpenAI()\n",
    "\n",
    "\n",
    "def call_model(prompt):\n",
    "    return (\n",
    "        model.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.content\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an AI with expertise in summarizing financial news.\n",
    "Your task is to provide a concise summary of the specific news article provided below.\n",
    "Before proceeding, take a moment to understand the context and nuances of the financial terminology used in the article.\n",
    "\n",
    "Article to Summarize:\n",
    "\n",
    "```\n",
    "{article}\n",
    "```\n",
    "\n",
    "Please respond with a concise summary of the article's main points.\n",
    "Ensure that your summary is based on the content of the article and not on external information or assumptions.\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_variables = [\"article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds = vm.init_dataset(\n",
    "    dataset=train_df,\n",
    "    input_id=\"train_dataset\",\n",
    "    text_column=\"article\",\n",
    "    target_column=\"highlights\",\n",
    ")\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=test_df,\n",
    "    input_id=\"test_dataset\",\n",
    "    text_column=\"article\",\n",
    "    target_column=\"highlights\",\n",
    ")\n",
    "\n",
    "vm_model = FoundationModel(\n",
    "    predict_fn=call_model,\n",
    "    prompt=Prompt(\n",
    "        template=prompt_template,\n",
    "        variables=prompt_variables,\n",
    "    ),\n",
    "    input_id=\"llm_model\"\n",
    ")\n",
    "\n",
    "# Assign pre-computed model predictions to the test dataset\n",
    "vm_test_ds.assign_predictions(vm_model, prediction_column=\"gpt_35_prediction\")\n",
    "vm_train_ds.assign_predictions(vm_model, prediction_column=\"gpt_35_prediction\")\n",
    "\n",
    "print(vm_train_ds)\n",
    "print(vm_test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "- Text Description\n",
    "- Common Words \n",
    "- Punctuations\n",
    "- StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.data_validation.nlp.TextDescription\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.data_validation.nlp.CommonWords\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.data_validation.nlp.Punctuations\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.data_validation.nlp.StopWords\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings \n",
    "\n",
    "- Cosine Similarity Distribution\n",
    "- Cluster Distribution\n",
    "- Descriptive Analytics\n",
    "- Stability Analysis Keyword\n",
    "- Stability Analysis Random Noise\n",
    "- Stability Analysis Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "embedding_model = pipeline(\n",
    "    'feature-extraction', \n",
    "    model='bert-base-uncased', \n",
    "    tokenizer='bert-base-uncased',\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "vm_embedding_model = vm.init_model(\n",
    "    model=embedding_model,\n",
    "    input_id=\"bert_embedding_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_test_ds.assign_predictions(\n",
    "    model=vm_embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.embeddings.CosineSimilarityDistribution\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_embedding_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.embeddings.ClusterDistribution\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_embedding_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.embeddings.DescriptiveAnalytics\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_embedding_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.embeddings.StabilityAnalysisKeyword\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_embedding_model,\n",
    "    },\n",
    "    params = {\n",
    "        \"text_column\": \"article\",\n",
    "        \"keyword_dict\": {\"finance\": \"financial\"},\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.embeddings.StabilityAnalysisRandomNoise\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_embedding_model,\n",
    "    },\n",
    "    params = {\n",
    "        \"text_column\": \"article\",\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.embeddings.StabilityAnalysisSynonyms\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_embedding_model,\n",
    "    },\n",
    "    params = {\n",
    "        \"text_column\": \"article\",\n",
    "        \"probability:\": 0.1,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Validation\n",
    "\n",
    "- Bias\n",
    "- Clarity\n",
    "- Conciseness\n",
    "- Delimitation\n",
    "- NegativeInstruction\n",
    "- Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = vm.tests.run_test(\n",
    "    \"validmind.prompt_validation.Bias\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = vm.tests.run_test(\n",
    "    \"validmind.prompt_validation.Clarity\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = vm.tests.run_test(\n",
    "    \"validmind.prompt_validation.Conciseness\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = vm.tests.run_test(\n",
    "    \"validmind.prompt_validation.Delimitation\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = vm.tests.run_test(\n",
    "    \"validmind.prompt_validation.NegativeInstruction\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = vm.tests.run_test(\n",
    "    \"validmind.prompt_validation.Specificity\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_code = False  \n",
    "if run_code:\n",
    "\n",
    "    test_suite_results = vm.run_test_suite(\n",
    "        \"prompt_validation\",\n",
    "        inputs={\n",
    "            \"dataset\": vm_test_ds,\n",
    "            \"model\": vm_model,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Tests\n",
    "\n",
    "- Token Disparity\n",
    "- Rouge Metrics\n",
    "- Rouge Metrics Aggregate\n",
    "- Bert Score\n",
    "- Bert Score Aggregate\n",
    "- Contextual Recall\n",
    "- Bleu Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.TokenDisparity\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.RougeMetrics\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.RougeMetricsAggregate\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.BertScore\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.BertScoreAggregate\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.ContextualRecall\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.BleuScore\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.MeteorScore\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias and Toxicity Tests\n",
    "\n",
    "- Toxicity Score\n",
    "- Toxicity Histogram\n",
    "- Regard Score\n",
    "- Regard Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.ToxicityScore\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.ToxicityHistogram\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.RegardHistogram\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"validmind.model_validation.RegardScore\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_test_ds,\n",
    "        \"model\": vm_model,\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-py3.10",
   "language": "python",
   "name": "validmind-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

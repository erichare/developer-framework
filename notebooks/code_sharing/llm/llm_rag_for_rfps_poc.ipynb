{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG for Question Similarity in RFPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU qdrant-client lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    raise Exception(\"OPENAI_API_KEY not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from IPython.display import HTML, display\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def _format_cell_text(text, width=50):\n",
    "    \"\"\"Private function to format a cell's text.\"\"\"\n",
    "    return \"\\n\".join([textwrap.fill(line, width=width) for line in text.split(\"\\n\")])\n",
    "\n",
    "\n",
    "def _format_dataframe_for_tabulate(df):\n",
    "    \"\"\"Private function to format the entire DataFrame for tabulation.\"\"\"\n",
    "    df_out = df.copy()\n",
    "\n",
    "    # Format all string columns\n",
    "    for column in df_out.columns:\n",
    "        # Check if column is of type object (likely strings)\n",
    "        if df_out[column].dtype == object:\n",
    "            df_out[column] = df_out[column].apply(_format_cell_text)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def _dataframe_to_html_table(df):\n",
    "    \"\"\"Private function to convert a DataFrame to an HTML table.\"\"\"\n",
    "    headers = df.columns.tolist()\n",
    "    table_data = df.values.tolist()\n",
    "    return tabulate(table_data, headers=headers, tablefmt=\"html\")\n",
    "\n",
    "\n",
    "def display_nice(df, num_rows=None):\n",
    "    \"\"\"Primary function to format and display a DataFrame.\"\"\"\n",
    "    if num_rows is not None:\n",
    "        df = df.head(num_rows)\n",
    "    formatted_df = _format_dataframe_for_tabulate(df)\n",
    "    html_table = _dataframe_to_html_table(formatted_df)\n",
    "    display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_keys(data, indent=0):\n",
    "    for key, value in data.items():\n",
    "        print(' ' * indent + str(key))\n",
    "        if isinstance(value, dict):  # if the value is another dictionary, recurse\n",
    "            print_dict_keys(value, indent + 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing RFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV file paths\n",
    "existing_rfp_paths = [\n",
    "    \"datasets/rag/rfp_existing_questions_client_2.csv\",\n",
    "]\n",
    "\n",
    "existing_rfp_df = [pd.read_csv(file_path) for file_path in existing_rfp_paths]\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "existing_rfp_df = pd.concat(existing_rfp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project_Title</th>\n",
       "      <th>RFP_Question_ID</th>\n",
       "      <th>RFP_Question</th>\n",
       "      <th>RFP_Answer</th>\n",
       "      <th>Area</th>\n",
       "      <th>Last_Accessed_At</th>\n",
       "      <th>Requester</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Can you discuss your expertise in creating AI-...</td>\n",
       "      <td>Our company has 15 years of experience in deve...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>2</td>\n",
       "      <td>How do you keep your AI applications current w...</td>\n",
       "      <td>We maintain a dedicated R&amp;D team focused on in...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>3</td>\n",
       "      <td>Are your AI applications adaptable to specific...</td>\n",
       "      <td>Absolutely, customization is a core aspect of ...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>4</td>\n",
       "      <td>What steps do you undertake to protect user pr...</td>\n",
       "      <td>User privacy and data security are paramount. ...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>5</td>\n",
       "      <td>What strategies do you employ to design user i...</td>\n",
       "      <td>Our design philosophy centers on simplicity an...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>6</td>\n",
       "      <td>Explain the support and maintenance services y...</td>\n",
       "      <td>Post-launch, we offer comprehensive support an...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>7</td>\n",
       "      <td>How do you evaluate the effectiveness and impa...</td>\n",
       "      <td>Success measurement is tailored to each projec...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>8</td>\n",
       "      <td>How do you manage ethical concerns in your LLM...</td>\n",
       "      <td>We adhere to ethical AI practices by implement...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>9</td>\n",
       "      <td>Could you outline how you train your LLMs, inc...</td>\n",
       "      <td>Our LLM training process begins with the metic...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>10</td>\n",
       "      <td>How do you ensure your LLMs continuously learn...</td>\n",
       "      <td>We implement advanced continuous learning mech...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>11</td>\n",
       "      <td>What actions do you take to make the decision-...</td>\n",
       "      <td>We prioritize transparency and explainability ...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>12</td>\n",
       "      <td>How do you verify and ensure that your LLMs ca...</td>\n",
       "      <td>We conduct extensive performance testing under...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>13</td>\n",
       "      <td>Can you provide case studies of successful LLM...</td>\n",
       "      <td>We can share case studies of successful LLM-ba...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>14</td>\n",
       "      <td>Describe how you integrate LLMs into existing ...</td>\n",
       "      <td>Our approach involves conducting a thorough an...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>15</td>\n",
       "      <td>What are your strategies for supporting and ma...</td>\n",
       "      <td>Our post-deployment support is designed to ens...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>16</td>\n",
       "      <td>How does your AI solution comply with the guid...</td>\n",
       "      <td>Our AI solution is meticulously designed to al...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>17</td>\n",
       "      <td>Could you describe the governance frameworks y...</td>\n",
       "      <td>We have established an AI Risk Council that pl...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>18</td>\n",
       "      <td>How do you identify and evaluate AI risks foll...</td>\n",
       "      <td>We conduct thorough assessments of AI systems ...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>19</td>\n",
       "      <td>What steps do you implement to ensure AI decis...</td>\n",
       "      <td>We prioritize transparency by incorporating ex...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>20</td>\n",
       "      <td>How do you monitor and assess AI risk exposure...</td>\n",
       "      <td>We have developed a set of Key Performance Ind...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>21</td>\n",
       "      <td>Explain how you manage and mitigate AI risks i...</td>\n",
       "      <td>We implement and maintain robust risk manageme...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>22</td>\n",
       "      <td>How do you ensure compliance with U.S. laws on...</td>\n",
       "      <td>We ensure compliance with U.S. regulations suc...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>23</td>\n",
       "      <td>In what ways do you participate in advancing A...</td>\n",
       "      <td>We actively participate in industry working gr...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Project_Title  RFP_Question_ID  \\\n",
       "0   AI-Powered Risk Assessment Model Development f...                1   \n",
       "1   AI-Powered Risk Assessment Model Development f...                2   \n",
       "2   AI-Powered Risk Assessment Model Development f...                3   \n",
       "3   AI-Powered Risk Assessment Model Development f...                4   \n",
       "4   AI-Powered Risk Assessment Model Development f...                5   \n",
       "5   AI-Powered Risk Assessment Model Development f...                6   \n",
       "6   AI-Powered Risk Assessment Model Development f...                7   \n",
       "7   AI-Powered Risk Assessment Model Development f...                8   \n",
       "8   AI-Powered Risk Assessment Model Development f...                9   \n",
       "9   AI-Powered Risk Assessment Model Development f...               10   \n",
       "10  AI-Powered Risk Assessment Model Development f...               11   \n",
       "11  AI-Powered Risk Assessment Model Development f...               12   \n",
       "12  AI-Powered Risk Assessment Model Development f...               13   \n",
       "13  AI-Powered Risk Assessment Model Development f...               14   \n",
       "14  AI-Powered Risk Assessment Model Development f...               15   \n",
       "15  AI-Powered Risk Assessment Model Development f...               16   \n",
       "16  AI-Powered Risk Assessment Model Development f...               17   \n",
       "17  AI-Powered Risk Assessment Model Development f...               18   \n",
       "18  AI-Powered Risk Assessment Model Development f...               19   \n",
       "19  AI-Powered Risk Assessment Model Development f...               20   \n",
       "20  AI-Powered Risk Assessment Model Development f...               21   \n",
       "21  AI-Powered Risk Assessment Model Development f...               22   \n",
       "22  AI-Powered Risk Assessment Model Development f...               23   \n",
       "\n",
       "                                         RFP_Question  \\\n",
       "0   Can you discuss your expertise in creating AI-...   \n",
       "1   How do you keep your AI applications current w...   \n",
       "2   Are your AI applications adaptable to specific...   \n",
       "3   What steps do you undertake to protect user pr...   \n",
       "4   What strategies do you employ to design user i...   \n",
       "5   Explain the support and maintenance services y...   \n",
       "6   How do you evaluate the effectiveness and impa...   \n",
       "7   How do you manage ethical concerns in your LLM...   \n",
       "8   Could you outline how you train your LLMs, inc...   \n",
       "9   How do you ensure your LLMs continuously learn...   \n",
       "10  What actions do you take to make the decision-...   \n",
       "11  How do you verify and ensure that your LLMs ca...   \n",
       "12  Can you provide case studies of successful LLM...   \n",
       "13  Describe how you integrate LLMs into existing ...   \n",
       "14  What are your strategies for supporting and ma...   \n",
       "15  How does your AI solution comply with the guid...   \n",
       "16  Could you describe the governance frameworks y...   \n",
       "17  How do you identify and evaluate AI risks foll...   \n",
       "18  What steps do you implement to ensure AI decis...   \n",
       "19  How do you monitor and assess AI risk exposure...   \n",
       "20  Explain how you manage and mitigate AI risks i...   \n",
       "21  How do you ensure compliance with U.S. laws on...   \n",
       "22  In what ways do you participate in advancing A...   \n",
       "\n",
       "                                           RFP_Answer                   Area  \\\n",
       "0   Our company has 15 years of experience in deve...                General   \n",
       "1   We maintain a dedicated R&D team focused on in...                General   \n",
       "2   Absolutely, customization is a core aspect of ...                General   \n",
       "3   User privacy and data security are paramount. ...                General   \n",
       "4   Our design philosophy centers on simplicity an...                General   \n",
       "5   Post-launch, we offer comprehensive support an...                General   \n",
       "6   Success measurement is tailored to each projec...                General   \n",
       "7   We adhere to ethical AI practices by implement...  Large Language Models   \n",
       "8   Our LLM training process begins with the metic...  Large Language Models   \n",
       "9   We implement advanced continuous learning mech...  Large Language Models   \n",
       "10  We prioritize transparency and explainability ...  Large Language Models   \n",
       "11  We conduct extensive performance testing under...  Large Language Models   \n",
       "12  We can share case studies of successful LLM-ba...  Large Language Models   \n",
       "13  Our approach involves conducting a thorough an...  Large Language Models   \n",
       "14  Our post-deployment support is designed to ens...  Large Language Models   \n",
       "15  Our AI solution is meticulously designed to al...          AI Regulation   \n",
       "16  We have established an AI Risk Council that pl...          AI Regulation   \n",
       "17  We conduct thorough assessments of AI systems ...          AI Regulation   \n",
       "18  We prioritize transparency by incorporating ex...          AI Regulation   \n",
       "19  We have developed a set of Key Performance Ind...          AI Regulation   \n",
       "20  We implement and maintain robust risk manageme...          AI Regulation   \n",
       "21  We ensure compliance with U.S. regulations suc...          AI Regulation   \n",
       "22  We actively participate in industry working gr...          AI Regulation   \n",
       "\n",
       "   Last_Accessed_At Requester   Status  \n",
       "0        18/12/2022    Bank B  Awarded  \n",
       "1        18/12/2022    Bank B  Awarded  \n",
       "2        18/12/2022    Bank B  Awarded  \n",
       "3        18/12/2022    Bank B  Awarded  \n",
       "4        18/12/2022    Bank B  Awarded  \n",
       "5        18/12/2022    Bank B  Awarded  \n",
       "6        18/12/2022    Bank B  Awarded  \n",
       "7        18/12/2022    Bank B  Awarded  \n",
       "8        18/12/2022    Bank B  Awarded  \n",
       "9        18/12/2022    Bank B  Awarded  \n",
       "10       18/12/2022    Bank B  Awarded  \n",
       "11       18/12/2022    Bank B  Awarded  \n",
       "12       18/12/2022    Bank B  Awarded  \n",
       "13       18/12/2022    Bank B  Awarded  \n",
       "14       18/12/2022    Bank B  Awarded  \n",
       "15       18/12/2022    Bank B  Awarded  \n",
       "16       18/12/2022    Bank B  Awarded  \n",
       "17       18/12/2022    Bank B  Awarded  \n",
       "18       18/12/2022    Bank B  Awarded  \n",
       "19       18/12/2022    Bank B  Awarded  \n",
       "20       18/12/2022    Bank B  Awarded  \n",
       "21       18/12/2022    Bank B  Awarded  \n",
       "22       18/12/2022    Bank B  Awarded  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_rfp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "documents = []\n",
    "\n",
    "# Iterate through each file path in the list\n",
    "for file_path in existing_rfp_paths:\n",
    "    loader = CSVLoader(\n",
    "        file_path=file_path,\n",
    "        metadata_columns=[\"Area\"]\n",
    "    )\n",
    "\n",
    "    # Load a document from the current CSV file\n",
    "    doc = loader.load()\n",
    "    \n",
    "    # Append documents\n",
    "    documents.extend(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `CSVLoader`, each document represents a single row and includes its respective contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 1\\nRFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\\nRFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of 95%.\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General'}\n",
      "Document 2: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 2\\nRFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?\\nRFP_Answer: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures that our applications remain innovative, with capabilities that adapt to evolving market demands and client needs. This approach has enabled us to enhance the predictive accuracy of our financial forecasting tools by 25% and improve the efficiency of our educational content personalization by 40%\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General'}\n",
      "Document 3: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 3\\nRFP_Question: Are your AI applications adaptable to specific requirements of users or businesses?\\nRFP_Answer: Absolutely, customization is a core aspect of our offering. We work closely with clients to understand their specific needs and tailor our AI algorithms and app functionalities accordingly, using technologies such as TensorFlow for machine learning models, React for responsive UI/UX designs, and Kubernetes for scalable cloud deployment. This personalized approach allows us to optimize AI functionalities to match unique business processes, enhancing user experience and operational efficiency for each client. For example, for a retail client, we customized our recommendation engine to increase customer retention by 20% through more accurate and personalized product suggestions.\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 2, 'Area': 'General'}\n",
      "Document 4: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 4\\nRFP_Question: What steps do you undertake to protect user privacy and secure data within your AI applications?\\nRFP_Answer: User privacy and data security are paramount. We implement robust measures such as end-to-end encryption to secure data transmissions, anonymization techniques to protect user identities, and comprehensive compliance with data protection laws like GDPR and CCPA. We also employ regular security audits and vulnerability assessments to ensure our systems are impenetrable. Additionally, our deployment of advanced intrusion detection systems and the use of secure coding practices reinforce our commitment to safeguarding user data at all times\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 3, 'Area': 'General'}\n",
      "Document 5: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 5\\nRFP_Question: What strategies do you employ to design user interfaces and experiences in AI applications to maximize usability and user engagement?\\nRFP_Answer: Our design philosophy centers on simplicity and intuitiveness. We conduct extensive user research and testing to inform our UI/UX designs, ensuring that our AI-based apps are accessible and engaging for all users, regardless of their technical expertise. This includes applying principles from human-centered design, utilizing accessibility guidelines such as WCAG 2.1, and conducting iterative testing with diverse user groups. Our commitment to inclusivity and usability leads to higher user adoption rates and satisfaction. For instance, feedback-driven enhancements in our visual design have improved user engagement by over 30% across our applications.\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 4, 'Area': 'General'}\n"
     ]
    }
   ],
   "source": [
    "number_of_documents = 5\n",
    "\n",
    "for i, document in enumerate(documents[:number_of_documents]):\n",
    "    print(f\"Document {i + 1}: {document}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the page content of each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page content for document 1:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 1\n",
      "RFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\n",
      "RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of 95%.\n",
      "Last_Accessed_At: 18/12/2022\n",
      "Requester: Bank B\n",
      "Status: Awarded\n",
      "\n",
      "Page content for document 2:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 2\n",
      "RFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?\n",
      "RFP_Answer: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures that our applications remain innovative, with capabilities that adapt to evolving market demands and client needs. This approach has enabled us to enhance the predictive accuracy of our financial forecasting tools by 25% and improve the efficiency of our educational content personalization by 40%\n",
      "Last_Accessed_At: 18/12/2022\n",
      "Requester: Bank B\n",
      "Status: Awarded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_documents = 2\n",
    "\n",
    "for i, document in enumerate(documents[:number_of_documents]):\n",
    "    print(f\"Page content for document {i + 1}:\")\n",
    "    print(document.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when adding metadata, it is appended to the default metadata, which consists of the row number and the source: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for document 1: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General'}\n",
      "Metadata for document 2: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General'}\n",
      "Metadata for document 3: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 2, 'Area': 'General'}\n",
      "Metadata for document 4: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 3, 'Area': 'General'}\n",
      "Metadata for document 5: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 4, 'Area': 'General'}\n"
     ]
    }
   ],
   "source": [
    "number_of_documents = 5\n",
    "\n",
    "for i, document in enumerate(documents[:number_of_documents]):\n",
    "    print(f\"Metadata for document {i + 1}: {document.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=10, add_start_index=True\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some general information about the chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 98\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the length of the bigger and smaller chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum chunk length: 499\n",
      "Minimum chunk length: 12\n",
      "Mean chunk length: 267.6020408163265\n"
     ]
    }
   ],
   "source": [
    "max_chunk_length = max([len(chunk.page_content) for chunk in chunks])\n",
    "min_chunk_length = min([len(chunk.page_content) for chunk in chunks])\n",
    "mean_chunk_length = sum([len(chunk.page_content) for chunk in chunks]) / len(chunks)\n",
    "\n",
    "print(f\"Maximum chunk length: {max_chunk_length}\")\n",
    "print(f\"Minimum chunk length: {min_chunk_length}\")\n",
    "print(f\"Mean chunk length: {mean_chunk_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of chunks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "variable=0<br>value=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "0",
         "nbinsx": 50,
         "offsetgroup": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          233,
          496,
          12,
          62,
          211,
          497,
          305,
          62,
          196,
          496,
          199,
          62,
          209,
          491,
          73,
          62,
          246,
          493,
          184,
          62,
          207,
          495,
          280,
          62,
          212,
          499,
          305,
          62,
          239,
          498,
          366,
          62,
          226,
          497,
          499,
          13,
          62,
          229,
          492,
          45,
          463,
          268,
          477,
          221,
          495,
          150,
          62,
          199,
          495,
          296,
          62,
          241,
          498,
          366,
          62,
          197,
          495,
          413,
          62,
          256,
          491,
          379,
          62,
          221,
          497,
          338,
          62,
          221,
          494,
          406,
          62,
          204,
          497,
          347,
          62,
          233,
          491,
          374,
          62,
          249,
          450,
          480,
          62,
          211,
          439,
          498,
          87,
          62,
          209,
          496,
          46,
          491,
          24,
          62,
          233,
          491,
          291,
          62
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "x": 499,
          "y": 0,
          "yshift": 10
         }
        ],
        "bargap": 0.2,
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of Chunk Lengths"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Chunk Length"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Calculate lengths of each chunk's page_content\n",
    "chunk_lengths = [len(chunk.page_content) for chunk in chunks]\n",
    "\n",
    "# Creating a histogram of chunk lengths\n",
    "fig = px.histogram(chunk_lengths, nbins=50, title=\"Distribution of Chunk Lengths\")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Chunk Length\",\n",
    "    yaxis_title=\"Count\",\n",
    "    bargap=0.2,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Add summary statistics as text on the plot\n",
    "fig.add_annotation(\n",
    "    x=max(chunk_lengths),\n",
    "    y=0,\n",
    "    showarrow=False,\n",
    "    yshift=10\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the chunks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 1\\nRFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 0}\n",
      "Chunk 2: page_content='RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 234}\n",
      "Chunk 3: page_content='rate of 95%.' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 723}\n",
      "Chunk 4: page_content='Last_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 736}\n"
     ]
    }
   ],
   "source": [
    "number_of_chunks = 5  \n",
    "\n",
    "for index, chunk in enumerate(chunks[:i]):\n",
    "    print(f\"Chunk {index + 1}: {chunk}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the page content of each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page content for chunk 1:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 1\n",
      "RFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\n",
      "\n",
      "Page content for chunk 2:\n",
      "RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of\n",
      "\n",
      "Page content for chunk 3:\n",
      "rate of 95%.\n",
      "\n",
      "Page content for chunk 4:\n",
      "Last_Accessed_At: 18/12/2022\n",
      "Requester: Bank B\n",
      "Status: Awarded\n",
      "\n",
      "Page content for chunk 5:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 2\n",
      "RFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_chunks = 5\n",
    "\n",
    "for i, document in enumerate(chunks[:number_of_chunks]):\n",
    "    print(f\"Page content for chunk {i + 1}:\")\n",
    "    print(document.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the metadata for individual chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for chunk 1: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 0}\n",
      "Metadata for chunk 2: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 234}\n",
      "Metadata for chunk 3: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 723}\n",
      "Metadata for chunk 4: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 736}\n",
      "Metadata for chunk 5: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "number_of_chunks = 5  \n",
    "\n",
    "for i, chunk in enumerate(chunks[:number_of_chunks]):\n",
    "    print(f\"Metadata for chunk {i + 1}: {chunk.metadata}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the source of each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source for chunk 1: datasets/rag/rfp_existing_questions_client_2.csv\n",
      "Source for chunk 2: datasets/rag/rfp_existing_questions_client_2.csv\n",
      "Source for chunk 3: datasets/rag/rfp_existing_questions_client_2.csv\n",
      "Source for chunk 4: datasets/rag/rfp_existing_questions_client_2.csv\n",
      "Source for chunk 5: datasets/rag/rfp_existing_questions_client_2.csv\n"
     ]
    }
   ],
   "source": [
    "number_of_chunks = 5  \n",
    "\n",
    "for i, chunk in enumerate(chunks[:number_of_chunks]):\n",
    "    print(f\"Source for chunk {i + 1}: {chunk.metadata['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store chunks into a vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  id</th><th>new_rfp                         </th><th>new_question  </th><th>question_to_llm  </th><th>answer  </th><th>ground_truth  </th><th>existing_rfp                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   1</td><td>rfp_new_questions_client_100.csv</td><td>What is your experience in developing AI-based\n",
       "applications, and can you provide examples of\n",
       "successful projects?               </td><td>What is the most similar question to: &quot;What is\n",
       "your experience in developing AI-based\n",
       "applications, and can you provide examples of\n",
       "successful projects?&quot;                  </td><td>None    </td><td>Can you discuss your expertise in creating AI-\n",
       "driven applications and share examples of your\n",
       "successful implementations?               </td><td>rfp_exisiting_questions_client_2.csv</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   2</td><td>rfp_new_questions_client_100.csv</td><td>How do you ensure your AI-based apps remain up-to-\n",
       "date with the latest AI advancements and\n",
       "technologies?               </td><td>What is the most similar question to: &quot;How do you\n",
       "ensure your AI-based apps remain up-to-date with\n",
       "the latest AI advancements and technologies?&quot;                  </td><td>None    </td><td>How do you keep your AI applications current with\n",
       "ongoing advancements in artificial intelligence?               </td><td>rfp_exisiting_questions_client_2.csv</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load all RFPs into a single pandas DataFrame\n",
    "\n",
    "rag_evaluation_df = pd.read_csv(\"datasets/rag/rag_evaluation_dataset_v1.csv\")\n",
    "\n",
    "display_nice(rag_evaluation_df, num_rows=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.0)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context. \n",
    "If you cannot answer the question with the context, please respond with 'I don't know':\n",
    "\n",
    "### CONTEXT\n",
    "{context}\n",
    "\n",
    "### QUESTION\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# Step 1: \"question\": Retrieved from the \"question\" key.\n",
    "# Step 2: \"context\": Retrieved from the \"question\" key and fed into the retriever.\n",
    "# Step 3: \"context\": Assigned to a RunnablePassthrough object using the \"context\" key from the previous step.\n",
    "# Step 4: \"answer\": \"context\" and \"question\" are combined to format the prompt, then sent to the LLM and stored under the \"answer\" key.\n",
    "# Step 5: \"context\": Repopulated using the \"context\" key from the previous step.\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0)\n",
    "\n",
    "rag_chain = (\n",
    "    \n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"answer\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask a question to test the chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': AIMessage(content='RFP_Question_ID: 1\\nRFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?', response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 2074, 'total_tokens': 2106}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_76f018034d', 'finish_reason': 'stop', 'logprobs': None}, id='run-91268de3-7ad9-4e91-b754-ac54fa72827c-0'), 'context': [Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 1\\nRFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?', metadata={'Area': 'General', 'row': 0, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 2\\nRFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?', metadata={'Area': 'General', 'row': 1, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of', metadata={'Area': 'General', 'row': 0, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 234}), Document(page_content='RFP_Answer: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures', metadata={'Area': 'General', 'row': 1, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 212}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 5\\nRFP_Question: What strategies do you employ to design user interfaces and experiences in AI applications to maximize usability and user engagement?', metadata={'Area': 'General', 'row': 4, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 7\\nRFP_Question: How do you evaluate the effectiveness and impact of your AI applications in achieving client goals?', metadata={'Area': 'General', 'row': 6, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 3\\nRFP_Question: Are your AI applications adaptable to specific requirements of users or businesses?', metadata={'Area': 'General', 'row': 2, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 13\\nRFP_Question: Can you provide case studies of successful LLM-based application deployments that outline encountered challenges and solutions?', metadata={'Area': 'Large Language Models', 'row': 12, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 4\\nRFP_Question: What steps do you undertake to protect user privacy and secure data within your AI applications?', metadata={'Area': 'General', 'row': 3, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 6\\nRFP_Question: Explain the support and maintenance services you offer for AI applications after they go live.', metadata={'Area': 'General', 'row': 5, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='RFP_Answer: We adhere to ethical AI practices by implementing bias detection and mitigation techniques during the training of our Large Language Models (LLMs). This involves using diverse datasets to prevent skewed results and deploying algorithms specifically designed to identify and correct bias in AI outputs. For data privacy, we employ data anonymization and secure data handling protocols, ensuring compliance with GDPR, CCPA, and other relevant regulations. Our systems use state-of-the-art', metadata={'Area': 'Large Language Models', 'row': 7, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 240}), Document(page_content='RFP_Answer: Our design philosophy centers on simplicity and intuitiveness. We conduct extensive user research and testing to inform our UI/UX designs, ensuring that our AI-based apps are accessible and engaging for all users, regardless of their technical expertise. This includes applying principles from human-centered design, utilizing accessibility guidelines such as WCAG 2.1, and conducting iterative testing with diverse user groups. Our commitment to inclusivity and usability leads to', metadata={'Area': 'General', 'row': 4, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 247}), Document(page_content='RFP_Answer: We conduct thorough assessments of AI systems and the people using AI within our organization. This process involves meticulously identifying potential risks such as data privacy, security, bias, and legal compliance. We assess both the impact and the likelihood of each identified risk to effectively prioritize them. Our approach includes the use of sophisticated tools and methodologies, such as risk matrices and scenario analysis, to quantify and categorize risks accurately. This', metadata={'Area': 'AI Regulation', 'row': 17, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 205}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 16\\nRFP_Question: How does your AI solution comply with the guidelines of the NIST AI RMF for responsible and trustworthy AI?', metadata={'Area': 'AI Regulation', 'row': 15, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 22\\nRFP_Question: How do you ensure compliance with U.S. laws on data privacy and security for your AI solutions?', metadata={'Area': 'AI Regulation', 'row': 21, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 23\\nRFP_Question: In what ways do you participate in advancing AI risk management practices, following the guidelines of the NIST AI RMF?', metadata={'Area': 'AI Regulation', 'row': 22, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content=\"Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 18\\nRFP_Question: How do you identify and evaluate AI risks following the 'Map' function of the NIST AI RMF?\", metadata={'Area': 'AI Regulation', 'row': 17, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='RFP_Answer: Absolutely, customization is a core aspect of our offering. We work closely with clients to understand their specific needs and tailor our AI algorithms and app functionalities accordingly, using technologies such as TensorFlow for machine learning models, React for responsive UI/UX designs, and Kubernetes for scalable cloud deployment. This personalized approach allows us to optimize AI functionalities to match unique business processes, enhancing user experience and operational', metadata={'Area': 'General', 'row': 2, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 197}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 15\\nRFP_Question: What are your strategies for supporting and maintaining LLM-based applications after deployment, including addressing model drift and updates?', metadata={'Area': 'Large Language Models', 'row': 14, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 19\\nRFP_Question: What steps do you implement to ensure AI decisions are transparent and explainable, in line with NIST AI RMF standards?', metadata={'Area': 'AI Regulation', 'row': 18, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0})]}\n"
     ]
    }
   ],
   "source": [
    "question = \"Find a similar question as this one: 'What is your experience in developing AI-based applications?'\"\n",
    "response = rag_chain.invoke({\"question\" : question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As defined in the earlier chat prompt, the RAG response includes two fields: `answer` and `context`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer\n",
      "context\n"
     ]
    }
   ],
   "source": [
    "print_dict_keys(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the answer, we see that the `rag_chain` is functioning correctly and identifies the most similar question in the `vectorstore`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Find a similar question as this one: 'What is your experience in developing AI-based applications?'\n",
      "\n",
      "Answer:\n",
      "RFP_Question_ID: 1\n",
      "RFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question:\")\n",
    "print(question)\n",
    "print()\n",
    "print(f\"Answer:\")\n",
    "print(response[\"answer\"].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inspect the content of the `answer` and the `context` retrieved based on the `question`. The context should contain `k` chunks, the most relevant based on the question. Remember that we set`k` in the `retriever` earlier. These `k` chunks are pasted into the prompt as text, informing the LLM to generate an answer that is closer in the embedding space to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content for chunk 1:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 1\n",
      "RFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\n",
      "\n",
      "Content for chunk 2:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 2\n",
      "RFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?\n",
      "\n",
      "Content for chunk 3:\n",
      "RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of\n",
      "\n",
      "Content for chunk 4:\n",
      "RFP_Answer: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures\n",
      "\n",
      "Content for chunk 5:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 5\n",
      "RFP_Question: What strategies do you employ to design user interfaces and experiences in AI applications to maximize usability and user engagement?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_chunks = 5  \n",
    "\n",
    "for i, chunk in enumerate(response[\"context\"][:number_of_chunks]):\n",
    "    print(f\"Content for chunk {i + 1}:\")  # i + 1 to start counting from 1 instead of 0\n",
    "    print(chunk.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now inspect the `response_metadata` object to understand its contents and identify what could be useful to incorporate in our RAG evaluation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_usage': {'completion_tokens': 32, 'prompt_tokens': 2074, 'total_tokens': 2106}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_76f018034d', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"].response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_usage\n",
      "    completion_tokens\n",
      "    prompt_tokens\n",
      "    total_tokens\n",
      "model_name\n",
      "system_fingerprint\n",
      "finish_reason\n",
      "logprobs\n"
     ]
    }
   ],
   "source": [
    "print_dict_keys(response[\"answer\"].response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the LLM used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gpt-4-turbo\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model: {response['answer'].response_metadata['model_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we showed earlier, we can also extract some token usage statistics that can help us understand and optimize our interactions with the language model for cost-effectiveness and efficiency.\n",
    "\n",
    "- **Prompt tokens**: tokens that form the input text sent to the language model. This includes all the text provided to the LLM to generate a response.\n",
    "- **Completion tokens**: number of tokens in the generated text or output from the model.\n",
    "- **Total tokens**: total number of tokens processed by the model. It is the sum of both `prompt_tokens` and `completion_tokens`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion tokens: 32\n",
      "Prompt tokens: 2074\n",
      "Total tokens: 2106\n"
     ]
    }
   ],
   "source": [
    "print(f\"Completion tokens: {response['answer'].response_metadata['token_usage']['completion_tokens']}\")\n",
    "print(f\"Prompt tokens: {response['answer'].response_metadata['token_usage']['prompt_tokens']}\")\n",
    "print(f\"Total tokens: {response['answer'].response_metadata['token_usage']['total_tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now expand our evaluation dataset to capture some metadata generated by the LLM, which will be used later when validating our RAG pipeline. We will add the following additional columns to our dataframe: `context`, `model_name`, `completion_tokens`, prompt_tokens, and `total_tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_evaluation_df['context'] = ''\n",
    "\n",
    "rag_evaluation_df['question_embeddings'] = ''\n",
    "rag_evaluation_df['answer_embeddings'] = ''\n",
    "rag_evaluation_df['context_embeddings'] = ''\n",
    "\n",
    "rag_evaluation_df['similarity_score_question_vs_context'] = ''\n",
    "rag_evaluation_df['similarity_score_question_vs_answer'] = ''\n",
    "rag_evaluation_df['similarity_score_context_vs_answer'] = ''\n",
    "\n",
    "rag_evaluation_df['model'] = ''\n",
    "\n",
    "rag_evaluation_df['completion_tokens'] = ''\n",
    "rag_evaluation_df['prompt_tokens'] = ''\n",
    "rag_evaluation_df['total_tokens'] = ''\n",
    "\n",
    "rag_evaluation_df['response_time'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to also compute few similarity metrics between embeddings such as cosine similaruty or euclidean distance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_score(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - embedding1 (array-like): Embedding of the first entity.\n",
    "    - embedding2 (array-like): Embedding of the second entity.\n",
    "\n",
    "    Returns:\n",
    "    - float: Cosine similarity score between the two embeddings.\n",
    "\n",
    "    Note: The order of the embeddings does not affect the result as cosine similarity is symmetric.\n",
    "    \"\"\"\n",
    "    # Ensure the embeddings are reshaped to 2D arrays for sklearn's cosine_similarity\n",
    "    embedding1 = np.array(embedding1).reshape(1, -1)\n",
    "    embedding2 = np.array(embedding2).reshape(1, -1)\n",
    "\n",
    "    # Calculate and return the cosine similarity\n",
    "    return cosine_similarity(embedding1, embedding2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Computes the Euclidean distance between two embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - embedding1 (array-like): First embedding vector.\n",
    "    - embedding2 (array-like): Second embedding vector.\n",
    "\n",
    "    Returns:\n",
    "    - float: Euclidean distance between the two embeddings.\n",
    "    \"\"\"\n",
    "    # Convert inputs to NumPy arrays if they aren't already\n",
    "    embedding1 = np.array(embedding1)\n",
    "    embedding2 = np.array(embedding2)\n",
    "    \n",
    "    # Calculate and return the Euclidean distance\n",
    "    return np.linalg.norm(embedding1 - embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0...\n",
      "Answer is 'None' for question ID 0. Invoking RAG model...\n",
      "Question ID 0 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 1...\n",
      "Answer is 'None' for question ID 1. Invoking RAG model...\n",
      "Question ID 1 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 2...\n",
      "Answer is 'None' for question ID 2. Invoking RAG model...\n",
      "Question ID 2 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 3...\n",
      "Answer is 'None' for question ID 3. Invoking RAG model...\n",
      "Question ID 3 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 4...\n",
      "Answer is 'None' for question ID 4. Invoking RAG model...\n",
      "Question ID 4 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 5...\n",
      "Answer is 'None' for question ID 5. Invoking RAG model...\n",
      "Question ID 5 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 6...\n",
      "Answer is 'None' for question ID 6. Invoking RAG model...\n",
      "Question ID 6 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 7...\n",
      "Answer is 'None' for question ID 7. Invoking RAG model...\n",
      "Question ID 7 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 8...\n",
      "Answer is 'None' for question ID 8. Invoking RAG model...\n",
      "Question ID 8 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 9...\n",
      "Answer is 'None' for question ID 9. Invoking RAG model...\n",
      "Question ID 9 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 10...\n",
      "Answer is 'None' for question ID 10. Invoking RAG model...\n",
      "Question ID 10 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 11...\n",
      "Answer is 'None' for question ID 11. Invoking RAG model...\n",
      "Question ID 11 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 12...\n",
      "Answer is 'None' for question ID 12. Invoking RAG model...\n",
      "Question ID 12 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 13...\n",
      "Answer is 'None' for question ID 13. Invoking RAG model...\n",
      "Question ID 13 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 14...\n",
      "Answer is 'None' for question ID 14. Invoking RAG model...\n",
      "Question ID 14 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 15...\n",
      "Answer is 'None' for question ID 15. Invoking RAG model...\n",
      "Question ID 15 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 16...\n",
      "Answer is 'None' for question ID 16. Invoking RAG model...\n",
      "Question ID 16 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 17...\n",
      "Answer is 'None' for question ID 17. Invoking RAG model...\n",
      "Question ID 17 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 18...\n",
      "Answer is 'None' for question ID 18. Invoking RAG model...\n",
      "Question ID 18 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 19...\n",
      "Answer is 'None' for question ID 19. Invoking RAG model...\n",
      "Question ID 19 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 20...\n",
      "Answer is 'None' for question ID 20. Invoking RAG model...\n",
      "Question ID 20 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 21...\n",
      "Answer is 'None' for question ID 21. Invoking RAG model...\n",
      "Question ID 21 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing row 22...\n",
      "Answer is 'None' for question ID 22. Invoking RAG model...\n",
      "Question ID 22 answer updated with the response from the RAG model.\n",
      "Computing embeddings for the question...\n",
      "Computing embeddings for the context...\n",
      "Computing embeddings for the answer...\n",
      "Computing cosine similarity between question and context...\n",
      "Computing cosine similarity between question and answer...\n",
      "Computing cosine similarity between context and answer...\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "number_of_iterations = 23\n",
    "\n",
    "for i, (index, row) in enumerate(rag_evaluation_df.iloc[:number_of_iterations].iterrows()):\n",
    "    print(f\"Processing row {i}...\")\n",
    "\n",
    "    # Check if the 'answer' field is 'None' (as a string) for the current row\n",
    "    if row[\"answer\"] == \"None\":\n",
    "        print(f\"Answer is 'None' for question ID {index}. Invoking RAG model...\")\n",
    "\n",
    "        start_time = time.time()  # Start timing\n",
    "        \n",
    "        # Invoke the RAG model with the question from the current row\n",
    "        response = rag_chain.invoke({\"question\": row[\"question_to_llm\"]})\n",
    "\n",
    "        end_time = time.time()  # End timing\n",
    "\n",
    "        # Calculate the response time and store it\n",
    "        rag_evaluation_df.at[index, 'response_time'] = round(end_time - start_time, 1)\n",
    "\n",
    "        # Store whatever response comes from the LLM\n",
    "        rag_evaluation_df.at[index, \"answer\"] = response[\"answer\"].content\n",
    "        print(f\"Question ID {index} answer updated with the response from the RAG model.\")\n",
    "    \n",
    "        # Store the context included in the prompt\n",
    "        context = \"\\n\\n\".join(chunk.page_content for chunk in response[\"context\"])\n",
    "        rag_evaluation_df.at[index, \"context\"] = context\n",
    "        \n",
    "        # Compute and store embeddings for the question, context and answer\n",
    "        print(\"Computing embeddings for the question...\")\n",
    "        question_embeddings = np.array(embeddings_model.embed_query(row[\"question_to_llm\"]))\n",
    "        rag_evaluation_df.at[index, 'question_embeddings'] = question_embeddings\n",
    "        \n",
    "        print(\"Computing embeddings for the context...\")\n",
    "        context_embeddings = np.array(embeddings_model.embed_query(context))\n",
    "        rag_evaluation_df.at[index, 'context_embeddings'] = context_embeddings\n",
    "        \n",
    "        print(\"Computing embeddings for the answer...\")\n",
    "        answer_embeddings = np.array(embeddings_model.embed_query(response[\"answer\"].content))\n",
    "        rag_evaluation_df.at[index, 'answer_embeddings'] = answer_embeddings\n",
    "        \n",
    "        # Compute similarity measures between embeddings \n",
    "        print(\"Computing cosine similarity between question and context...\")\n",
    "        rag_evaluation_df.at[index, 'similarity_score_question_vs_context'] = cosine_similarity_score(question_embeddings, context_embeddings)\n",
    "        \n",
    "        print(\"Computing cosine similarity between question and answer...\")\n",
    "        rag_evaluation_df.at[index, 'similarity_score_question_vs_answer'] = cosine_similarity_score(question_embeddings, answer_embeddings)\n",
    "\n",
    "        print(\"Computing cosine similarity between context and answer...\")\n",
    "        rag_evaluation_df.at[index, 'similarity_score_context_vs_answer'] = cosine_similarity_score(context_embeddings, answer_embeddings)\n",
    "        \n",
    "        # Store some metadata such as model name and tokens statistics\n",
    "        rag_evaluation_df.at[index, \"model\"] = response[\"answer\"].response_metadata[\"model_name\"]\n",
    "        rag_evaluation_df.at[index, \"completion_tokens\"] = response['answer'].response_metadata['token_usage']['completion_tokens']\n",
    "        rag_evaluation_df.at[index, \"prompt_tokens\"] = response['answer'].response_metadata['token_usage']['prompt_tokens']\n",
    "        rag_evaluation_df.at[index, \"total_tokens\"] = response['answer'].response_metadata['token_usage']['total_tokens']\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>new_rfp</th>\n",
       "      <th>new_question</th>\n",
       "      <th>question_to_llm</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>existing_rfp</th>\n",
       "      <th>context</th>\n",
       "      <th>question_embeddings</th>\n",
       "      <th>answer_embeddings</th>\n",
       "      <th>context_embeddings</th>\n",
       "      <th>similarity_score_question_vs_context</th>\n",
       "      <th>similarity_score_question_vs_answer</th>\n",
       "      <th>similarity_score_context_vs_answer</th>\n",
       "      <th>model</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>What is your experience in developing AI-based...</td>\n",
       "      <td>What is the most similar question to: \"What is...</td>\n",
       "      <td>RFP_Question_ID: 1\\nRFP_Question: Can you disc...</td>\n",
       "      <td>Can you discuss your expertise in creating AI-...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.012242779808196847, -0.02875495641236209, ...</td>\n",
       "      <td>[0.0310747014081873, -0.027107230157425624, 0....</td>\n",
       "      <td>[-0.002070941676414154, 0.016138519678307824, ...</td>\n",
       "      <td>0.585144</td>\n",
       "      <td>0.725917</td>\n",
       "      <td>0.69799</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>32</td>\n",
       "      <td>2050</td>\n",
       "      <td>2082</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How do you ensure your AI-based apps remain up...</td>\n",
       "      <td>What is the most similar question to: \"How do ...</td>\n",
       "      <td>RFP_Question: How do you keep your AI applicat...</td>\n",
       "      <td>How do you keep your AI applications current w...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.021238304961058666, -0.002903160656478289,...</td>\n",
       "      <td>[0.009167934150736499, 0.004675850898067104, 0...</td>\n",
       "      <td>[0.003495793715123486, 0.029037076361042993, 0...</td>\n",
       "      <td>0.583265</td>\n",
       "      <td>0.783871</td>\n",
       "      <td>0.681394</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>20</td>\n",
       "      <td>2178</td>\n",
       "      <td>2198</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>Can your AI-based applications be customized t...</td>\n",
       "      <td>What is the most similar question to: \"Can you...</td>\n",
       "      <td>RFP_Question: Are your AI applications adaptab...</td>\n",
       "      <td>Are your AI applications adaptable to specific...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>RFP_Answer: Absolutely, customization is a cor...</td>\n",
       "      <td>[-0.024933725810230647, -0.00398689651570446, ...</td>\n",
       "      <td>[-0.009066043640488342, 0.004352435574698996, ...</td>\n",
       "      <td>[0.00557660436251417, 0.017872921644696806, 0....</td>\n",
       "      <td>0.544418</td>\n",
       "      <td>0.724164</td>\n",
       "      <td>0.650534</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>18</td>\n",
       "      <td>2110</td>\n",
       "      <td>2128</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>What measures do you take to ensure user priva...</td>\n",
       "      <td>What is the most similar question to: \"What me...</td>\n",
       "      <td>RFP_Question: What steps do you undertake to p...</td>\n",
       "      <td>What steps do you undertake to protect user pr...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.011542554119771953, -0.012979928523676116,...</td>\n",
       "      <td>[0.01756528858249858, -0.0021651658480433076, ...</td>\n",
       "      <td>[0.005625466015599571, 0.027107654769665805, 0...</td>\n",
       "      <td>0.614859</td>\n",
       "      <td>0.763888</td>\n",
       "      <td>0.690945</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>22</td>\n",
       "      <td>2136</td>\n",
       "      <td>2158</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How do you approach user interface and experie...</td>\n",
       "      <td>What is the most similar question to: \"How do ...</td>\n",
       "      <td>RFP_Question: What strategies do you employ to...</td>\n",
       "      <td>What strategies do you employ to design user i...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>RFP_Answer: Our design philosophy centers on s...</td>\n",
       "      <td>[-0.022403337192397944, -0.003745948452053383,...</td>\n",
       "      <td>[0.012766196768228667, 0.02172657166295028, 0....</td>\n",
       "      <td>[0.003870411601094043, 0.020839706984124785, 0...</td>\n",
       "      <td>0.498187</td>\n",
       "      <td>0.790653</td>\n",
       "      <td>0.596217</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>26</td>\n",
       "      <td>2100</td>\n",
       "      <td>2126</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>Describe your support and maintenance services...</td>\n",
       "      <td>What is the most similar question to: \"Describ...</td>\n",
       "      <td>RFP_Question_ID: 6\\nRFP_Question: Explain the ...</td>\n",
       "      <td>Explain the support and maintenance services y...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.02591718013947877, 0.026053946723562156, 0...</td>\n",
       "      <td>[0.0030569415769184254, 0.032351002340196805, ...</td>\n",
       "      <td>[-0.004738790191233332, 0.012303232755733858, ...</td>\n",
       "      <td>0.574956</td>\n",
       "      <td>0.769456</td>\n",
       "      <td>0.641872</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>30</td>\n",
       "      <td>2080</td>\n",
       "      <td>2110</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How do you measure the success and impact of y...</td>\n",
       "      <td>What is the most similar question to: \"How do ...</td>\n",
       "      <td>The most similar question to \"How do you measu...</td>\n",
       "      <td>How do you evaluate the effectiveness and impa...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.005094874094156965, -0.0018191395470256865...</td>\n",
       "      <td>[-0.00878038568775405, -0.009270509111679268, ...</td>\n",
       "      <td>[0.0035890195577847014, 0.0202937935330464, 0....</td>\n",
       "      <td>0.590167</td>\n",
       "      <td>0.939786</td>\n",
       "      <td>0.617473</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>53</td>\n",
       "      <td>2035</td>\n",
       "      <td>2088</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How do you ensure the ethical use of LLMs in y...</td>\n",
       "      <td>What is the most similar question to: \"How do ...</td>\n",
       "      <td>RFP_Question_ID: 8\\nRFP_Question: How do you m...</td>\n",
       "      <td>How do you manage ethical concerns in your LLM...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[0.021570483446575122, 0.014879887146777028, 0...</td>\n",
       "      <td>[0.026099357489269805, 0.012381280646806315, 0...</td>\n",
       "      <td>[0.006703774816147418, 0.014809646435435513, 0...</td>\n",
       "      <td>0.617357</td>\n",
       "      <td>0.829949</td>\n",
       "      <td>0.669105</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>37</td>\n",
       "      <td>2063</td>\n",
       "      <td>2100</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>Can you describe the process of training your ...</td>\n",
       "      <td>What is the most similar question to: \"Can you...</td>\n",
       "      <td>RFP_Question_ID: 9\\nRFP_Question: Could you ou...</td>\n",
       "      <td>Could you outline how you train your LLMs, inc...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.02396939689706394, 0.018455669672488594, 0...</td>\n",
       "      <td>[0.011562094135351562, 0.019687660111660777, 0...</td>\n",
       "      <td>[0.013534342148055555, 0.016004392023382625, 0...</td>\n",
       "      <td>0.568258</td>\n",
       "      <td>0.761843</td>\n",
       "      <td>0.668359</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>38</td>\n",
       "      <td>2199</td>\n",
       "      <td>2237</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How do you handle the continuous learning and ...</td>\n",
       "      <td>What is the most similar question to: \"How do ...</td>\n",
       "      <td>The most similar question to \"How do you handl...</td>\n",
       "      <td>How do you ensure your LLMs continuously learn...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.008237089426533709, 0.02109827336666294, 0...</td>\n",
       "      <td>[-0.014028603505788242, 0.019560468426855514, ...</td>\n",
       "      <td>[0.011712163709805153, 0.005895829305481538, 0...</td>\n",
       "      <td>0.527055</td>\n",
       "      <td>0.956986</td>\n",
       "      <td>0.53162</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>58</td>\n",
       "      <td>2203</td>\n",
       "      <td>2261</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>What measures do you take to ensure the transp...</td>\n",
       "      <td>What is the most similar question to: \"What me...</td>\n",
       "      <td>RFP_Question: What actions do you take to make...</td>\n",
       "      <td>What actions do you take to make the decision-...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.013587386723794776, 0.00556639885149576, 0...</td>\n",
       "      <td>[-0.014100776926247227, 0.028742851604862004, ...</td>\n",
       "      <td>[0.007159265695977494, 0.03300717103463557, 0....</td>\n",
       "      <td>0.606615</td>\n",
       "      <td>0.790901</td>\n",
       "      <td>0.586791</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>25</td>\n",
       "      <td>2135</td>\n",
       "      <td>2160</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How do you assess and ensure the performance a...</td>\n",
       "      <td>What is the most similar question to: \"How do ...</td>\n",
       "      <td>RFP_Question: How do you verify and ensure tha...</td>\n",
       "      <td>How do you verify and ensure that your LLMs ca...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>RFP_Answer: We conduct extensive performance t...</td>\n",
       "      <td>[-0.011384415804847862, 0.01486040978785559, 0...</td>\n",
       "      <td>[0.010212780634484725, 0.04281626527186002, 0....</td>\n",
       "      <td>[0.004137188261680031, 0.013544679833804111, 0...</td>\n",
       "      <td>0.573402</td>\n",
       "      <td>0.74141</td>\n",
       "      <td>0.568094</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>22</td>\n",
       "      <td>2108</td>\n",
       "      <td>2130</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>Can you provide examples of successful deploym...</td>\n",
       "      <td>What is the most similar question to: \"Can you...</td>\n",
       "      <td>The most similar question to \"Can you provide ...</td>\n",
       "      <td>Can you provide case studies of successful LLM...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>RFP_Answer: We can share case studies of succe...</td>\n",
       "      <td>[0.0053169715833493916, -0.006949637731748671,...</td>\n",
       "      <td>[0.010576286517614232, 0.0059551452625119725, ...</td>\n",
       "      <td>[0.006603175100025997, 0.005670396432022413, 0...</td>\n",
       "      <td>0.628482</td>\n",
       "      <td>0.951312</td>\n",
       "      <td>0.635016</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>52</td>\n",
       "      <td>2029</td>\n",
       "      <td>2081</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>What is your approach to integrating LLMs with...</td>\n",
       "      <td>What is the most similar question to: \"What is...</td>\n",
       "      <td>RFP_Question: Describe how you integrate LLMs ...</td>\n",
       "      <td>Describe how you integrate LLMs into existing ...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>RFP_Answer: Our approach involves conducting a...</td>\n",
       "      <td>[-0.020124713429307745, -0.0004988097469494085...</td>\n",
       "      <td>[-0.00464839980914793, 0.02650004513693912, 0....</td>\n",
       "      <td>[0.004213855229464925, 0.009941181388020852, 0...</td>\n",
       "      <td>0.562789</td>\n",
       "      <td>0.744559</td>\n",
       "      <td>0.614149</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>19</td>\n",
       "      <td>2082</td>\n",
       "      <td>2101</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How do you plan to support and maintain LLM-ba...</td>\n",
       "      <td>What is the most similar question to: \"How do ...</td>\n",
       "      <td>The most similar question to \"How do you plan ...</td>\n",
       "      <td>What are your strategies for supporting and ma...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>RFP_Answer: Our post-deployment support is des...</td>\n",
       "      <td>[-0.007420965991490901, 0.04956698082175351, 0...</td>\n",
       "      <td>[-0.007432110970636761, 0.03926498761186463, 0...</td>\n",
       "      <td>[-0.00036490626566094, 0.02311671491491352, 0....</td>\n",
       "      <td>0.631476</td>\n",
       "      <td>0.961636</td>\n",
       "      <td>0.664236</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>59</td>\n",
       "      <td>2126</td>\n",
       "      <td>2185</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How does your AI solution align with the NIST ...</td>\n",
       "      <td>What is the most similar question to: \"How doe...</td>\n",
       "      <td>RFP_Question: How does your AI solution comply...</td>\n",
       "      <td>How does your AI solution comply with the guid...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>RFP_Answer: Our AI solution is meticulously de...</td>\n",
       "      <td>[-0.024076844192504537, 0.004061743862669836, ...</td>\n",
       "      <td>[0.0034582621035253716, 0.018990318172255122, ...</td>\n",
       "      <td>[0.003314178674187951, 0.009757730437193744, 0...</td>\n",
       "      <td>0.676642</td>\n",
       "      <td>0.843948</td>\n",
       "      <td>0.735881</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>27</td>\n",
       "      <td>2068</td>\n",
       "      <td>2095</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>Can you describe the governance structures you...</td>\n",
       "      <td>What is the most similar question to: \"Can you...</td>\n",
       "      <td>RFP_Question: Could you describe the governanc...</td>\n",
       "      <td>Could you describe the governance frameworks y...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.008052477280807952, 0.033308541890396996, ...</td>\n",
       "      <td>[0.010880410513588184, 0.017498636364719343, 0...</td>\n",
       "      <td>[0.0030195862950919148, 0.021052473157487695, ...</td>\n",
       "      <td>0.670413</td>\n",
       "      <td>0.836631</td>\n",
       "      <td>0.727574</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>27</td>\n",
       "      <td>2060</td>\n",
       "      <td>2087</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How do you identify and assess AI risks in lin...</td>\n",
       "      <td>What is the most similar question to: \"How do ...</td>\n",
       "      <td>RFP_Question_ID: 18\\nRFP_Question: How do you ...</td>\n",
       "      <td>How do you identify and evaluate AI risks foll...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.02460394761122877, 0.022054107706891476, 0...</td>\n",
       "      <td>[0.0015179464477811156, 0.033250256609367417, ...</td>\n",
       "      <td>[0.009768373907393227, 0.024222591007012875, 0...</td>\n",
       "      <td>0.656444</td>\n",
       "      <td>0.877607</td>\n",
       "      <td>0.712226</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>36</td>\n",
       "      <td>2006</td>\n",
       "      <td>2042</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>What measures do you take to ensure transparen...</td>\n",
       "      <td>What is the most similar question to: \"What me...</td>\n",
       "      <td>RFP_Question: What steps do you implement to e...</td>\n",
       "      <td>What steps do you implement to ensure AI decis...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.01298543116888274, 0.012363928901313223, 0...</td>\n",
       "      <td>[-0.007185383545431859, 0.026770268922978437, ...</td>\n",
       "      <td>[0.0047528350521155675, 0.027148538019591564, ...</td>\n",
       "      <td>0.682818</td>\n",
       "      <td>0.82312</td>\n",
       "      <td>0.729036</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>30</td>\n",
       "      <td>2156</td>\n",
       "      <td>2186</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How do you track and measure exposure to AI ri...</td>\n",
       "      <td>What is the most similar question to: \"How do ...</td>\n",
       "      <td>RFP_Question: How do you monitor and assess AI...</td>\n",
       "      <td>How do you monitor and assess AI risk exposure...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.017150190231389383, 0.009718005830936486, ...</td>\n",
       "      <td>[0.007095605286568667, 0.030860055734765315, 0...</td>\n",
       "      <td>[0.0032891564784606232, 0.015881662633439708, ...</td>\n",
       "      <td>0.599095</td>\n",
       "      <td>0.840924</td>\n",
       "      <td>0.704434</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>36</td>\n",
       "      <td>2075</td>\n",
       "      <td>2111</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>Describe how your AI solutions manage and miti...</td>\n",
       "      <td>What is the most similar question to: \"Describ...</td>\n",
       "      <td>RFP_Question_ID: 21\\nRFP_Question: Explain how...</td>\n",
       "      <td>Explain how you manage and mitigate AI risks i...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.025189838097553253, 0.040055336375701724, ...</td>\n",
       "      <td>[0.01807079358525926, 0.04915548573583894, 0.0...</td>\n",
       "      <td>[0.004329927746834291, 0.02350532271947371, 0....</td>\n",
       "      <td>0.688308</td>\n",
       "      <td>0.811194</td>\n",
       "      <td>0.744222</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>37</td>\n",
       "      <td>2045</td>\n",
       "      <td>2082</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>How do you ensure that your AI solutions are c...</td>\n",
       "      <td>What is the most similar question to: \"How do ...</td>\n",
       "      <td>The most similar question to \"How do you ensur...</td>\n",
       "      <td>How do you ensure compliance with U.S. laws on...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.000199194390609713, 0.004925684748433598, ...</td>\n",
       "      <td>[-0.0008818536311500733, 0.012060341443225833,...</td>\n",
       "      <td>[0.010784785109801695, 0.03256630851188828, 0....</td>\n",
       "      <td>0.64035</td>\n",
       "      <td>0.94528</td>\n",
       "      <td>0.634112</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>54</td>\n",
       "      <td>2151</td>\n",
       "      <td>2205</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>rfp_new_questions_client_100.csv</td>\n",
       "      <td>In what ways do you contribute to the continua...</td>\n",
       "      <td>What is the most similar question to: \"In what...</td>\n",
       "      <td>The most similar question to \"In what ways do ...</td>\n",
       "      <td>In what ways do you participate in advancing A...</td>\n",
       "      <td>rfp_exisiting_questions_client_2.csv</td>\n",
       "      <td>Project_Title: AI-Powered Risk Assessment Mode...</td>\n",
       "      <td>[-0.012498520688869403, -0.0037221299667366658...</td>\n",
       "      <td>[-0.02664997184745821, -0.010097080623255343, ...</td>\n",
       "      <td>[0.009309162053996218, 0.013277804937123123, 0...</td>\n",
       "      <td>0.669713</td>\n",
       "      <td>0.946756</td>\n",
       "      <td>0.666294</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>63</td>\n",
       "      <td>2073</td>\n",
       "      <td>2136</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                           new_rfp  \\\n",
       "0    1  rfp_new_questions_client_100.csv   \n",
       "1    2  rfp_new_questions_client_100.csv   \n",
       "2    3  rfp_new_questions_client_100.csv   \n",
       "3    4  rfp_new_questions_client_100.csv   \n",
       "4    5  rfp_new_questions_client_100.csv   \n",
       "5    6  rfp_new_questions_client_100.csv   \n",
       "6    7  rfp_new_questions_client_100.csv   \n",
       "7    8  rfp_new_questions_client_100.csv   \n",
       "8    9  rfp_new_questions_client_100.csv   \n",
       "9   10  rfp_new_questions_client_100.csv   \n",
       "10  11  rfp_new_questions_client_100.csv   \n",
       "11  12  rfp_new_questions_client_100.csv   \n",
       "12  13  rfp_new_questions_client_100.csv   \n",
       "13  14  rfp_new_questions_client_100.csv   \n",
       "14  15  rfp_new_questions_client_100.csv   \n",
       "15  16  rfp_new_questions_client_100.csv   \n",
       "16  17  rfp_new_questions_client_100.csv   \n",
       "17  18  rfp_new_questions_client_100.csv   \n",
       "18  19  rfp_new_questions_client_100.csv   \n",
       "19  20  rfp_new_questions_client_100.csv   \n",
       "20  21  rfp_new_questions_client_100.csv   \n",
       "21  22  rfp_new_questions_client_100.csv   \n",
       "22  23  rfp_new_questions_client_100.csv   \n",
       "\n",
       "                                         new_question  \\\n",
       "0   What is your experience in developing AI-based...   \n",
       "1   How do you ensure your AI-based apps remain up...   \n",
       "2   Can your AI-based applications be customized t...   \n",
       "3   What measures do you take to ensure user priva...   \n",
       "4   How do you approach user interface and experie...   \n",
       "5   Describe your support and maintenance services...   \n",
       "6   How do you measure the success and impact of y...   \n",
       "7   How do you ensure the ethical use of LLMs in y...   \n",
       "8   Can you describe the process of training your ...   \n",
       "9   How do you handle the continuous learning and ...   \n",
       "10  What measures do you take to ensure the transp...   \n",
       "11  How do you assess and ensure the performance a...   \n",
       "12  Can you provide examples of successful deploym...   \n",
       "13  What is your approach to integrating LLMs with...   \n",
       "14  How do you plan to support and maintain LLM-ba...   \n",
       "15  How does your AI solution align with the NIST ...   \n",
       "16  Can you describe the governance structures you...   \n",
       "17  How do you identify and assess AI risks in lin...   \n",
       "18  What measures do you take to ensure transparen...   \n",
       "19  How do you track and measure exposure to AI ri...   \n",
       "20  Describe how your AI solutions manage and miti...   \n",
       "21  How do you ensure that your AI solutions are c...   \n",
       "22  In what ways do you contribute to the continua...   \n",
       "\n",
       "                                      question_to_llm  \\\n",
       "0   What is the most similar question to: \"What is...   \n",
       "1   What is the most similar question to: \"How do ...   \n",
       "2   What is the most similar question to: \"Can you...   \n",
       "3   What is the most similar question to: \"What me...   \n",
       "4   What is the most similar question to: \"How do ...   \n",
       "5   What is the most similar question to: \"Describ...   \n",
       "6   What is the most similar question to: \"How do ...   \n",
       "7   What is the most similar question to: \"How do ...   \n",
       "8   What is the most similar question to: \"Can you...   \n",
       "9   What is the most similar question to: \"How do ...   \n",
       "10  What is the most similar question to: \"What me...   \n",
       "11  What is the most similar question to: \"How do ...   \n",
       "12  What is the most similar question to: \"Can you...   \n",
       "13  What is the most similar question to: \"What is...   \n",
       "14  What is the most similar question to: \"How do ...   \n",
       "15  What is the most similar question to: \"How doe...   \n",
       "16  What is the most similar question to: \"Can you...   \n",
       "17  What is the most similar question to: \"How do ...   \n",
       "18  What is the most similar question to: \"What me...   \n",
       "19  What is the most similar question to: \"How do ...   \n",
       "20  What is the most similar question to: \"Describ...   \n",
       "21  What is the most similar question to: \"How do ...   \n",
       "22  What is the most similar question to: \"In what...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   RFP_Question_ID: 1\\nRFP_Question: Can you disc...   \n",
       "1   RFP_Question: How do you keep your AI applicat...   \n",
       "2   RFP_Question: Are your AI applications adaptab...   \n",
       "3   RFP_Question: What steps do you undertake to p...   \n",
       "4   RFP_Question: What strategies do you employ to...   \n",
       "5   RFP_Question_ID: 6\\nRFP_Question: Explain the ...   \n",
       "6   The most similar question to \"How do you measu...   \n",
       "7   RFP_Question_ID: 8\\nRFP_Question: How do you m...   \n",
       "8   RFP_Question_ID: 9\\nRFP_Question: Could you ou...   \n",
       "9   The most similar question to \"How do you handl...   \n",
       "10  RFP_Question: What actions do you take to make...   \n",
       "11  RFP_Question: How do you verify and ensure tha...   \n",
       "12  The most similar question to \"Can you provide ...   \n",
       "13  RFP_Question: Describe how you integrate LLMs ...   \n",
       "14  The most similar question to \"How do you plan ...   \n",
       "15  RFP_Question: How does your AI solution comply...   \n",
       "16  RFP_Question: Could you describe the governanc...   \n",
       "17  RFP_Question_ID: 18\\nRFP_Question: How do you ...   \n",
       "18  RFP_Question: What steps do you implement to e...   \n",
       "19  RFP_Question: How do you monitor and assess AI...   \n",
       "20  RFP_Question_ID: 21\\nRFP_Question: Explain how...   \n",
       "21  The most similar question to \"How do you ensur...   \n",
       "22  The most similar question to \"In what ways do ...   \n",
       "\n",
       "                                         ground_truth  \\\n",
       "0   Can you discuss your expertise in creating AI-...   \n",
       "1   How do you keep your AI applications current w...   \n",
       "2   Are your AI applications adaptable to specific...   \n",
       "3   What steps do you undertake to protect user pr...   \n",
       "4   What strategies do you employ to design user i...   \n",
       "5   Explain the support and maintenance services y...   \n",
       "6   How do you evaluate the effectiveness and impa...   \n",
       "7   How do you manage ethical concerns in your LLM...   \n",
       "8   Could you outline how you train your LLMs, inc...   \n",
       "9   How do you ensure your LLMs continuously learn...   \n",
       "10  What actions do you take to make the decision-...   \n",
       "11  How do you verify and ensure that your LLMs ca...   \n",
       "12  Can you provide case studies of successful LLM...   \n",
       "13  Describe how you integrate LLMs into existing ...   \n",
       "14  What are your strategies for supporting and ma...   \n",
       "15  How does your AI solution comply with the guid...   \n",
       "16  Could you describe the governance frameworks y...   \n",
       "17  How do you identify and evaluate AI risks foll...   \n",
       "18  What steps do you implement to ensure AI decis...   \n",
       "19  How do you monitor and assess AI risk exposure...   \n",
       "20  Explain how you manage and mitigate AI risks i...   \n",
       "21  How do you ensure compliance with U.S. laws on...   \n",
       "22  In what ways do you participate in advancing A...   \n",
       "\n",
       "                            existing_rfp  \\\n",
       "0   rfp_exisiting_questions_client_2.csv   \n",
       "1   rfp_exisiting_questions_client_2.csv   \n",
       "2   rfp_exisiting_questions_client_2.csv   \n",
       "3   rfp_exisiting_questions_client_2.csv   \n",
       "4   rfp_exisiting_questions_client_2.csv   \n",
       "5   rfp_exisiting_questions_client_2.csv   \n",
       "6   rfp_exisiting_questions_client_2.csv   \n",
       "7   rfp_exisiting_questions_client_2.csv   \n",
       "8   rfp_exisiting_questions_client_2.csv   \n",
       "9   rfp_exisiting_questions_client_2.csv   \n",
       "10  rfp_exisiting_questions_client_2.csv   \n",
       "11  rfp_exisiting_questions_client_2.csv   \n",
       "12  rfp_exisiting_questions_client_2.csv   \n",
       "13  rfp_exisiting_questions_client_2.csv   \n",
       "14  rfp_exisiting_questions_client_2.csv   \n",
       "15  rfp_exisiting_questions_client_2.csv   \n",
       "16  rfp_exisiting_questions_client_2.csv   \n",
       "17  rfp_exisiting_questions_client_2.csv   \n",
       "18  rfp_exisiting_questions_client_2.csv   \n",
       "19  rfp_exisiting_questions_client_2.csv   \n",
       "20  rfp_exisiting_questions_client_2.csv   \n",
       "21  rfp_exisiting_questions_client_2.csv   \n",
       "22  rfp_exisiting_questions_client_2.csv   \n",
       "\n",
       "                                              context  \\\n",
       "0   Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "1   Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "2   RFP_Answer: Absolutely, customization is a cor...   \n",
       "3   Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "4   RFP_Answer: Our design philosophy centers on s...   \n",
       "5   Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "6   Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "7   Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "8   Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "9   Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "10  Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "11  RFP_Answer: We conduct extensive performance t...   \n",
       "12  RFP_Answer: We can share case studies of succe...   \n",
       "13  RFP_Answer: Our approach involves conducting a...   \n",
       "14  RFP_Answer: Our post-deployment support is des...   \n",
       "15  RFP_Answer: Our AI solution is meticulously de...   \n",
       "16  Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "17  Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "18  Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "19  Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "20  Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "21  Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "22  Project_Title: AI-Powered Risk Assessment Mode...   \n",
       "\n",
       "                                  question_embeddings  \\\n",
       "0   [-0.012242779808196847, -0.02875495641236209, ...   \n",
       "1   [-0.021238304961058666, -0.002903160656478289,...   \n",
       "2   [-0.024933725810230647, -0.00398689651570446, ...   \n",
       "3   [-0.011542554119771953, -0.012979928523676116,...   \n",
       "4   [-0.022403337192397944, -0.003745948452053383,...   \n",
       "5   [-0.02591718013947877, 0.026053946723562156, 0...   \n",
       "6   [-0.005094874094156965, -0.0018191395470256865...   \n",
       "7   [0.021570483446575122, 0.014879887146777028, 0...   \n",
       "8   [-0.02396939689706394, 0.018455669672488594, 0...   \n",
       "9   [-0.008237089426533709, 0.02109827336666294, 0...   \n",
       "10  [-0.013587386723794776, 0.00556639885149576, 0...   \n",
       "11  [-0.011384415804847862, 0.01486040978785559, 0...   \n",
       "12  [0.0053169715833493916, -0.006949637731748671,...   \n",
       "13  [-0.020124713429307745, -0.0004988097469494085...   \n",
       "14  [-0.007420965991490901, 0.04956698082175351, 0...   \n",
       "15  [-0.024076844192504537, 0.004061743862669836, ...   \n",
       "16  [-0.008052477280807952, 0.033308541890396996, ...   \n",
       "17  [-0.02460394761122877, 0.022054107706891476, 0...   \n",
       "18  [-0.01298543116888274, 0.012363928901313223, 0...   \n",
       "19  [-0.017150190231389383, 0.009718005830936486, ...   \n",
       "20  [-0.025189838097553253, 0.040055336375701724, ...   \n",
       "21  [-0.000199194390609713, 0.004925684748433598, ...   \n",
       "22  [-0.012498520688869403, -0.0037221299667366658...   \n",
       "\n",
       "                                    answer_embeddings  \\\n",
       "0   [0.0310747014081873, -0.027107230157425624, 0....   \n",
       "1   [0.009167934150736499, 0.004675850898067104, 0...   \n",
       "2   [-0.009066043640488342, 0.004352435574698996, ...   \n",
       "3   [0.01756528858249858, -0.0021651658480433076, ...   \n",
       "4   [0.012766196768228667, 0.02172657166295028, 0....   \n",
       "5   [0.0030569415769184254, 0.032351002340196805, ...   \n",
       "6   [-0.00878038568775405, -0.009270509111679268, ...   \n",
       "7   [0.026099357489269805, 0.012381280646806315, 0...   \n",
       "8   [0.011562094135351562, 0.019687660111660777, 0...   \n",
       "9   [-0.014028603505788242, 0.019560468426855514, ...   \n",
       "10  [-0.014100776926247227, 0.028742851604862004, ...   \n",
       "11  [0.010212780634484725, 0.04281626527186002, 0....   \n",
       "12  [0.010576286517614232, 0.0059551452625119725, ...   \n",
       "13  [-0.00464839980914793, 0.02650004513693912, 0....   \n",
       "14  [-0.007432110970636761, 0.03926498761186463, 0...   \n",
       "15  [0.0034582621035253716, 0.018990318172255122, ...   \n",
       "16  [0.010880410513588184, 0.017498636364719343, 0...   \n",
       "17  [0.0015179464477811156, 0.033250256609367417, ...   \n",
       "18  [-0.007185383545431859, 0.026770268922978437, ...   \n",
       "19  [0.007095605286568667, 0.030860055734765315, 0...   \n",
       "20  [0.01807079358525926, 0.04915548573583894, 0.0...   \n",
       "21  [-0.0008818536311500733, 0.012060341443225833,...   \n",
       "22  [-0.02664997184745821, -0.010097080623255343, ...   \n",
       "\n",
       "                                   context_embeddings  \\\n",
       "0   [-0.002070941676414154, 0.016138519678307824, ...   \n",
       "1   [0.003495793715123486, 0.029037076361042993, 0...   \n",
       "2   [0.00557660436251417, 0.017872921644696806, 0....   \n",
       "3   [0.005625466015599571, 0.027107654769665805, 0...   \n",
       "4   [0.003870411601094043, 0.020839706984124785, 0...   \n",
       "5   [-0.004738790191233332, 0.012303232755733858, ...   \n",
       "6   [0.0035890195577847014, 0.0202937935330464, 0....   \n",
       "7   [0.006703774816147418, 0.014809646435435513, 0...   \n",
       "8   [0.013534342148055555, 0.016004392023382625, 0...   \n",
       "9   [0.011712163709805153, 0.005895829305481538, 0...   \n",
       "10  [0.007159265695977494, 0.03300717103463557, 0....   \n",
       "11  [0.004137188261680031, 0.013544679833804111, 0...   \n",
       "12  [0.006603175100025997, 0.005670396432022413, 0...   \n",
       "13  [0.004213855229464925, 0.009941181388020852, 0...   \n",
       "14  [-0.00036490626566094, 0.02311671491491352, 0....   \n",
       "15  [0.003314178674187951, 0.009757730437193744, 0...   \n",
       "16  [0.0030195862950919148, 0.021052473157487695, ...   \n",
       "17  [0.009768373907393227, 0.024222591007012875, 0...   \n",
       "18  [0.0047528350521155675, 0.027148538019591564, ...   \n",
       "19  [0.0032891564784606232, 0.015881662633439708, ...   \n",
       "20  [0.004329927746834291, 0.02350532271947371, 0....   \n",
       "21  [0.010784785109801695, 0.03256630851188828, 0....   \n",
       "22  [0.009309162053996218, 0.013277804937123123, 0...   \n",
       "\n",
       "   similarity_score_question_vs_context similarity_score_question_vs_answer  \\\n",
       "0                              0.585144                            0.725917   \n",
       "1                              0.583265                            0.783871   \n",
       "2                              0.544418                            0.724164   \n",
       "3                              0.614859                            0.763888   \n",
       "4                              0.498187                            0.790653   \n",
       "5                              0.574956                            0.769456   \n",
       "6                              0.590167                            0.939786   \n",
       "7                              0.617357                            0.829949   \n",
       "8                              0.568258                            0.761843   \n",
       "9                              0.527055                            0.956986   \n",
       "10                             0.606615                            0.790901   \n",
       "11                             0.573402                             0.74141   \n",
       "12                             0.628482                            0.951312   \n",
       "13                             0.562789                            0.744559   \n",
       "14                             0.631476                            0.961636   \n",
       "15                             0.676642                            0.843948   \n",
       "16                             0.670413                            0.836631   \n",
       "17                             0.656444                            0.877607   \n",
       "18                             0.682818                             0.82312   \n",
       "19                             0.599095                            0.840924   \n",
       "20                             0.688308                            0.811194   \n",
       "21                              0.64035                             0.94528   \n",
       "22                             0.669713                            0.946756   \n",
       "\n",
       "   similarity_score_context_vs_answer        model completion_tokens  \\\n",
       "0                             0.69799  gpt-4-turbo                32   \n",
       "1                            0.681394  gpt-4-turbo                20   \n",
       "2                            0.650534  gpt-4-turbo                18   \n",
       "3                            0.690945  gpt-4-turbo                22   \n",
       "4                            0.596217  gpt-4-turbo                26   \n",
       "5                            0.641872  gpt-4-turbo                30   \n",
       "6                            0.617473  gpt-4-turbo                53   \n",
       "7                            0.669105  gpt-4-turbo                37   \n",
       "8                            0.668359  gpt-4-turbo                38   \n",
       "9                             0.53162  gpt-4-turbo                58   \n",
       "10                           0.586791  gpt-4-turbo                25   \n",
       "11                           0.568094  gpt-4-turbo                22   \n",
       "12                           0.635016  gpt-4-turbo                52   \n",
       "13                           0.614149  gpt-4-turbo                19   \n",
       "14                           0.664236  gpt-4-turbo                59   \n",
       "15                           0.735881  gpt-4-turbo                27   \n",
       "16                           0.727574  gpt-4-turbo                27   \n",
       "17                           0.712226  gpt-4-turbo                36   \n",
       "18                           0.729036  gpt-4-turbo                30   \n",
       "19                           0.704434  gpt-4-turbo                36   \n",
       "20                           0.744222  gpt-4-turbo                37   \n",
       "21                           0.634112  gpt-4-turbo                54   \n",
       "22                           0.666294  gpt-4-turbo                63   \n",
       "\n",
       "   prompt_tokens total_tokens response_time  \n",
       "0           2050         2082           3.0  \n",
       "1           2178         2198           2.2  \n",
       "2           2110         2128           6.1  \n",
       "3           2136         2158           2.3  \n",
       "4           2100         2126           3.0  \n",
       "5           2080         2110           5.2  \n",
       "6           2035         2088           4.2  \n",
       "7           2063         2100           4.3  \n",
       "8           2199         2237           3.8  \n",
       "9           2203         2261           4.6  \n",
       "10          2135         2160           2.8  \n",
       "11          2108         2130           2.8  \n",
       "12          2029         2081           4.7  \n",
       "13          2082         2101           2.1  \n",
       "14          2126         2185           3.8  \n",
       "15          2068         2095           3.4  \n",
       "16          2060         2087           3.6  \n",
       "17          2006         2042           2.9  \n",
       "18          2156         2186           2.7  \n",
       "19          2075         2111           2.9  \n",
       "20          2045         2082           3.9  \n",
       "21          2151         2205          34.7  \n",
       "22          2073         2136          12.7  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "rag_evaluation_df.to_csv('rag_evaluation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_nice(rag_evaluation_df, num_rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "\n",
    "from ragas.metrics.critique import harmfulness\n",
    "from ragas import evaluate\n",
    "\n",
    "def create_ragas_dataset(rag_pipeline, eval_dataset):\n",
    "  rag_dataset = []\n",
    "  for row in tqdm(eval_dataset):\n",
    "    answer = rag_pipeline.invoke({\"question\" : row[\"question\"]})\n",
    "    rag_dataset.append(\n",
    "        {\"question\" : row[\"question\"],\n",
    "         \"answer\" : answer[\"response\"].content,\n",
    "         \"contexts\" : [context.page_content for context in answer[\"context\"]],\n",
    "         \"ground_truths\" : [row[\"ground_truth\"]]\n",
    "         }\n",
    "    )\n",
    "  rag_df = pd.DataFrame(rag_dataset)\n",
    "  rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
    "  return rag_eval_dataset\n",
    "\n",
    "def evaluate_ragas_dataset(ragas_dataset):\n",
    "  result = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\\\n",
    "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run:\n",
    "\n",
    "    from typing import List\n",
    "\n",
    "    from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "    # This function formats a list of Document objects into a single string.\n",
    "    # Each document's content and source are formatted and separated by two newlines.\n",
    "    def format_docs(docs: List[Document]) -> str:\n",
    "        return \"\\n\\n\".join(\n",
    "            f\"Content: {doc.page_content}\\nSource: {doc.metadata['source']}\" for doc in docs\n",
    "        )\n",
    "\n",
    "    # This chain is used for processing 'source_documents'. It formats the documents\n",
    "    # using the 'format_docs' function, then passes the formatted string through\n",
    "    # subsequent unspecified operations (`prompt`, `llm`) and finally parses the output to a string.\n",
    "    rag_chain_from_docs = (\n",
    "        RunnablePassthrough.assign(\n",
    "            source_documents=(lambda x: format_docs(x[\"source_documents\"]))\n",
    "        )\n",
    "        | prompt  # Uses the 'prompt' template to format the context and question.\n",
    "        | llm     # Uses the language model to generate an answer.\n",
    "        | StrOutputParser()  # Parses the output from the language model into a string format.\n",
    "    )\n",
    "\n",
    "    # This RunnableParallel constructs a parallel chain for processing.\n",
    "    # It takes 'source_documents' from a retriever and a 'question' as inputs.\n",
    "    # The 'answer' part of the chain is assigned to the previously defined 'rag_chain_from_docs'.\n",
    "    rag_chain = RunnableParallel(\n",
    "        {\n",
    "            \"source_documents\": retriever,  \n",
    "            \"question\": RunnablePassthrough(),  # Passes the question through without modification.\n",
    "        }\n",
    "    ).assign(answer=rag_chain_from_docs)  # The final output is determined by the chain that processes documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def stable_hash_meta(doc: Document) -> str:\n",
    "    \"\"\"\n",
    "    Stable hash document based on its metadata. Assumes 'metadata' is always present.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        metadata_json = json.dumps(doc.metadata, sort_keys=True)\n",
    "    except AttributeError:\n",
    "        raise ValueError(\"Document does not have metadata.\")\n",
    "    return hashlib.sha1(metadata_json.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits_ids = [{\"doc\": split, \"id\": stable_hash_meta(split)} for split in splits]\n",
    "\n",
    "#existing_ids = vectorstore.get()[\"ids\"]\n",
    "\n",
    "#new_splits_ids = [split for split in splits_ids if split[\"id\"] not in existing_ids]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-py3.10",
   "language": "python",
   "name": "validmind-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

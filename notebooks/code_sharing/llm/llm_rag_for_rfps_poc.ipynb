{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG for Question Similarity in RFPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU qdrant-client lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    raise Exception(\"OPENAI_API_KEY not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from IPython.display import HTML, display\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def _format_cell_text(text, width=50):\n",
    "    \"\"\"Private function to format a cell's text.\"\"\"\n",
    "    return \"\\n\".join([textwrap.fill(line, width=width) for line in text.split(\"\\n\")])\n",
    "\n",
    "\n",
    "def _format_dataframe_for_tabulate(df):\n",
    "    \"\"\"Private function to format the entire DataFrame for tabulation.\"\"\"\n",
    "    df_out = df.copy()\n",
    "\n",
    "    # Format all string columns\n",
    "    for column in df_out.columns:\n",
    "        # Check if column is of type object (likely strings)\n",
    "        if df_out[column].dtype == object:\n",
    "            df_out[column] = df_out[column].apply(_format_cell_text)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def _dataframe_to_html_table(df):\n",
    "    \"\"\"Private function to convert a DataFrame to an HTML table.\"\"\"\n",
    "    headers = df.columns.tolist()\n",
    "    table_data = df.values.tolist()\n",
    "    return tabulate(table_data, headers=headers, tablefmt=\"html\")\n",
    "\n",
    "\n",
    "def display_nice(df, num_rows=None):\n",
    "    \"\"\"Primary function to format and display a DataFrame.\"\"\"\n",
    "    if num_rows is not None:\n",
    "        df = df.head(num_rows)\n",
    "    formatted_df = _format_dataframe_for_tabulate(df)\n",
    "    html_table = _dataframe_to_html_table(formatted_df)\n",
    "    display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict_keys(data, indent=0):\n",
    "    for key, value in data.items():\n",
    "        print(' ' * indent + str(key))\n",
    "        if isinstance(value, dict):  # if the value is another dictionary, recurse\n",
    "            print_dict_keys(value, indent + 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing RFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV file paths\n",
    "existing_rfp_paths = [\n",
    "    \"datasets/rag/rfp_existing_questions_client_2.csv\",\n",
    "]\n",
    "\n",
    "existing_rfp_df = [pd.read_csv(file_path) for file_path in existing_rfp_paths]\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "existing_rfp_df = pd.concat(existing_rfp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project_Title</th>\n",
       "      <th>RFP_Question_ID</th>\n",
       "      <th>RFP_Question</th>\n",
       "      <th>RFP_Answer</th>\n",
       "      <th>Area</th>\n",
       "      <th>Last_Accessed_At</th>\n",
       "      <th>Requester</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Can you discuss your expertise in creating AI-...</td>\n",
       "      <td>Our company has 15 years of experience in deve...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>2</td>\n",
       "      <td>How do you keep your AI applications current w...</td>\n",
       "      <td>We maintain a dedicated R&amp;D team focused on in...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>3</td>\n",
       "      <td>Are your AI applications adaptable to specific...</td>\n",
       "      <td>Absolutely, customization is a core aspect of ...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>4</td>\n",
       "      <td>What steps do you undertake to protect user pr...</td>\n",
       "      <td>User privacy and data security are paramount. ...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>5</td>\n",
       "      <td>What strategies do you employ to design user i...</td>\n",
       "      <td>Our design philosophy centers on simplicity an...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>6</td>\n",
       "      <td>Explain the support and maintenance services y...</td>\n",
       "      <td>Post-launch, we offer comprehensive support an...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>7</td>\n",
       "      <td>How do you evaluate the effectiveness and impa...</td>\n",
       "      <td>Success measurement is tailored to each projec...</td>\n",
       "      <td>General</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>8</td>\n",
       "      <td>How do you manage ethical concerns in your LLM...</td>\n",
       "      <td>We adhere to ethical AI practices by implement...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>9</td>\n",
       "      <td>Could you outline how you train your LLMs, inc...</td>\n",
       "      <td>Our LLM training process begins with the metic...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>10</td>\n",
       "      <td>How do you ensure your LLMs continuously learn...</td>\n",
       "      <td>We implement advanced continuous learning mech...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>11</td>\n",
       "      <td>What actions do you take to make the decision-...</td>\n",
       "      <td>We prioritize transparency and explainability ...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>12</td>\n",
       "      <td>How do you verify and ensure that your LLMs ca...</td>\n",
       "      <td>We conduct extensive performance testing under...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>13</td>\n",
       "      <td>Can you provide case studies of successful LLM...</td>\n",
       "      <td>We can share case studies of successful LLM-ba...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>14</td>\n",
       "      <td>Describe how you integrate LLMs into existing ...</td>\n",
       "      <td>Our approach involves conducting a thorough an...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>15</td>\n",
       "      <td>What are your strategies for supporting and ma...</td>\n",
       "      <td>Our post-deployment support is designed to ens...</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>16</td>\n",
       "      <td>How does your AI solution comply with the guid...</td>\n",
       "      <td>Our AI solution is meticulously designed to al...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>17</td>\n",
       "      <td>Could you describe the governance frameworks y...</td>\n",
       "      <td>We have established an AI Risk Council that pl...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>18</td>\n",
       "      <td>How do you identify and evaluate AI risks foll...</td>\n",
       "      <td>We conduct thorough assessments of AI systems ...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>19</td>\n",
       "      <td>What steps do you implement to ensure AI decis...</td>\n",
       "      <td>We prioritize transparency by incorporating ex...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>20</td>\n",
       "      <td>How do you monitor and assess AI risk exposure...</td>\n",
       "      <td>We have developed a set of Key Performance Ind...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>21</td>\n",
       "      <td>Explain how you manage and mitigate AI risks i...</td>\n",
       "      <td>We implement and maintain robust risk manageme...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>22</td>\n",
       "      <td>How do you ensure compliance with U.S. laws on...</td>\n",
       "      <td>We ensure compliance with U.S. regulations suc...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AI-Powered Risk Assessment Model Development f...</td>\n",
       "      <td>23</td>\n",
       "      <td>In what ways do you participate in advancing A...</td>\n",
       "      <td>We actively participate in industry working gr...</td>\n",
       "      <td>AI Regulation</td>\n",
       "      <td>18/12/2022</td>\n",
       "      <td>Bank B</td>\n",
       "      <td>Awarded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Project_Title  RFP_Question_ID  \\\n",
       "0   AI-Powered Risk Assessment Model Development f...                1   \n",
       "1   AI-Powered Risk Assessment Model Development f...                2   \n",
       "2   AI-Powered Risk Assessment Model Development f...                3   \n",
       "3   AI-Powered Risk Assessment Model Development f...                4   \n",
       "4   AI-Powered Risk Assessment Model Development f...                5   \n",
       "5   AI-Powered Risk Assessment Model Development f...                6   \n",
       "6   AI-Powered Risk Assessment Model Development f...                7   \n",
       "7   AI-Powered Risk Assessment Model Development f...                8   \n",
       "8   AI-Powered Risk Assessment Model Development f...                9   \n",
       "9   AI-Powered Risk Assessment Model Development f...               10   \n",
       "10  AI-Powered Risk Assessment Model Development f...               11   \n",
       "11  AI-Powered Risk Assessment Model Development f...               12   \n",
       "12  AI-Powered Risk Assessment Model Development f...               13   \n",
       "13  AI-Powered Risk Assessment Model Development f...               14   \n",
       "14  AI-Powered Risk Assessment Model Development f...               15   \n",
       "15  AI-Powered Risk Assessment Model Development f...               16   \n",
       "16  AI-Powered Risk Assessment Model Development f...               17   \n",
       "17  AI-Powered Risk Assessment Model Development f...               18   \n",
       "18  AI-Powered Risk Assessment Model Development f...               19   \n",
       "19  AI-Powered Risk Assessment Model Development f...               20   \n",
       "20  AI-Powered Risk Assessment Model Development f...               21   \n",
       "21  AI-Powered Risk Assessment Model Development f...               22   \n",
       "22  AI-Powered Risk Assessment Model Development f...               23   \n",
       "\n",
       "                                         RFP_Question  \\\n",
       "0   Can you discuss your expertise in creating AI-...   \n",
       "1   How do you keep your AI applications current w...   \n",
       "2   Are your AI applications adaptable to specific...   \n",
       "3   What steps do you undertake to protect user pr...   \n",
       "4   What strategies do you employ to design user i...   \n",
       "5   Explain the support and maintenance services y...   \n",
       "6   How do you evaluate the effectiveness and impa...   \n",
       "7   How do you manage ethical concerns in your LLM...   \n",
       "8   Could you outline how you train your LLMs, inc...   \n",
       "9   How do you ensure your LLMs continuously learn...   \n",
       "10  What actions do you take to make the decision-...   \n",
       "11  How do you verify and ensure that your LLMs ca...   \n",
       "12  Can you provide case studies of successful LLM...   \n",
       "13  Describe how you integrate LLMs into existing ...   \n",
       "14  What are your strategies for supporting and ma...   \n",
       "15  How does your AI solution comply with the guid...   \n",
       "16  Could you describe the governance frameworks y...   \n",
       "17  How do you identify and evaluate AI risks foll...   \n",
       "18  What steps do you implement to ensure AI decis...   \n",
       "19  How do you monitor and assess AI risk exposure...   \n",
       "20  Explain how you manage and mitigate AI risks i...   \n",
       "21  How do you ensure compliance with U.S. laws on...   \n",
       "22  In what ways do you participate in advancing A...   \n",
       "\n",
       "                                           RFP_Answer                   Area  \\\n",
       "0   Our company has 15 years of experience in deve...                General   \n",
       "1   We maintain a dedicated R&D team focused on in...                General   \n",
       "2   Absolutely, customization is a core aspect of ...                General   \n",
       "3   User privacy and data security are paramount. ...                General   \n",
       "4   Our design philosophy centers on simplicity an...                General   \n",
       "5   Post-launch, we offer comprehensive support an...                General   \n",
       "6   Success measurement is tailored to each projec...                General   \n",
       "7   We adhere to ethical AI practices by implement...  Large Language Models   \n",
       "8   Our LLM training process begins with the metic...  Large Language Models   \n",
       "9   We implement advanced continuous learning mech...  Large Language Models   \n",
       "10  We prioritize transparency and explainability ...  Large Language Models   \n",
       "11  We conduct extensive performance testing under...  Large Language Models   \n",
       "12  We can share case studies of successful LLM-ba...  Large Language Models   \n",
       "13  Our approach involves conducting a thorough an...  Large Language Models   \n",
       "14  Our post-deployment support is designed to ens...  Large Language Models   \n",
       "15  Our AI solution is meticulously designed to al...          AI Regulation   \n",
       "16  We have established an AI Risk Council that pl...          AI Regulation   \n",
       "17  We conduct thorough assessments of AI systems ...          AI Regulation   \n",
       "18  We prioritize transparency by incorporating ex...          AI Regulation   \n",
       "19  We have developed a set of Key Performance Ind...          AI Regulation   \n",
       "20  We implement and maintain robust risk manageme...          AI Regulation   \n",
       "21  We ensure compliance with U.S. regulations suc...          AI Regulation   \n",
       "22  We actively participate in industry working gr...          AI Regulation   \n",
       "\n",
       "   Last_Accessed_At Requester   Status  \n",
       "0        18/12/2022    Bank B  Awarded  \n",
       "1        18/12/2022    Bank B  Awarded  \n",
       "2        18/12/2022    Bank B  Awarded  \n",
       "3        18/12/2022    Bank B  Awarded  \n",
       "4        18/12/2022    Bank B  Awarded  \n",
       "5        18/12/2022    Bank B  Awarded  \n",
       "6        18/12/2022    Bank B  Awarded  \n",
       "7        18/12/2022    Bank B  Awarded  \n",
       "8        18/12/2022    Bank B  Awarded  \n",
       "9        18/12/2022    Bank B  Awarded  \n",
       "10       18/12/2022    Bank B  Awarded  \n",
       "11       18/12/2022    Bank B  Awarded  \n",
       "12       18/12/2022    Bank B  Awarded  \n",
       "13       18/12/2022    Bank B  Awarded  \n",
       "14       18/12/2022    Bank B  Awarded  \n",
       "15       18/12/2022    Bank B  Awarded  \n",
       "16       18/12/2022    Bank B  Awarded  \n",
       "17       18/12/2022    Bank B  Awarded  \n",
       "18       18/12/2022    Bank B  Awarded  \n",
       "19       18/12/2022    Bank B  Awarded  \n",
       "20       18/12/2022    Bank B  Awarded  \n",
       "21       18/12/2022    Bank B  Awarded  \n",
       "22       18/12/2022    Bank B  Awarded  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_rfp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "documents = []\n",
    "\n",
    "# Iterate through each file path in the list\n",
    "for file_path in existing_rfp_paths:\n",
    "    loader = CSVLoader(\n",
    "        file_path=file_path,\n",
    "        metadata_columns=[\"Area\"]\n",
    "    )\n",
    "\n",
    "    # Load a document from the current CSV file\n",
    "    doc = loader.load()\n",
    "    \n",
    "    # Append documents\n",
    "    documents.extend(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `CSVLoader`, each document represents a single row and includes its respective contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 1\\nRFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\\nRFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of 95%.\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General'}\n",
      "Document 2: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 2\\nRFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?\\nRFP_Answer: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures that our applications remain innovative, with capabilities that adapt to evolving market demands and client needs. This approach has enabled us to enhance the predictive accuracy of our financial forecasting tools by 25% and improve the efficiency of our educational content personalization by 40%\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General'}\n",
      "Document 3: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 3\\nRFP_Question: Are your AI applications adaptable to specific requirements of users or businesses?\\nRFP_Answer: Absolutely, customization is a core aspect of our offering. We work closely with clients to understand their specific needs and tailor our AI algorithms and app functionalities accordingly, using technologies such as TensorFlow for machine learning models, React for responsive UI/UX designs, and Kubernetes for scalable cloud deployment. This personalized approach allows us to optimize AI functionalities to match unique business processes, enhancing user experience and operational efficiency for each client. For example, for a retail client, we customized our recommendation engine to increase customer retention by 20% through more accurate and personalized product suggestions.\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 2, 'Area': 'General'}\n",
      "Document 4: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 4\\nRFP_Question: What steps do you undertake to protect user privacy and secure data within your AI applications?\\nRFP_Answer: User privacy and data security are paramount. We implement robust measures such as end-to-end encryption to secure data transmissions, anonymization techniques to protect user identities, and comprehensive compliance with data protection laws like GDPR and CCPA. We also employ regular security audits and vulnerability assessments to ensure our systems are impenetrable. Additionally, our deployment of advanced intrusion detection systems and the use of secure coding practices reinforce our commitment to safeguarding user data at all times\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 3, 'Area': 'General'}\n",
      "Document 5: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 5\\nRFP_Question: What strategies do you employ to design user interfaces and experiences in AI applications to maximize usability and user engagement?\\nRFP_Answer: Our design philosophy centers on simplicity and intuitiveness. We conduct extensive user research and testing to inform our UI/UX designs, ensuring that our AI-based apps are accessible and engaging for all users, regardless of their technical expertise. This includes applying principles from human-centered design, utilizing accessibility guidelines such as WCAG 2.1, and conducting iterative testing with diverse user groups. Our commitment to inclusivity and usability leads to higher user adoption rates and satisfaction. For instance, feedback-driven enhancements in our visual design have improved user engagement by over 30% across our applications.\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 4, 'Area': 'General'}\n"
     ]
    }
   ],
   "source": [
    "number_of_documents = 5\n",
    "\n",
    "for i, document in enumerate(documents[:number_of_documents]):\n",
    "    print(f\"Document {i + 1}: {document}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the page content of each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page content for document 1:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 1\n",
      "RFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\n",
      "RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of 95%.\n",
      "Last_Accessed_At: 18/12/2022\n",
      "Requester: Bank B\n",
      "Status: Awarded\n",
      "\n",
      "Page content for document 2:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 2\n",
      "RFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?\n",
      "RFP_Answer: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures that our applications remain innovative, with capabilities that adapt to evolving market demands and client needs. This approach has enabled us to enhance the predictive accuracy of our financial forecasting tools by 25% and improve the efficiency of our educational content personalization by 40%\n",
      "Last_Accessed_At: 18/12/2022\n",
      "Requester: Bank B\n",
      "Status: Awarded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_documents = 2\n",
    "\n",
    "for i, document in enumerate(documents[:number_of_documents]):\n",
    "    print(f\"Page content for document {i + 1}:\")\n",
    "    print(document.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when adding metadata, it is appended to the default metadata, which consists of the row number and the source: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for document 1: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General'}\n",
      "Metadata for document 2: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General'}\n",
      "Metadata for document 3: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 2, 'Area': 'General'}\n",
      "Metadata for document 4: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 3, 'Area': 'General'}\n",
      "Metadata for document 5: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 4, 'Area': 'General'}\n"
     ]
    }
   ],
   "source": [
    "number_of_documents = 5\n",
    "\n",
    "for i, document in enumerate(documents[:number_of_documents]):\n",
    "    print(f\"Metadata for document {i + 1}: {document.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=10, add_start_index=True\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some general information about the chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 98\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the length of the bigger and smaller chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum chunk length: 499\n",
      "Minimum chunk length: 12\n",
      "Mean chunk length: 267.6020408163265\n"
     ]
    }
   ],
   "source": [
    "max_chunk_length = max([len(chunk.page_content) for chunk in chunks])\n",
    "min_chunk_length = min([len(chunk.page_content) for chunk in chunks])\n",
    "mean_chunk_length = sum([len(chunk.page_content) for chunk in chunks]) / len(chunks)\n",
    "\n",
    "print(f\"Maximum chunk length: {max_chunk_length}\")\n",
    "print(f\"Minimum chunk length: {min_chunk_length}\")\n",
    "print(f\"Mean chunk length: {mean_chunk_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of chunks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "variable=0<br>value=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "0",
         "nbinsx": 50,
         "offsetgroup": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          233,
          496,
          12,
          62,
          211,
          497,
          305,
          62,
          196,
          496,
          199,
          62,
          209,
          491,
          73,
          62,
          246,
          493,
          184,
          62,
          207,
          495,
          280,
          62,
          212,
          499,
          305,
          62,
          239,
          498,
          366,
          62,
          226,
          497,
          499,
          13,
          62,
          229,
          492,
          45,
          463,
          268,
          477,
          221,
          495,
          150,
          62,
          199,
          495,
          296,
          62,
          241,
          498,
          366,
          62,
          197,
          495,
          413,
          62,
          256,
          491,
          379,
          62,
          221,
          497,
          338,
          62,
          221,
          494,
          406,
          62,
          204,
          497,
          347,
          62,
          233,
          491,
          374,
          62,
          249,
          450,
          480,
          62,
          211,
          439,
          498,
          87,
          62,
          209,
          496,
          46,
          491,
          24,
          62,
          233,
          491,
          291,
          62
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "x": 499,
          "y": 0,
          "yshift": 10
         }
        ],
        "bargap": 0.2,
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of Chunk Lengths"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Chunk Length"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Calculate lengths of each chunk's page_content\n",
    "chunk_lengths = [len(chunk.page_content) for chunk in chunks]\n",
    "\n",
    "# Creating a histogram of chunk lengths\n",
    "fig = px.histogram(chunk_lengths, nbins=50, title=\"Distribution of Chunk Lengths\")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Chunk Length\",\n",
    "    yaxis_title=\"Count\",\n",
    "    bargap=0.2,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Add summary statistics as text on the plot\n",
    "fig.add_annotation(\n",
    "    x=max(chunk_lengths),\n",
    "    y=0,\n",
    "    showarrow=False,\n",
    "    yshift=10\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the chunks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 1\\nRFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 0}\n",
      "Chunk 2: page_content='RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 234}\n",
      "Chunk 3: page_content='rate of 95%.' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 723}\n",
      "Chunk 4: page_content='Last_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded' metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 736}\n"
     ]
    }
   ],
   "source": [
    "number_of_chunks = 5  \n",
    "\n",
    "for index, chunk in enumerate(chunks[:i]):\n",
    "    print(f\"Chunk {index + 1}: {chunk}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the page content of each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page content for chunk 1:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 1\n",
      "RFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\n",
      "\n",
      "Page content for chunk 2:\n",
      "RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of\n",
      "\n",
      "Page content for chunk 3:\n",
      "rate of 95%.\n",
      "\n",
      "Page content for chunk 4:\n",
      "Last_Accessed_At: 18/12/2022\n",
      "Requester: Bank B\n",
      "Status: Awarded\n",
      "\n",
      "Page content for chunk 5:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 2\n",
      "RFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_chunks = 5\n",
    "\n",
    "for i, document in enumerate(chunks[:number_of_chunks]):\n",
    "    print(f\"Page content for chunk {i + 1}:\")\n",
    "    print(document.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the metadata for individual chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for chunk 1: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 0}\n",
      "Metadata for chunk 2: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 234}\n",
      "Metadata for chunk 3: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 723}\n",
      "Metadata for chunk 4: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 736}\n",
      "Metadata for chunk 5: {'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "number_of_chunks = 5  \n",
    "\n",
    "for i, chunk in enumerate(chunks[:number_of_chunks]):\n",
    "    print(f\"Metadata for chunk {i + 1}: {chunk.metadata}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the source of each chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source for chunk 1: datasets/rag/rfp_existing_questions_client_2.csv\n",
      "Source for chunk 2: datasets/rag/rfp_existing_questions_client_2.csv\n",
      "Source for chunk 3: datasets/rag/rfp_existing_questions_client_2.csv\n",
      "Source for chunk 4: datasets/rag/rfp_existing_questions_client_2.csv\n",
      "Source for chunk 5: datasets/rag/rfp_existing_questions_client_2.csv\n"
     ]
    }
   ],
   "source": [
    "number_of_chunks = 5  \n",
    "\n",
    "for i, chunk in enumerate(chunks[:number_of_chunks]):\n",
    "    print(f\"Source for chunk {i + 1}: {chunk.metadata['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store chunks into a vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  id</th><th>new_rfp                         </th><th>new_question  </th><th>question_to_llm  </th><th>answer  </th><th>ground_truth  </th><th>existing_rfp                        </th><th>llm        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   1</td><td>rfp_new_questions_client_100.csv</td><td>What is your experience in developing AI-based\n",
       "applications, and can you provide examples of\n",
       "successful projects?               </td><td>What is the most similar question to: &quot;What is\n",
       "your experience in developing AI-based\n",
       "applications, and can you provide examples of\n",
       "successful projects?&quot;                  </td><td>None    </td><td>Can you discuss your expertise in creating AI-\n",
       "driven applications and share examples of your\n",
       "successful implementations?               </td><td>rfp_exisiting_questions_client_2.csv</td><td>gpt-4-turbo</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   2</td><td>rfp_new_questions_client_100.csv</td><td>How do you ensure your AI-based apps remain up-to-\n",
       "date with the latest AI advancements and\n",
       "technologies?               </td><td>What is the most similar question to: &quot;How do you\n",
       "ensure your AI-based apps remain up-to-date with\n",
       "the latest AI advancements and technologies?&quot;                  </td><td>None    </td><td>How do you keep your AI applications current with\n",
       "ongoing advancements in artificial intelligence?               </td><td>rfp_exisiting_questions_client_2.csv</td><td>gpt-4-turbo</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load all RFPs into a single pandas DataFrame\n",
    "\n",
    "rag_evaluation_df = pd.read_csv(\"datasets/rag/rag_evaluation_dataset_v1.csv\")\n",
    "\n",
    "display_nice(rag_evaluation_df, num_rows=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.0)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context. \n",
    "If you cannot answer the question with the context, please respond with 'I don't know':\n",
    "\n",
    "### CONTEXT\n",
    "{context}\n",
    "\n",
    "### QUESTION\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# Step 1: \"question\": Retrieved from the \"question\" key.\n",
    "# Step 2: \"context\": Retrieved from the \"question\" key and fed into the retriever.\n",
    "# Step 3: \"context\": Assigned to a RunnablePassthrough object using the \"context\" key from the previous step.\n",
    "# Step 4: \"answer\": \"context\" and \"question\" are combined to format the prompt, then sent to the LLM and stored under the \"answer\" key.\n",
    "# Step 5: \"context\": Repopulated using the \"context\" key from the previous step.\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0)\n",
    "\n",
    "rag_chain = (\n",
    "    \n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"answer\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask a question to test the chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': AIMessage(content='RFP_Question_ID: 1\\nRFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?', response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 2076, 'total_tokens': 2108}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_76f018034d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0fb67830-d0c7-4248-86d8-18a55f495ae4-0'), 'context': [Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 1\\nRFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?', metadata={'Area': 'General', 'row': 0, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 2\\nRFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?', metadata={'Area': 'General', 'row': 1, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of', metadata={'Area': 'General', 'row': 0, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 234}), Document(page_content='RFP_Answer: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures', metadata={'Area': 'General', 'row': 1, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 212}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 5\\nRFP_Question: What strategies do you employ to design user interfaces and experiences in AI applications to maximize usability and user engagement?', metadata={'Area': 'General', 'row': 4, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 7\\nRFP_Question: How do you evaluate the effectiveness and impact of your AI applications in achieving client goals?', metadata={'Area': 'General', 'row': 6, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 3\\nRFP_Question: Are your AI applications adaptable to specific requirements of users or businesses?', metadata={'Area': 'General', 'row': 2, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 13\\nRFP_Question: Can you provide case studies of successful LLM-based application deployments that outline encountered challenges and solutions?', metadata={'Area': 'Large Language Models', 'row': 12, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 4\\nRFP_Question: What steps do you undertake to protect user privacy and secure data within your AI applications?', metadata={'Area': 'General', 'row': 3, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 6\\nRFP_Question: Explain the support and maintenance services you offer for AI applications after they go live.', metadata={'Area': 'General', 'row': 5, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='RFP_Answer: We adhere to ethical AI practices by implementing bias detection and mitigation techniques during the training of our Large Language Models (LLMs). This involves using diverse datasets to prevent skewed results and deploying algorithms specifically designed to identify and correct bias in AI outputs. For data privacy, we employ data anonymization and secure data handling protocols, ensuring compliance with GDPR, CCPA, and other relevant regulations. Our systems use state-of-the-art', metadata={'Area': 'Large Language Models', 'row': 7, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 240}), Document(page_content='RFP_Answer: Our design philosophy centers on simplicity and intuitiveness. We conduct extensive user research and testing to inform our UI/UX designs, ensuring that our AI-based apps are accessible and engaging for all users, regardless of their technical expertise. This includes applying principles from human-centered design, utilizing accessibility guidelines such as WCAG 2.1, and conducting iterative testing with diverse user groups. Our commitment to inclusivity and usability leads to', metadata={'Area': 'General', 'row': 4, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 247}), Document(page_content='RFP_Answer: We conduct thorough assessments of AI systems and the people using AI within our organization. This process involves meticulously identifying potential risks such as data privacy, security, bias, and legal compliance. We assess both the impact and the likelihood of each identified risk to effectively prioritize them. Our approach includes the use of sophisticated tools and methodologies, such as risk matrices and scenario analysis, to quantify and categorize risks accurately. This', metadata={'Area': 'AI Regulation', 'row': 17, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 205}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 16\\nRFP_Question: How does your AI solution comply with the guidelines of the NIST AI RMF for responsible and trustworthy AI?', metadata={'Area': 'AI Regulation', 'row': 15, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 22\\nRFP_Question: How do you ensure compliance with U.S. laws on data privacy and security for your AI solutions?', metadata={'Area': 'AI Regulation', 'row': 21, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 23\\nRFP_Question: In what ways do you participate in advancing AI risk management practices, following the guidelines of the NIST AI RMF?', metadata={'Area': 'AI Regulation', 'row': 22, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='RFP_Answer: Absolutely, customization is a core aspect of our offering. We work closely with clients to understand their specific needs and tailor our AI algorithms and app functionalities accordingly, using technologies such as TensorFlow for machine learning models, React for responsive UI/UX designs, and Kubernetes for scalable cloud deployment. This personalized approach allows us to optimize AI functionalities to match unique business processes, enhancing user experience and operational', metadata={'Area': 'General', 'row': 2, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 197}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 15\\nRFP_Question: What are your strategies for supporting and maintaining LLM-based applications after deployment, including addressing model drift and updates?', metadata={'Area': 'Large Language Models', 'row': 14, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 19\\nRFP_Question: What steps do you implement to ensure AI decisions are transparent and explainable, in line with NIST AI RMF standards?', metadata={'Area': 'AI Regulation', 'row': 18, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0}), Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 8\\nRFP_Question: How do you manage ethical concerns in your LLM applications, especially in terms of reducing bias and protecting data privacy?', metadata={'Area': 'Large Language Models', 'row': 7, 'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'start_index': 0})]}\n"
     ]
    }
   ],
   "source": [
    "question = \"Find a similar question as this one: 'What is your experience in developing AI-based applications?'\"\n",
    "response = rag_chain.invoke({\"question\" : question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As defined in the earlier chat prompt, the RAG response includes two fields: `answer` and `context`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer\n",
      "context\n"
     ]
    }
   ],
   "source": [
    "print_dict_keys(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the answer, we see that the `rag_chain` is functioning correctly and identifies the most similar question in the `vectorstore`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Find a similar question as this one: 'What is your experience in developing AI-based applications?'\n",
      "\n",
      "Answer:\n",
      "RFP_Question_ID: 1\n",
      "RFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question:\")\n",
    "print(question)\n",
    "print()\n",
    "print(f\"Answer:\")\n",
    "print(response[\"answer\"].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we inspect the content of the `answer` and the `context` retrieved based on the `question`. The context should contain `k` chunks, the most relevant based on the question. Remember that we set`k` in the `retriever` earlier. These `k` chunks are pasted into the prompt as text, informing the LLM to generate an answer that is closer in the embedding space to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content for chunk 1:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 1\n",
      "RFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\n",
      "\n",
      "Content for chunk 2:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 2\n",
      "RFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?\n",
      "\n",
      "Content for chunk 3:\n",
      "RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of\n",
      "\n",
      "Content for chunk 4:\n",
      "RFP_Answer: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures\n",
      "\n",
      "Content for chunk 5:\n",
      "Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\n",
      "RFP_Question_ID: 5\n",
      "RFP_Question: What strategies do you employ to design user interfaces and experiences in AI applications to maximize usability and user engagement?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_chunks = 5  \n",
    "\n",
    "for i, chunk in enumerate(response[\"context\"][:number_of_chunks]):\n",
    "    print(f\"Content for chunk {i + 1}:\")  # i + 1 to start counting from 1 instead of 0\n",
    "    print(chunk.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now inspect the `response_metadata` object to understand its contents and identify what could be useful to incorporate in our RAG evaluation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_usage': {'completion_tokens': 32, 'prompt_tokens': 2076, 'total_tokens': 2108}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_76f018034d', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"].response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_usage\n",
      "    completion_tokens\n",
      "    prompt_tokens\n",
      "    total_tokens\n",
      "model_name\n",
      "system_fingerprint\n",
      "finish_reason\n",
      "logprobs\n"
     ]
    }
   ],
   "source": [
    "print_dict_keys(response[\"answer\"].response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'source_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tn/rbr74q892k13m82y37y396h40000gn/T/ipykernel_6152/1364547231.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source_documents\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'source_documents'"
     ]
    }
   ],
   "source": [
    "print(response[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if 'source_documents' not in rag_evaluation_df.columns:\n",
    "#    rag_evaluation_df['source_documents'] = pd.Series([[] for _ in range(len(rag_evaluation_df))], index=rag_evaluation_df.index)\n",
    "\n",
    "\n",
    "# Iterate over the DataFrame rows\n",
    "for i, row in rag_evaluation_df.iterrows():\n",
    "    print(f\"Processing row {i}...\")\n",
    "\n",
    "    # Check if the 'answer' field is 'None' (as a string) for the current row\n",
    "    if row[\"answer\"] == \"None\":\n",
    "        print(f\"Answer is 'None' for question ID {i}. Invoking RAG model...\")\n",
    "\n",
    "        # Invoke the RAG model with the question from the current row\n",
    "        response = rag_chain.invoke(row[\"question_to_llm\"])\n",
    "\n",
    "        # Store whatever response comes from the LLM\n",
    "        rag_evaluation_df.at[i, \"answer\"] = response[\"answer\"]\n",
    "        print(f\"Question ID {i} answer updated with the response from the RAG model.\")\n",
    "\n",
    "        # Compute the hashed metadata for each source document\n",
    "        source_hashes = [stable_hash_meta(source_document.metadata) for source_document in response[\"source_documents\"]]\n",
    "\n",
    "        # Check if source_hashes is a list before assignment, throw error if not\n",
    "        #if not isinstance(source_hashes, list):\n",
    "        #    print(f\"Expected a list for source_hashes but got {type(source_hashes)} instead.\")\n",
    "        #    raise TypeError(f\"source_hashes must be a list, but was {type(source_hashes)}\")\n",
    "\n",
    "        # Assign the list of source document hashes directly to the DataFrame cell\n",
    "        #rag_evaluation_df.at[i, \"source_documents\"] = source_hashes\n",
    "        #print(f\"Question ID {i} source documents updated with hashed metadata.\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_nice(rag_evaluation_df, num_rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "\n",
    "from ragas.metrics.critique import harmfulness\n",
    "from ragas import evaluate\n",
    "\n",
    "def create_ragas_dataset(rag_pipeline, eval_dataset):\n",
    "  rag_dataset = []\n",
    "  for row in tqdm(eval_dataset):\n",
    "    answer = rag_pipeline.invoke({\"question\" : row[\"question\"]})\n",
    "    rag_dataset.append(\n",
    "        {\"question\" : row[\"question\"],\n",
    "         \"answer\" : answer[\"response\"].content,\n",
    "         \"contexts\" : [context.page_content for context in answer[\"context\"]],\n",
    "         \"ground_truths\" : [row[\"ground_truth\"]]\n",
    "         }\n",
    "    )\n",
    "  rag_df = pd.DataFrame(rag_dataset)\n",
    "  rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
    "  return rag_eval_dataset\n",
    "\n",
    "def evaluate_ragas_dataset(ragas_dataset):\n",
    "  result = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\\\n",
    "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run:\n",
    "\n",
    "    from typing import List\n",
    "\n",
    "    from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "    # This function formats a list of Document objects into a single string.\n",
    "    # Each document's content and source are formatted and separated by two newlines.\n",
    "    def format_docs(docs: List[Document]) -> str:\n",
    "        return \"\\n\\n\".join(\n",
    "            f\"Content: {doc.page_content}\\nSource: {doc.metadata['source']}\" for doc in docs\n",
    "        )\n",
    "\n",
    "    # This chain is used for processing 'source_documents'. It formats the documents\n",
    "    # using the 'format_docs' function, then passes the formatted string through\n",
    "    # subsequent unspecified operations (`prompt`, `llm`) and finally parses the output to a string.\n",
    "    rag_chain_from_docs = (\n",
    "        RunnablePassthrough.assign(\n",
    "            source_documents=(lambda x: format_docs(x[\"source_documents\"]))\n",
    "        )\n",
    "        | prompt  # Uses the 'prompt' template to format the context and question.\n",
    "        | llm     # Uses the language model to generate an answer.\n",
    "        | StrOutputParser()  # Parses the output from the language model into a string format.\n",
    "    )\n",
    "\n",
    "    # This RunnableParallel constructs a parallel chain for processing.\n",
    "    # It takes 'source_documents' from a retriever and a 'question' as inputs.\n",
    "    # The 'answer' part of the chain is assigned to the previously defined 'rag_chain_from_docs'.\n",
    "    rag_chain = RunnableParallel(\n",
    "        {\n",
    "            \"source_documents\": retriever,  \n",
    "            \"question\": RunnablePassthrough(),  # Passes the question through without modification.\n",
    "        }\n",
    "    ).assign(answer=rag_chain_from_docs)  # The final output is determined by the chain that processes documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def stable_hash_meta(doc: Document) -> str:\n",
    "    \"\"\"\n",
    "    Stable hash document based on its metadata. Assumes 'metadata' is always present.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        metadata_json = json.dumps(doc.metadata, sort_keys=True)\n",
    "    except AttributeError:\n",
    "        raise ValueError(\"Document does not have metadata.\")\n",
    "    return hashlib.sha1(metadata_json.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits_ids = [{\"doc\": split, \"id\": stable_hash_meta(split)} for split in splits]\n",
    "\n",
    "#existing_ids = vectorstore.get()[\"ids\"]\n",
    "\n",
    "#new_splits_ids = [split for split in splits_ids if split[\"id\"] not in existing_ids]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-py3.10",
   "language": "python",
   "name": "validmind-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

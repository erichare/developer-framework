{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Framework RAG Model Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# load openai api key\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if not 'OPENAI_API_KEY' in os.environ:\n",
    "    raise ValueError('OPENAI_API_KEY is not set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# load documents\n",
    "import os\n",
    "from csv import DictReader\n",
    "from uuid import uuid4\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "column_map = {\"RFP_Question\": \"question\", \"RFP_Answer\": \"ground_truth\"}\n",
    "\n",
    "\n",
    "def load_documents(prefix):\n",
    "    documents = []\n",
    "    root_dir = \"datasets/rag/\"\n",
    "    for file in os.listdir(root_dir):\n",
    "        if file.startswith(prefix) and file.endswith(\".csv\"):\n",
    "            # use csv dict reader to load the csv file\n",
    "            with open(os.path.join(root_dir, file)) as f:\n",
    "                reader = DictReader(f)\n",
    "                for row in reader:\n",
    "                    # add a unique id to the row\n",
    "                    row[\"id\"] = str(uuid4())\n",
    "                    documents.append(row)\n",
    "\n",
    "    df = pd.DataFrame(documents)\n",
    "    df = df[[\"id\", \"RFP_Question\", \"RFP_Answer\"]]\n",
    "    # df.rename(columns=column_map, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_dataset_split(limit=None):\n",
    "    df = load_documents(\"rfp_existing_questions\")\n",
    "\n",
    "    if limit:\n",
    "        df = df.head(limit)\n",
    "\n",
    "    # split the dataset into a \"train\" - which gets inserted into the vector store\n",
    "    # and a \"test\" - which is used to evaluate the search results\n",
    "    train_df = df.sample(frac=0.8)\n",
    "    test_df = df.drop(train_df.index)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Model Selection\n",
    "\n",
    "First let's setup our embedding model and run some tests to make sure its working well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from validmind.models import FunctionModel\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def embed(input):\n",
    "    \"\"\"Returns a text embedding for the given text\"\"\"\n",
    "    return (\n",
    "        client.embeddings.create(\n",
    "            input=input[\"RFP_Question\"],\n",
    "            model=\"text-embedding-3-small\",\n",
    "        )\n",
    "        .data[0]\n",
    "        .embedding\n",
    "    )\n",
    "\n",
    "vm_embedder = FunctionModel(input_id=\"embedding_model\", predict_fn=embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our test dataset so we can run it through our different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 15:11:44,183 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RFP_Question</th>\n",
       "      <th>RFP_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>881f050a-874d-4863-a5ce-f802cf4469a4</td>\n",
       "      <td>Please share your experience with developing A...</td>\n",
       "      <td>Our company has 15 years of experience in deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7ae0aeca-4fe5-495b-b95a-2a24a8f828e0</td>\n",
       "      <td>What measures do you employ to ensure your LLM...</td>\n",
       "      <td>We prioritize transparency and explainability ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1e1b0a2a-1d01-4a7b-af63-53a397c90263</td>\n",
       "      <td>Describe your strategy for integrating LLMs in...</td>\n",
       "      <td>Our approach involves conducting a thorough an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4023a94a-41c6-4390-9adc-babd738aafcb</td>\n",
       "      <td>Can you discuss your governance framework for ...</td>\n",
       "      <td>We have established an AI Risk Council that pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   881f050a-874d-4863-a5ce-f802cf4469a4   \n",
       "10  7ae0aeca-4fe5-495b-b95a-2a24a8f828e0   \n",
       "13  1e1b0a2a-1d01-4a7b-af63-53a397c90263   \n",
       "16  4023a94a-41c6-4390-9adc-babd738aafcb   \n",
       "\n",
       "                                         RFP_Question  \\\n",
       "0   Please share your experience with developing A...   \n",
       "10  What measures do you employ to ensure your LLM...   \n",
       "13  Describe your strategy for integrating LLMs in...   \n",
       "16  Can you discuss your governance framework for ...   \n",
       "\n",
       "                                           RFP_Answer  \n",
       "0   Our company has 15 years of experience in deve...  \n",
       "10  We prioritize transparency and explainability ...  \n",
       "13  Our approach involves conducting a thorough an...  \n",
       "16  We have established an AI Risk Council that pl...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import validmind as vm\n",
    "\n",
    "train_df, test_df = load_dataset_split(20)\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    test_df,\n",
    "    text_column=\"RFP_Question\", # some NLP which work with text data require a `text_column` to be specified\n",
    "    target_column=\"RFP_Answer\",\n",
    "    __log=False,\n",
    ")\n",
    "\n",
    "vm_test_ds.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 15:11:44,194 - INFO(validmind.vm_models.dataset.utils): Running predict_proba()... This may take a while\n",
      "2024-05-07 15:11:44,195 - INFO(validmind.vm_models.dataset.utils): Not running predict_proba() for unsupported models.\n",
      "2024-05-07 15:11:44,195 - INFO(validmind.vm_models.dataset.utils): Running predict()... This may take a while\n",
      "2024-05-07 15:11:44,937 - INFO(validmind.vm_models.dataset.utils): Done running predict()\n"
     ]
    }
   ],
   "source": [
    "vm_test_ds.assign_predictions(vm_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RFP_Question</th>\n",
       "      <th>RFP_Answer</th>\n",
       "      <th>embedding_model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>881f050a-874d-4863-a5ce-f802cf4469a4</td>\n",
       "      <td>Please share your experience with developing A...</td>\n",
       "      <td>Our company has 15 years of experience in deve...</td>\n",
       "      <td>[0.006856707856059074, -0.04714655876159668, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7ae0aeca-4fe5-495b-b95a-2a24a8f828e0</td>\n",
       "      <td>What measures do you employ to ensure your LLM...</td>\n",
       "      <td>We prioritize transparency and explainability ...</td>\n",
       "      <td>[0.010077687911689281, 0.02444615587592125, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1e1b0a2a-1d01-4a7b-af63-53a397c90263</td>\n",
       "      <td>Describe your strategy for integrating LLMs in...</td>\n",
       "      <td>Our approach involves conducting a thorough an...</td>\n",
       "      <td>[0.010061484761536121, 0.022379260510206223, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4023a94a-41c6-4390-9adc-babd738aafcb</td>\n",
       "      <td>Can you discuss your governance framework for ...</td>\n",
       "      <td>We have established an AI Risk Council that pl...</td>\n",
       "      <td>[0.014880189672112465, 0.03505474328994751, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   881f050a-874d-4863-a5ce-f802cf4469a4   \n",
       "10  7ae0aeca-4fe5-495b-b95a-2a24a8f828e0   \n",
       "13  1e1b0a2a-1d01-4a7b-af63-53a397c90263   \n",
       "16  4023a94a-41c6-4390-9adc-babd738aafcb   \n",
       "\n",
       "                                         RFP_Question  \\\n",
       "0   Please share your experience with developing A...   \n",
       "10  What measures do you employ to ensure your LLM...   \n",
       "13  Describe your strategy for integrating LLMs in...   \n",
       "16  Can you discuss your governance framework for ...   \n",
       "\n",
       "                                           RFP_Answer  \\\n",
       "0   Our company has 15 years of experience in deve...   \n",
       "10  We prioritize transparency and explainability ...   \n",
       "13  Our approach involves conducting a thorough an...   \n",
       "16  We have established an AI Risk Council that pl...   \n",
       "\n",
       "                           embedding_model_prediction  \n",
       "0   [0.006856707856059074, -0.04714655876159668, 0...  \n",
       "10  [0.010077687911689281, 0.02444615587592125, 0....  \n",
       "13  [0.010061484761536121, 0.022379260510206223, 0...  \n",
       "16  [0.014880189672112465, 0.03505474328994751, 0....  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm_test_ds.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and run one of the ValidMind embeddings stability analysis tests to make sure our embeddings model is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444bb634fa4b4164bdb7b9a25b017094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h1>Stability Analysis Random Noise ✅</h1>\\n            <p>Evaluate r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validmind.tests import run_test\n",
    "\n",
    "result = run_test(\n",
    "    \"validmind.model_validation.embeddings.StabilityAnalysisRandomNoise\",\n",
    "    inputs={\"model\": vm_embedder, \"dataset\": vm_test_ds},\n",
    "    params={\"probability\": 0.3},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert embeddings and questions into Vector DB\n",
    "\n",
    "> Note: We use the name `train_df` to refer to the dataset that is loaded into the vector store and used as context. This is not a great name but its consistent with data science terminology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, PointStruct, VectorParams\n",
    "\n",
    "qdrant = QdrantClient(\":memory:\")\n",
    "qdrant.recreate_collection(\n",
    "    \"rfp_rag_collection\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "qdrant.upsert(\n",
    "    \"rfp_rag_collection\",\n",
    "    points=[\n",
    "        PointStruct(\n",
    "            id=row[\"id\"],\n",
    "            vector=embed(row),\n",
    "            payload={\"RFP_Question\": row[\"RFP_Question\"], \"RFP_Answer\": row[\"RFP_Answer\"]},\n",
    "        )\n",
    "        for _, row in train_df.iterrows()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Retrieval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def retrieve(input):\n",
    "    contexts = []\n",
    "\n",
    "    for result in qdrant.search(\n",
    "        \"rfp_rag_collection\",\n",
    "        # notice the key we are using to get the embedding model's output\n",
    "        query_vector=input[\"embedding_model\"],\n",
    "        limit=input.get(\n",
    "            \"limit\", 10\n",
    "        ),  # we could add a row to the dataset to specify a limit\n",
    "    ):\n",
    "        context = f\"Q: {result.payload['RFP_Question']}\\n\"\n",
    "        context += f\"A: {result.payload['RFP_Answer']}\\n\"\n",
    "\n",
    "        contexts.append(context)\n",
    "\n",
    "    return contexts\n",
    "\n",
    "\n",
    "vm_retriever = FunctionModel(input_id=\"retrieval_model\", predict_fn=retrieve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we try to run `predict()` on this model directly or compute predictions for our test dataset using `assign_predictions()`, we will run into an error. This is because the retriever function expects that the input contains an embedding which has to be computed by the embedding model. So what we can do is create a PipelineModel that contains the embedding model and the retrieval model and run predictions on that. This is because the intermediate output of each \"component\" model in a PipelineModel is passed as part of the input to the next model (the retrieval model). The key for the model's output is the `input_id` you specify when creating the model.\n",
    "\n",
    "To demonstate this, let's create a pipeline model that contains the embedding model and the retrieval model.\n",
    "\n",
    "Here is how the pipeline model prediction will work:\n",
    "\n",
    "embed_retrieve_pipeline.predict():\n",
    "```\n",
    "{\"question\": \"What is the capital of France?\"}\n",
    "|\n",
    "embedder.predict() -> [0.1, 0.2, 0.3, ...]\n",
    "|\n",
    "{\"question\": \"What is the capital of France?\", \"embedding_model\": [0.1, 0.2, 0.3, ...]}\n",
    "|\n",
    "retriever.predict() -> [\"Capital of France is Paris.\", \"Paris is the capital of France.\"]\n",
    "|\n",
    "[\"Capital of France is Paris.\", \"Paris is the capital of France.\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.models import PipelineModel\n",
    "\n",
    "embed_retrieve_pipeline = PipelineModel(vm_embedder | vm_retriever, input_id=\"embed_retrieve_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q: How do you maintain your AI applications with the newest AI technologies and advancements?\\nA: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures that our applications remain innovative, with capabilities that adapt to evolving market demands and client needs. This approach has enabled us to enhance the predictive accuracy of our financial forecasting tools by 25% and improve the efficiency of our educational content personalization by 40%\\n',\n",
       " 'Q: What considerations do you take into account for user interface and user experience design in your AI applications?\\nA: Our design philosophy centers on simplicity and intuitiveness. We conduct extensive user research and testing to inform our UI/UX designs, ensuring that our AI-based apps are accessible and engaging for all users, regardless of their technical expertise. This includes applying principles from human-centered design, utilizing accessibility guidelines such as WCAG 2.1, and conducting iterative testing with diverse user groups. Our commitment to inclusivity and usability leads to higher user adoption rates and satisfaction. For instance, feedback-driven enhancements in our visual design have improved user engagement by over 30% across our applications.\\n',\n",
       " \"Q: How do you evaluate the success of your AI applications in fulfilling client goals?\\nA: Success measurement is tailored to each project's objectives. We establish key performance indicators (KPIs) in collaboration with our clients, such as user engagement rates, efficiency improvements, or return on investment (ROI). We then regularly review these metrics using advanced analytics platforms and business intelligence tools to assess the app’s impact. Our approach includes monthly performance analysis meetings where we provide detailed reports and insights on metrics like session duration, user retention rates, and cost savings achieved through automation. We also implement A/B testing to continuously refine and optimize the application based on real-world usage data, ensuring that we make data-driven improvements that align closely with our clients' strategic goals.\\n\",\n",
       " 'Q: What support and maintenance do you provide following the deployment of AI applications?\\nA: Post-launch, we offer comprehensive support and maintenance services, including regular updates, bug fixes, and performance optimization. Our support team is available 24/7 to assist with any issues or questions. We utilize a ticketing system that ensures swift response times, with an average initial response time of under 2 hours. Additionally, we provide monthly performance reports and hold quarterly reviews with clients to discuss system status and potential improvements. Our proactive approach includes using automated monitoring tools to detect and resolve issues before they impact users, ensuring that our applications perform optimally at all times. This service structure has been instrumental in maintaining a client satisfaction rate above 98%.\\n',\n",
       " 'Q: How does your AI strategy align with the NIST AI RMF for trustworthy and responsible use of AI?\\nA: Our AI solution is meticulously designed to align with the NIST AI Risk Management Framework (RMF) guidelines, ensuring adherence to principles of trustworthiness and responsibility. We have implemented comprehensive governance structures that oversee the ethical development and deployment of our AI technologies. This includes risk identification and assessment processes where potential risks are analyzed and categorized at each stage of the AI lifecycle. To manage these risks, we have instituted robust risk management controls that are deeply integrated into our development and operational processes. These controls are based on the NIST framework’s best practices, ensuring that our AI solutions are not only effective but also secure and ethical, maintaining transparency and accountability at all times.\\n',\n",
       " 'Q: What actions do you undertake to secure user data and maintain privacy within your AI platforms?\\nA: User privacy and data security are paramount. We implement robust measures such as end-to-end encryption to secure data transmissions, anonymization techniques to protect user identities, and comprehensive compliance with data protection laws like GDPR and CCPA. We also employ regular security audits and vulnerability assessments to ensure our systems are impenetrable. Additionally, our deployment of advanced intrusion detection systems and the use of secure coding practices reinforce our commitment to safeguarding user data at all times\\n',\n",
       " 'Q: Can your AI applications be tailored to meet unique organizational or user-specific requirements?\\nA: Absolutely, customization is a core aspect of our offering. We work closely with clients to understand their specific needs and tailor our AI algorithms and app functionalities accordingly, using technologies such as TensorFlow for machine learning models, React for responsive UI/UX designs, and Kubernetes for scalable cloud deployment. This personalized approach allows us to optimize AI functionalities to match unique business processes, enhancing user experience and operational efficiency for each client. For example, for a retail client, we customized our recommendation engine to increase customer retention by 20% through more accurate and personalized product suggestions.\\n',\n",
       " \"Q: What steps do you take to ensure the transparency and explainability of your AI systems' decisions?\\nA: We prioritize transparency by incorporating explainability features into our AI models, providing detailed documentation on the decision-making processes, and ensuring that stakeholders can understand and trust the outputs of our AI systems. To achieve this, we integrate explainability tools like feature importance scores and decision trees that clearly outline how and why decisions are made by our AI. We supplement these technical tools with comprehensive documentation that describes the algorithms' functions in accessible language. This approach is designed to demystify the AI's operations for non-technical stakeholders, fostering a higher level of trust and acceptance. By ensuring that our AI systems are transparent and their workings understandable, we maintain open communication and build confidence among users and regulators alike.\\n\",\n",
       " \"Q: How do you monitor and assess AI risk exposure using metrics suggested by the NIST AI RMF's 'Measure' function?\\nA: We have developed a set of Key Performance Indicators (KPIs) and metrics specifically designed to assess and analyze AI risk exposure across our systems. These metrics are tracked continuously to provide a clear, quantifiable measure of risk at any given time. To streamline this process, we utilize AI risk assessment tools that automate both data collection and analysis, enhancing the accuracy and efficiency of our monitoring efforts.\\n These tools employ advanced analytics to detect subtle shifts in risk patterns, enabling proactive risk management. Regular updates to our risk assessment protocols ensure that they remain aligned with current threat landscapes and regulatory requirements. This systematic monitoring and analysis not only help us maintain control over AI risks but also ensure that we can respond swiftly and effectively to any changes in risk levels, keeping our AI systems secure and compliant.\\n\",\n",
       " \"Q: How do you perform risk assessment and identification according to the NIST AI RMF's 'Map' function?\\nA: We conduct thorough assessments of AI systems and the people using AI within our organization. This process involves meticulously identifying potential risks such as data privacy, security, bias, and legal compliance. We assess both the impact and the likelihood of each identified risk to effectively prioritize them. Our approach includes the use of sophisticated tools and methodologies, such as risk matrices and scenario analysis, to quantify and categorize risks accurately. This comprehensive assessment enables us to develop targeted risk mitigation strategies and allocate resources more efficiently, ensuring that the most critical risks are addressed promptly and effectively. This proactive risk management practice helps us maintain the integrity of our AI systems and uphold our ethical and legal responsibilities.\\n\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_retrieve_pipeline.predict({\"RFP_Question\": \"What is your experience with AI?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Generation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert RFP AI assistant.\n",
    "You are tasked with answering new RFP questions based on existing RFP questions and answers.\n",
    "You will be provided with the existing RFP questions and answer pairs that are the most relevant to the new RFP question.\n",
    "After that you will be provided with a new RFP question.\n",
    "You will generate an answer and respond only with the answer.\n",
    "Ignore your pre-existing knowledge and answer the question based on the provided context.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def generate(input):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"\\n\\n\".join(input[\"retrieval_model\"])},\n",
    "            {\"role\": \"user\", \"content\": input[\"RFP_Question\"]},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "vm_generator = FunctionModel(input_id=\"generation_model\", predict_fn=generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup RAG Model (Pipeline of \"Component\" Models)\n",
    "\n",
    "Now that we have our individual models setup, let's create a `RAGModel` instance that will chain them together and give us a single model that can be evalated end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from validmind.models import PipelineModel\n",
    "\n",
    "vm_rag_model = PipelineModel(vm_embedder | vm_retriever | vm_generator, input_id=\"rag_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the test dataset through the entire pipeline. It will overwrite the current predictions that we generated from the individual models, but the key here is that calling `predict` on the `RAGModel` will run the entire pipeline and store the intermediate predictions in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. Our commitment to utilizing cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes sets us apart in the AI landscape. Our track record includes enhancing the predictive accuracy of financial forecasting tools by 25% and improving the efficiency of educational content personalization by 40%, showcasing our expertise and success in implementing AI solutions.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm_rag_model.predict({\"RFP_Question\": \"What is your experience with AI?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 15:11:52,715 - INFO(validmind.vm_models.dataset.utils): Running predict_proba()... This may take a while\n",
      "2024-05-07 15:11:52,716 - INFO(validmind.vm_models.dataset.utils): Not running predict_proba() for unsupported models.\n",
      "2024-05-07 15:11:52,716 - INFO(validmind.vm_models.dataset.utils): Running predict()... This may take a while\n",
      "2024-05-07 15:12:16,003 - INFO(validmind.vm_models.dataset.utils): Done running predict()\n"
     ]
    }
   ],
   "source": [
    "vm_test_ds.assign_predictions(vm_rag_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>RFP_Question</th>\n",
       "      <th>RFP_Answer</th>\n",
       "      <th>embedding_model_prediction</th>\n",
       "      <th>rag_model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>881f050a-874d-4863-a5ce-f802cf4469a4</td>\n",
       "      <td>Please share your experience with developing A...</td>\n",
       "      <td>Our company has 15 years of experience in deve...</td>\n",
       "      <td>[0.006856707856059074, -0.04714655876159668, 0...</td>\n",
       "      <td>We have a strong track record in developing AI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7ae0aeca-4fe5-495b-b95a-2a24a8f828e0</td>\n",
       "      <td>What measures do you employ to ensure your LLM...</td>\n",
       "      <td>We prioritize transparency and explainability ...</td>\n",
       "      <td>[0.010077687911689281, 0.02444615587592125, 0....</td>\n",
       "      <td>We prioritize transparency by incorporating ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1e1b0a2a-1d01-4a7b-af63-53a397c90263</td>\n",
       "      <td>Describe your strategy for integrating LLMs in...</td>\n",
       "      <td>Our approach involves conducting a thorough an...</td>\n",
       "      <td>[0.010061484761536121, 0.022379260510206223, 0...</td>\n",
       "      <td>Our strategy for integrating Large Language Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4023a94a-41c6-4390-9adc-babd738aafcb</td>\n",
       "      <td>Can you discuss your governance framework for ...</td>\n",
       "      <td>We have established an AI Risk Council that pl...</td>\n",
       "      <td>[0.014880189672112465, 0.03505474328994751, 0....</td>\n",
       "      <td>Our governance framework for managing AI risks...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   881f050a-874d-4863-a5ce-f802cf4469a4   \n",
       "10  7ae0aeca-4fe5-495b-b95a-2a24a8f828e0   \n",
       "13  1e1b0a2a-1d01-4a7b-af63-53a397c90263   \n",
       "16  4023a94a-41c6-4390-9adc-babd738aafcb   \n",
       "\n",
       "                                         RFP_Question  \\\n",
       "0   Please share your experience with developing A...   \n",
       "10  What measures do you employ to ensure your LLM...   \n",
       "13  Describe your strategy for integrating LLMs in...   \n",
       "16  Can you discuss your governance framework for ...   \n",
       "\n",
       "                                           RFP_Answer  \\\n",
       "0   Our company has 15 years of experience in deve...   \n",
       "10  We prioritize transparency and explainability ...   \n",
       "13  Our approach involves conducting a thorough an...   \n",
       "16  We have established an AI Risk Council that pl...   \n",
       "\n",
       "                           embedding_model_prediction  \\\n",
       "0   [0.006856707856059074, -0.04714655876159668, 0...   \n",
       "10  [0.010077687911689281, 0.02444615587592125, 0....   \n",
       "13  [0.010061484761536121, 0.022379260510206223, 0...   \n",
       "16  [0.014880189672112465, 0.03505474328994751, 0....   \n",
       "\n",
       "                                 rag_model_prediction  \n",
       "0   We have a strong track record in developing AI...  \n",
       "10  We prioritize transparency by incorporating ex...  \n",
       "13  Our strategy for integrating Large Language Mo...  \n",
       "16  Our governance framework for managing AI risks...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm_test_ds.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with some RAGAS Metrics\n",
    "\n",
    "Below I am just experimenting to see how the RAGAS metrics can work with the `RAGModel` instance. This is not a full implementation of the RAGAS metrics but just a poc. We'll want to make this work in a more general way so that the columns can be properly mapped from the user-provided `predict_col` or the default `predict_col` to the column names that RAGAS expects i.e. `question`, `contexts`, `answer`, `ground_truth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vm_ragas_ds \u001b[38;5;241m=\u001b[39m vm\u001b[38;5;241m.\u001b[39minit_dataset(\u001b[43mresult_df\u001b[49m, __log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_df' is not defined"
     ]
    }
   ],
   "source": [
    "vm_ragas_ds = vm.init_dataset(result_df, __log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_distribution(scores):\n",
    "    # plot distribution of scores (0-1) from ragas metric\n",
    "    # scores is a list of floats\n",
    "    fig = px.histogram(x=scores, nbins=10)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "result = run_test(\n",
    "    \"validmind.model_validation.ragas.AnswerSimilarity\",\n",
    "    inputs={\"dataset\": vm_ragas_ds},\n",
    "    show=False,\n",
    ")\n",
    "plot_distribution(result.metric.summary.results[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "result = run_test(\n",
    "    \"validmind.model_validation.ragas.ContextEntityRecall\",\n",
    "    inputs={\"dataset\": vm_ragas_ds},\n",
    "    show=False,\n",
    ")\n",
    "plot_distribution(result.metric.summary.results[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "result = run_test(\n",
    "    \"validmind.model_validation.ragas.ContextPrecision\",\n",
    "    inputs={\"dataset\": vm_ragas_ds},\n",
    "    show=False,\n",
    ")\n",
    "plot_distribution(result.metric.summary.results[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "result = run_test(\n",
    "    \"validmind.model_validation.ragas.ContextRelevancy\",\n",
    "    inputs={\"dataset\": vm_ragas_ds},\n",
    "    show=False,\n",
    ")\n",
    "plot_distribution(result.metric.summary.results[0].data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-mI3jzOkk-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG for RFP Q&A Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain langchain-openai langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU qdrant-client lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    raise Exception(\"OPENAI_API_KEY not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from IPython.display import HTML, display\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def _format_cell_text(text, width=50):\n",
    "    \"\"\"Private function to format a cell's text.\"\"\"\n",
    "    return \"\\n\".join([textwrap.fill(line, width=width) for line in text.split(\"\\n\")])\n",
    "\n",
    "\n",
    "def _format_dataframe_for_tabulate(df):\n",
    "    \"\"\"Private function to format the entire DataFrame for tabulation.\"\"\"\n",
    "    df_out = df.copy()\n",
    "\n",
    "    # Format all string columns\n",
    "    for column in df_out.columns:\n",
    "        # Check if column is of type object (likely strings)\n",
    "        if df_out[column].dtype == object:\n",
    "            df_out[column] = df_out[column].apply(_format_cell_text)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def _dataframe_to_html_table(df):\n",
    "    \"\"\"Private function to convert a DataFrame to an HTML table.\"\"\"\n",
    "    headers = df.columns.tolist()\n",
    "    table_data = df.values.tolist()\n",
    "    return tabulate(table_data, headers=headers, tablefmt=\"html\")\n",
    "\n",
    "\n",
    "def display_nice(df, num_rows=None):\n",
    "    \"\"\"Primary function to format and display a DataFrame.\"\"\"\n",
    "    if num_rows is not None:\n",
    "        df = df.head(num_rows)\n",
    "    formatted_df = _format_dataframe_for_tabulate(df)\n",
    "    html_table = _dataframe_to_html_table(formatted_df)\n",
    "    display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing RFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV file paths\n",
    "existing_rfp_paths = [\n",
    "    \"datasets/rag/rfp_existing_questions_client_2.csv\",\n",
    "]\n",
    "\n",
    "existing_rfp_df = [pd.read_csv(file_path) for file_path in existing_rfp_paths]\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "existing_rfp_df = pd.concat(existing_rfp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "documents = []\n",
    "\n",
    "# Iterate through each file path in the list\n",
    "for file_path in existing_rfp_paths:\n",
    "    loader = CSVLoader(\n",
    "        file_path=file_path,\n",
    "        metadata_columns=[\"Area\"]\n",
    "    )\n",
    "\n",
    "    # Load a document from the current CSV file\n",
    "    doc = loader.load()\n",
    "    \n",
    "    # Append documents\n",
    "    documents.extend(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the documents loaded: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 1\\nRFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?\\nRFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of 95%.\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General'}),\n",
       " Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 2\\nRFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?\\nRFP_Answer: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures that our applications remain innovative, with capabilities that adapt to evolving market demands and client needs. This approach has enabled us to enhance the predictive accuracy of our financial forecasting tools by 25% and improve the efficiency of our educational content personalization by 40%\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General'}),\n",
       " Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 3\\nRFP_Question: Are your AI applications adaptable to specific requirements of users or businesses?\\nRFP_Answer: Absolutely, customization is a core aspect of our offering. We work closely with clients to understand their specific needs and tailor our AI algorithms and app functionalities accordingly, using technologies such as TensorFlow for machine learning models, React for responsive UI/UX designs, and Kubernetes for scalable cloud deployment. This personalized approach allows us to optimize AI functionalities to match unique business processes, enhancing user experience and operational efficiency for each client. For example, for a retail client, we customized our recommendation engine to increase customer retention by 20% through more accurate and personalized product suggestions.\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 2, 'Area': 'General'}),\n",
       " Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 4\\nRFP_Question: What steps do you undertake to protect user privacy and secure data within your AI applications?\\nRFP_Answer: User privacy and data security are paramount. We implement robust measures such as end-to-end encryption to secure data transmissions, anonymization techniques to protect user identities, and comprehensive compliance with data protection laws like GDPR and CCPA. We also employ regular security audits and vulnerability assessments to ensure our systems are impenetrable. Additionally, our deployment of advanced intrusion detection systems and the use of secure coding practices reinforce our commitment to safeguarding user data at all times\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 3, 'Area': 'General'}),\n",
       " Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 5\\nRFP_Question: What strategies do you employ to design user interfaces and experiences in AI applications to maximize usability and user engagement?\\nRFP_Answer: Our design philosophy centers on simplicity and intuitiveness. We conduct extensive user research and testing to inform our UI/UX designs, ensuring that our AI-based apps are accessible and engaging for all users, regardless of their technical expertise. This includes applying principles from human-centered design, utilizing accessibility guidelines such as WCAG 2.1, and conducting iterative testing with diverse user groups. Our commitment to inclusivity and usability leads to higher user adoption rates and satisfaction. For instance, feedback-driven enhancements in our visual design have improved user engagement by over 30% across our applications.\\nLast_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 4, 'Area': 'General'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'datasets/rag/rfp_existing_questions_client_2.csv',\n",
       " 'row': 0,\n",
       " 'Area': 'General'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=10, add_start_index=True\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 1\\nRFP_Question: Can you discuss your expertise in creating AI-driven applications and share examples of your successful implementations?', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 0}),\n",
       " Document(page_content='RFP_Answer: Our company has 15 years of experience in developing AI-based applications, with a strong portfolio in sectors such as healthcare, finance, and education. For instance, our project MediAI Insight for the healthcare industry demonstrated significant achievements in patient data analysis, resulting in a 30% reduction in diagnostic errors and a 40% improvement in treatment personalization. Our platform has engaged over 200 healthcare facilities, achieving a user satisfaction rate of', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 234}),\n",
       " Document(page_content='rate of 95%.', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 723}),\n",
       " Document(page_content='Last_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 736}),\n",
       " Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 2\\nRFP_Question: How do you keep your AI applications current with ongoing advancements in artificial intelligence?', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General', 'start_index': 0}),\n",
       " Document(page_content='RFP_Answer: We maintain a dedicated R&D team focused on integrating the latest AI advancements into our applications. This includes regular updates and feature enhancements based on cutting-edge technologies such as GPT (Generative Pre-trained Transformer) for natural language understanding, CNNs (Convolutional Neural Networks) for advanced image recognition tasks, and DQN (Deep Q-Networks) for decision-making processes in complex environments. Our commitment to these AI methodologies ensures', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General', 'start_index': 212}),\n",
       " Document(page_content='ensures that our applications remain innovative, with capabilities that adapt to evolving market demands and client needs. This approach has enabled us to enhance the predictive accuracy of our financial forecasting tools by 25% and improve the efficiency of our educational content personalization by 40%', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General', 'start_index': 702}),\n",
       " Document(page_content='Last_Accessed_At: 18/12/2022\\nRequester: Bank B\\nStatus: Awarded', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General', 'start_index': 1008}),\n",
       " Document(page_content='Project_Title: AI-Powered Risk Assessment Model Development for Loan Processing\\nRFP_Question_ID: 3\\nRFP_Question: Are your AI applications adaptable to specific requirements of users or businesses?', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 2, 'Area': 'General', 'start_index': 0}),\n",
       " Document(page_content='RFP_Answer: Absolutely, customization is a core aspect of our offering. We work closely with clients to understand their specific needs and tailor our AI algorithms and app functionalities accordingly, using technologies such as TensorFlow for machine learning models, React for responsive UI/UX designs, and Kubernetes for scalable cloud deployment. This personalized approach allows us to optimize AI functionalities to match unique business processes, enhancing user experience and operational', metadata={'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 2, 'Area': 'General', 'start_index': 197})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store chunks into a vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"docs_store\",\n",
    "    embedding_function=embeddings_model,\n",
    "    persist_directory=\"docs-db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new chunk IDs based on chunk metadata\n",
    "\n",
    "Expand the existing index to include the metadata fields. For this will define a hash function to create unique identifiers from existing split ids and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 0}\n",
      "{'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 234}\n",
      "{'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 723}\n",
      "{'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 0, 'Area': 'General', 'start_index': 736}\n",
      "{'source': 'datasets/rag/rfp_existing_questions_client_2.csv', 'row': 1, 'Area': 'General', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "for split in splits[:5]:  \n",
    "    print(split.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrac the source for example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/rag/rfp_existing_questions_client_2.csv\n",
      "datasets/rag/rfp_existing_questions_client_2.csv\n",
      "datasets/rag/rfp_existing_questions_client_2.csv\n",
      "datasets/rag/rfp_existing_questions_client_2.csv\n",
      "datasets/rag/rfp_existing_questions_client_2.csv\n"
     ]
    }
   ],
   "source": [
    "for split in splits[:5]:  \n",
    "    print(split.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def stable_hash_meta(doc: Document) -> str:\n",
    "    \"\"\"\n",
    "    Stable hash document based on its metadata. Assumes 'metadata' is always present.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        metadata_json = json.dumps(doc.metadata, sort_keys=True)\n",
    "    except AttributeError:\n",
    "        raise ValueError(\"Document does not have metadata.\")\n",
    "    return hashlib.sha1(metadata_json.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_ids = [{\"doc\": split, \"id\": stable_hash_meta(split)} for split in splits]\n",
    "\n",
    "existing_ids = vectorstore.get()[\"ids\"]\n",
    "\n",
    "new_splits_ids = [split for split in splits_ids if split[\"id\"] not in existing_ids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  id</th><th>new_rfp                         </th><th>new_question  </th><th>question_to_llm  </th><th>answer  </th><th>ground_truth  </th><th>existing_rfp                        </th><th>llm        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   1</td><td>rfp_new_questions_client_100.csv</td><td>What is your experience in developing AI-based\n",
       "applications, and can you provide examples of\n",
       "successful projects?               </td><td>What is the most similar question to: &quot;What is\n",
       "your experience in developing AI-based\n",
       "applications, and can you provide examples of\n",
       "successful projects?&quot;                  </td><td>None    </td><td>Can you discuss your expertise in creating AI-\n",
       "driven applications and share examples of your\n",
       "successful implementations?               </td><td>rfp_exisiting_questions_client_2.csv</td><td>gpt-4-turbo</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   2</td><td>rfp_new_questions_client_100.csv</td><td>How do you ensure your AI-based apps remain up-to-\n",
       "date with the latest AI advancements and\n",
       "technologies?               </td><td>What is the most similar question to: &quot;How do you\n",
       "ensure your AI-based apps remain up-to-date with\n",
       "the latest AI advancements and technologies?&quot;                  </td><td>None    </td><td>How do you keep your AI applications current with\n",
       "ongoing advancements in artificial intelligence?               </td><td>rfp_exisiting_questions_client_2.csv</td><td>gpt-4-turbo</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   3</td><td>rfp_new_questions_client_100.csv</td><td>Can your AI-based applications be customized to\n",
       "meet specific user or business needs?               </td><td>What is the most similar question to: &quot;Can your\n",
       "AI-based applications be customized to meet\n",
       "specific user or business needs?&quot;                  </td><td>None    </td><td>Are your AI applications adaptable to specific\n",
       "requirements of users or businesses?               </td><td>rfp_exisiting_questions_client_2.csv</td><td>gpt-4-turbo</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   4</td><td>rfp_new_questions_client_100.csv</td><td>What measures do you take to ensure user privacy\n",
       "and data security in your AI-based apps?               </td><td>What is the most similar question to: &quot;What\n",
       "measures do you take to ensure user privacy and\n",
       "data security in your AI-based apps?&quot;                  </td><td>None    </td><td>What steps do you undertake to protect user\n",
       "privacy and secure data within your AI\n",
       "applications?               </td><td>rfp_exisiting_questions_client_2.csv</td><td>gpt-4-turbo</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   5</td><td>rfp_new_questions_client_100.csv</td><td>How do you approach user interface and experience\n",
       "design in AI-based apps to ensure ease of use and\n",
       "engagement?               </td><td>What is the most similar question to: &quot;How do you\n",
       "approach user interface and experience design in\n",
       "AI-based apps to ensure ease of use and\n",
       "engagement?&quot;                  </td><td>None    </td><td>What strategies do you employ to design user\n",
       "interfaces and experiences in AI applications to\n",
       "maximize usability and user engagement?               </td><td>rfp_exisiting_questions_client_2.csv</td><td>gpt-4-turbo</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load all RFPs into a single pandas DataFrame\n",
    "\n",
    "rag_evaluation_df = pd.read_csv(\"datasets/rag/rag_evaluation_dataset_v1.csv\")\n",
    "\n",
    "display_nice(rag_evaluation_df, num_rows=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.0)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context. \n",
    "If you cannot answer the question with the context, please respond with 'I don't know':\n",
    "\n",
    "### CONTEXT\n",
    "{context}\n",
    "\n",
    "### QUESTION\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    return \"\\n\\n\".join(\n",
    "        f\"Content: {doc.page_content}\\nSource: {doc.metadata['source']}\" for doc in docs\n",
    "    )\n",
    "\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(\n",
    "        source_documents=(lambda x: format_docs(x[\"source_documents\"]))\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain = RunnableParallel(\n",
    "    {\n",
    "        \"source_documents\": retriever,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if 'source_documents' not in rag_evaluation_df.columns:\n",
    "#    rag_evaluation_df['source_documents'] = pd.Series([[] for _ in range(len(rag_evaluation_df))], index=rag_evaluation_df.index)\n",
    "\n",
    "\n",
    "# Iterate over the DataFrame rows\n",
    "for i, row in rag_evaluation_df.iterrows():\n",
    "    print(f\"Processing row {i}...\")\n",
    "\n",
    "    # Check if the 'answer' field is 'None' (as a string) for the current row\n",
    "    if row[\"answer\"] == \"None\":\n",
    "        print(f\"Answer is 'None' for question ID {i}. Invoking RAG model...\")\n",
    "\n",
    "        # Invoke the RAG model with the question from the current row\n",
    "        response = rag_chain.invoke(row[\"question_to_llm\"])\n",
    "\n",
    "        # Store whatever response comes from the LLM\n",
    "        rag_evaluation_df.at[i, \"answer\"] = response[\"answer\"]\n",
    "        print(f\"Question ID {i} answer updated with the response from the RAG model.\")\n",
    "\n",
    "        # Compute the hashed metadata for each source document\n",
    "        source_hashes = [stable_hash_meta(source_document.metadata) for source_document in response[\"source_documents\"]]\n",
    "\n",
    "        # Check if source_hashes is a list before assignment, throw error if not\n",
    "        #if not isinstance(source_hashes, list):\n",
    "        #    print(f\"Expected a list for source_hashes but got {type(source_hashes)} instead.\")\n",
    "        #    raise TypeError(f\"source_hashes must be a list, but was {type(source_hashes)}\")\n",
    "\n",
    "        # Assign the list of source document hashes directly to the DataFrame cell\n",
    "        #rag_evaluation_df.at[i, \"source_documents\"] = source_hashes\n",
    "        #print(f\"Question ID {i} source documents updated with hashed metadata.\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_nice(rag_evaluation_df, num_rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "\n",
    "from ragas.metrics.critique import harmfulness\n",
    "from ragas import evaluate\n",
    "\n",
    "def create_ragas_dataset(rag_pipeline, eval_dataset):\n",
    "  rag_dataset = []\n",
    "  for row in tqdm(eval_dataset):\n",
    "    answer = rag_pipeline.invoke({\"question\" : row[\"question\"]})\n",
    "    rag_dataset.append(\n",
    "        {\"question\" : row[\"question\"],\n",
    "         \"answer\" : answer[\"response\"].content,\n",
    "         \"contexts\" : [context.page_content for context in answer[\"context\"]],\n",
    "         \"ground_truths\" : [row[\"ground_truth\"]]\n",
    "         }\n",
    "    )\n",
    "  rag_df = pd.DataFrame(rag_dataset)\n",
    "  rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
    "  return rag_eval_dataset\n",
    "\n",
    "def evaluate_ragas_dataset(ragas_dataset):\n",
    "  result = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\\\n",
    "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-py3.10",
   "language": "python",
   "name": "validmind-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

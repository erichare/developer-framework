{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for Application Scorecard Model Documentation\n",
    "\n",
    "This interactive notebook guides model developers through the process of documenting a model with the ValidMind Developer Framework. It uses the [Lending Club](https://www.kaggle.com/code/kmalit/bank-customer-churn-prediction/data) sample dataset from ... to build a simple application scorecard.\n",
    "\n",
    "As part of the notebook, you will learn how to train a sample model while exploring how the documentation process works:\n",
    "\n",
    "- Initializing the ValidMind Developer Framework\n",
    "- Loading a sample dataset provided by the library to train an application scorecard model\n",
    "- Running a ValidMind test suite to quickly generate documention about the data and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ValidMind at a glance\n",
    "\n",
    "ValidMind's platform enables organizations to identify, document, and manage model risks for all types of models, including AI/ML models, LLMs, and statistical models. As a model developer, you use the ValidMind Developer Framework to automate documentation and validation tests, and then use the ValidMind AI Risk Platform UI to collaborate on model documentation. Together, these products simplify model risk management, facilitate compliance with regulations and institutional standards, and enhance collaboration between yourself and model validators.\n",
    "\n",
    "If this is your first time trying out ValidMind, you can make use of the following resources alongside this notebook:\n",
    "\n",
    "- [Get started](https://docs.validmind.ai/guide/get-started.html) — The basics, including key concepts, and how our products work\n",
    "- [Get started with the ValidMind Developer Framework](https://docs.validmind.ai/guide/get-started-developer-framework.html) — The path for developers, more code samples, and our developer reference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "::: {.callout-tip}\n",
    "\n",
    "### New to ValidMind?\n",
    "\n",
    "For access to all features available in this notebook, create a free ValidMind account.\n",
    "\n",
    "Signing up is FREE — [**Sign up now**](https://app.prod.validmind.ai)\n",
    ":::\n",
    "\n",
    "If you encounter errors due to missing modules in your Python environment, install the modules with `pip install`, and then re-run the notebook. For more help, refer to [Installing Python Modules](https://docs.python.org/3/installing/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the client library\n",
    "\n",
    "The client library provides Python support for the ValidMind Developer Framework. To install it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "ValidMind generates a unique _code snippet_ for each registered model to connect with your developer environment. You initialize the client library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.\n",
    "\n",
    "Get your code snippet:\n",
    "\n",
    "1. In a browser, log into the [Platform UI](https://app.prod.validmind.ai).\n",
    "\n",
    "2. In the left sidebar, navigate to **Model Inventory** and click **+ Register new model**.\n",
    "\n",
    "3. Enter the model details and click **Continue**. ([Need more help?](https://docs.validmind.ai/guide/register-models-in-model-inventory.html))\n",
    "\n",
    "   For example, to register a model for use with this notebook, select:\n",
    "\n",
    "   - Documentation template: `Binary classification`\n",
    "   - Use case: `Marketing/Sales - Attrition/Churn Management`\n",
    "\n",
    "   You can fill in other options according to your preference.\n",
    "\n",
    "4. Go to **Getting Started** and click **Copy snippet to clipboard**.\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your code snippet\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"https://api.prod.validmind.ai/api/v1/tracking\",\n",
    "  api_key = \"...\",\n",
    "  api_secret = \"...\",\n",
    "  project = \"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Python environment\n",
    "\n",
    "Next, let's import the necessary libraries and set up your Python environment for data analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the documentation template\n",
    "\n",
    "A template predefines sections for your model documentation and provides a general outline to follow, making the documentation process much easier.\n",
    "\n",
    "You will upload documentation and test results into this template later on. For now, take a look at the structure that the template provides with the `vm.preview_template()` function from the ValidMind library and note the empty sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.preview_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the sample dataset\n",
    "\n",
    "The sample dataset used here is provided by the ValidMind library. To be able to use it, you need to import the dataset and load it into a pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html), a two-dimensional tabular data structure that makes use of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sample dataset from the library\n",
    "\n",
    "from validmind.datasets.credit_risk import lending_club\n",
    "\n",
    "raw_df = lending_club.load()\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the raw dataset\n",
    "\n",
    "Cleaning involves a series of processing steps to refine the dataset for statistical analysis. This is simplified by utilizing `lending_club.clean_data`, which implements the following data cleaning tasks: \n",
    "\n",
    "- Drop rows with missing target values. \n",
    "- Drop columns with more than 50% missing values. \n",
    "- Drop columns with only one unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = lending_club.clean(raw_df)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepocess the clean dataset\n",
    "\n",
    "Preprocessing performs a number of operations to get ready for the subsequent steps:\n",
    "\n",
    "- Preprocess the data: Splits the DataFrame (`df`) into multiple datasets (`train_df`, `validation_df`, and `test_df`) using `lending_club.preprocess` to simplify preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_df = lending_club.preprocess(clean_df)\n",
    "preprocess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "\n",
    "TBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_df = lending_club.feature_engineering(preprocess_df)\n",
    "fe_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "TBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = lending_club.split(fe_df, add_constant=True)\n",
    "\n",
    "x_train = train_df.drop(lending_club.target_column, axis=1)\n",
    "y_train = train_df[lending_club.target_column]\n",
    "x_test = test_df.drop(lending_club.target_column, axis=1)\n",
    "y_test = test_df[lending_club.target_column]\n",
    "\n",
    "# Define the model\n",
    "model = sm.GLM(\n",
    "    y_train, \n",
    "    x_train, \n",
    "    family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "model = model.fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document the model\n",
    "\n",
    "As part of documenting the model with the ValidMind Developer Framework, you need to preprocess the raw dataset, initialize some training and test datasets, initialize a model object you can use for testing, and then run the full suite of tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the ValidMind datasets\n",
    "\n",
    "Before you can run tests, you must first initialize a ValidMind dataset object using the [`init_dataset`](https://docs.validmind.ai/validmind/validmind.html#init_dataset) function from the ValidMind (`vm`) module.\n",
    "\n",
    "This function takes a number of arguments:\n",
    "\n",
    "- `dataset` — the dataset that you want to provide as input to tests\n",
    "- `input_id` - a unique identifier that allows tracking what inputs are used when running each individual test\n",
    "- `target_column` — a required argument if tests require access to true values. This is the name of the target column in the dataset\n",
    "\n",
    "With all datasets ready, you can now initialize the raw, processed, training and test datasets (`raw_df`, `clean_df`, `preprocessed_df`, `fe_df`,  `train_df` and `test_df`) created earlier into their own dataset objects using [`vm.init_dataset()`](https://docs.validmind.ai/validmind/validmind.html#init_dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_raw_dataset = vm.init_dataset(\n",
    "    dataset=raw_df,\n",
    "    input_id=\"raw_dataset\",\n",
    "    target_column=lending_club.target_column,\n",
    ")\n",
    "\n",
    "vm_clean_dataset = vm.init_dataset(\n",
    "    dataset=clean_df,\n",
    "    input_id=\"clean_dataset\",\n",
    "    target_column=lending_club.target_column,\n",
    ")\n",
    "\n",
    "vm_preprocess_dataset = vm.init_dataset(\n",
    "    dataset=preprocess_df,\n",
    "    input_id=\"preprocess_dataset\",\n",
    "    target_column=lending_club.target_column,\n",
    ")\n",
    "\n",
    "vm_fe_dataset = vm.init_dataset(\n",
    "    dataset=fe_df,\n",
    "    input_id=\"fe_dataset\",\n",
    "    target_column=lending_club.target_column,\n",
    ")\n",
    "\n",
    "vm_train_ds = vm.init_dataset(\n",
    "    dataset=train_df,\n",
    "    input_id=\"train_dataset\",\n",
    "    target_column=lending_club.target_column,\n",
    ")\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=test_df, \n",
    "    input_id=\"test_dataset\", \n",
    "    target_column=lending_club.target_column\n",
    ")\n",
    "\n",
    "print(vm_raw_dataset)\n",
    "print(vm_clean_dataset)\n",
    "print(vm_preprocess_dataset)\n",
    "print(vm_fe_dataset)\n",
    "print(vm_train_ds)\n",
    "print(vm_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a model object\n",
    "\n",
    "Additionally, you need to initialize a ValidMind model object (`vm_model`) that can be passed to other functions for analysis and tests on the data. You simply intialize this model object with [`vm.init_model()`](https://docs.validmind.ai/validmind/validmind.html#init_model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_model = vm.init_model(\n",
    "    model,\n",
    "    input_id=\"glm_model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign predictions to the datasets\n",
    "\n",
    "We can now use the `assign_predictions()` method from the `Dataset` object to link existing predictions to any model. If no prediction values are passed, the method will compute predictions automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds.assign_predictions(\n",
    "    model=vm_model,\n",
    ")\n",
    "\n",
    "vm_test_ds.assign_predictions(\n",
    "    model=vm_model,\n",
    ")\n",
    "\n",
    "print(vm_train_ds)\n",
    "print(vm_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.TabularDescriptionTables\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_raw_dataset\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.MissingValuesBarPlot\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_raw_dataset\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.TabularDescriptionTables\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_clean_dataset\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.TabularDescriptionTables\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_preprocess_dataset\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.IQROutliersTable\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_preprocess_dataset\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.ClassImbalance\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_preprocess_dataset\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.TabularNumericalHistograms\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_preprocess_dataset\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.TabularCategoricalBarPlots\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_preprocess_dataset\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.TargetRateBarPlots\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_preprocess_dataset\n",
    "    },\n",
    "    params = {\n",
    "        \"default_column\": lending_club.target_column,\n",
    "        \"columns\": None\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.PearsonCorrelationMatrix\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_preprocess_dataset\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document WoE analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.WOEBinTable\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_preprocess_dataset\n",
    "    },\n",
    "    params = {\n",
    "        \"breaks_adj\": lending_club.breaks_adj\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.data_validation.WOEBinPlots\",\n",
    "    inputs = {\n",
    "        \"dataset\": vm_preprocess_dataset\n",
    "    },\n",
    "    params = {\n",
    "        \"breaks_adj\": lending_club.breaks_adj\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.model_validation.statsmodels.RegressionCoeffsPlot\",\n",
    "    inputs = {\n",
    "        \"models\": [vm_model]\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.model_validation.statsmodels.RegressionModelsCoeffs\",\n",
    "    inputs = {\n",
    "        \"models\": [vm_model]\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.model_validation.statsmodels.GINITable\",\n",
    "    inputs = {\n",
    "        \"model\": vm_model,\n",
    "        \"datasets\": [vm_train_ds, vm_test_ds]\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run:\n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.statsmodels.LogRegressionConfusionMatrix\",\n",
    "        inputs = {\n",
    "            \"model\": vm_model\n",
    "        },\n",
    "        params = {\n",
    "            \"cut_off_threshold\": 0.5\n",
    "        }\n",
    "    )\n",
    "    test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False\n",
    "if run:\n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.sklearn.ROCCurve\",\n",
    "        inputs = {\n",
    "            \"model\": vm_model,\n",
    "            \"dataset\": vm_test_ds\n",
    "        }\n",
    "    )\n",
    "    test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= vm.tests.run_test(\n",
    "    \"validmind.model_validation.statsmodels.LogisticRegPredictionHistogram\",\n",
    "    inputs = {\n",
    "        \"model\": vm_model,\n",
    "        \"datasets\": [vm_train_ds, vm_test_ds]\n",
    "    }\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True\n",
    "if run:\n",
    "\n",
    "    test= vm.tests.run_test(\n",
    "        \"validmind.model_validation.statsmodels.LogisticRegCumulativeProb\",\n",
    "        inputs = {\n",
    "            \"model\": vm_model,\n",
    "            \"datasets\": [vm_train_ds, vm_test_ds]\n",
    "        }\n",
    "    )\n",
    "    test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "You can look at the results of this test suite right in the notebook where you ran the code, as you would expect. But there is a better way: view the test results as part of your model documentation right in the ValidMind Platform UI: \n",
    "\n",
    "1. In the [Platform UI](https://app.prod.validmind.ai), go to the **Documentation** page for the model you registered earlier.\n",
    "\n",
    "2. TBC\n",
    "\n",
    "What you can see now is a more easily consumable version of the tests you just executed, along with other parts of your model documentation that still need to be completed. \n",
    "\n",
    "If you want to learn more about where you are in the model documentation process, take a look at [How do I use the framework?](https://docs.validmind.ai/guide/get-started-developer-framework.html#how-do-i-use-the-framework)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-py3.10",
   "language": "python",
   "name": "validmind-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

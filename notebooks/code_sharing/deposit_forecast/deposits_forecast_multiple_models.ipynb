{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deposits Forecast Multiple Models using PyMC and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data preparation\n",
    "   - Load data\n",
    "   - Create VM datasets\n",
    "   - Run data validation tests\n",
    "2. Model development\n",
    "   - Fit seasonality and random forest model\n",
    "   - Create VM datasets and models \n",
    "   - Assign predictions\n",
    "   - Run model validation tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "\n",
    "Let's go ahead and install the `validmind` library if its not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "ValidMind generates a unique _code snippet_ for each registered model to connect with your developer environment. You initialize the client library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.\n",
    "\n",
    "Get your code snippet:\n",
    "\n",
    "1. In a browser, log into the [Platform UI](https://app.prod.validmind.ai).\n",
    "\n",
    "2. In the left sidebar, navigate to **Model Inventory** and click **+ Register new model**.\n",
    "\n",
    "3. Enter the model details, making sure to select **Time Series Forecasting** as the template and **Credit Risk - Underwriting - Loan** as the use case, and click **Continue**. ([Need more help?](https://docs.validmind.ai/guide/register-models-in-model-inventory.html))\n",
    "\n",
    "4. Go to **Getting Started** and click **Copy snippet to clipboard**.\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"https://api.prod.validmind.ai/api/v1/tracking\",\n",
    "  api_key = \"...\",\n",
    "  api_secret = \"...\",\n",
    "  project = \"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External test provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import LocalTestProvider\n",
    "\n",
    "tests_folder = \"tests\"\n",
    "# initialize the test provider with the tests folder we created earlier\n",
    "my_test_provider = LocalTestProvider(tests_folder)\n",
    "\n",
    "vm.tests.register_test_provider(\n",
    "    namespace=\"deposits_test_provider\",\n",
    "    test_provider=my_test_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.datasets.regression import fred_multiple_deposits as demo\n",
    "\n",
    "deposits_1, deposits_2, deposits_3, deposits_4, deposits_5, fed_funds, tb3ms, gs10, gs30, = demo.load_data()\n",
    "\n",
    "target_column = \"DPSACBW027NBOG\"\n",
    "\n",
    "# Create raw dataframe for model 1\n",
    "raw_1_df = deposits_1.copy()\n",
    "raw_1_df[\"FEDFUNDS\"] = fed_funds[\"FEDFUNDS\"]\n",
    "raw_1_df[\"TB3MS\"] = tb3ms[\"TB3MS\"]\n",
    "raw_1_df[\"GS10\"] = gs10[\"GS10\"]\n",
    "raw_1_df[\"GS30\"] = gs30[\"GS30\"]\n",
    "\n",
    "# Create raw dataframe for model 2\n",
    "raw_2_df = deposits_2.copy()\n",
    "raw_2_df[\"FEDFUNDS\"] = fed_funds[\"FEDFUNDS\"]\n",
    "raw_2_df[\"TB3MS\"] = tb3ms[\"TB3MS\"]\n",
    "raw_2_df[\"GS10\"] = gs10[\"GS10\"]\n",
    "raw_2_df[\"GS30\"] = gs30[\"GS30\"]\n",
    "\n",
    "# Create raw dataframe for model 3\n",
    "raw_3_df = deposits_3.copy()\n",
    "raw_3_df[\"FEDFUNDS\"] = fed_funds[\"FEDFUNDS\"]\n",
    "raw_3_df[\"TB3MS\"] = tb3ms[\"TB3MS\"]\n",
    "raw_3_df[\"GS10\"] = gs10[\"GS10\"]\n",
    "raw_3_df[\"GS30\"] = gs30[\"GS30\"]\n",
    "\n",
    "# Create raw dataframe for model 4\n",
    "raw_4_df = deposits_4.copy()\n",
    "raw_4_df[\"FEDFUNDS\"] = fed_funds[\"FEDFUNDS\"]\n",
    "raw_4_df[\"TB3MS\"] = tb3ms[\"TB3MS\"]\n",
    "raw_4_df[\"GS10\"] = gs10[\"GS10\"]\n",
    "raw_4_df[\"GS30\"] = gs30[\"GS30\"]\n",
    "\n",
    "# Create raw dataframe for model 5\n",
    "raw_5_df = deposits_5.copy()\n",
    "raw_5_df[\"FEDFUNDS\"] = fed_funds[\"FEDFUNDS\"]\n",
    "raw_5_df[\"TB3MS\"] = tb3ms[\"TB3MS\"]\n",
    "raw_5_df[\"GS10\"] = gs10[\"GS10\"]\n",
    "raw_5_df[\"GS30\"] = gs30[\"GS30\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create VM datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_raw_1_ds = vm.init_dataset(\n",
    "    dataset=raw_1_df,\n",
    "    input_id=\"raw_1_ds\",\n",
    "    target_column=target_column,\n",
    ")\n",
    "\n",
    "vm_raw_2_ds = vm.init_dataset(\n",
    "    dataset=raw_2_df,\n",
    "    input_id=\"raw_2_ds\",\n",
    "    target_column=target_column,\n",
    ")\n",
    "\n",
    "vm_raw_3_ds = vm.init_dataset(\n",
    "    dataset=raw_3_df,\n",
    "    input_id=\"raw_3_ds\",\n",
    "    target_column=target_column,\n",
    ")\n",
    "\n",
    "vm_raw_4_ds = vm.init_dataset(\n",
    "    dataset=raw_4_df,\n",
    "    input_id=\"raw_4_ds\",\n",
    "    target_column=target_column,\n",
    ")\n",
    "\n",
    "vm_raw_5_ds = vm.init_dataset(\n",
    "    dataset=raw_5_df,\n",
    "    input_id=\"raw_5_ds\",\n",
    "    target_column=target_column,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run data validation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [vm_raw_1_ds, vm_raw_2_ds, vm_raw_3_ds, vm_raw_4_ds, vm_raw_5_ds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Datasets Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    f\"deposits_test_provider.TimeSeriesDatasetsDescription\",\n",
    "    inputs={\"datasets\": datasets}\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Target Variable Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    f\"deposits_test_provider.TimeSeriesTargetVariableDescription\",\n",
    "    inputs={\"datasets\": datasets}\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Line Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run=True\n",
    "if run:\n",
    "\n",
    "    for i, dataset in enumerate(datasets, start=1):\n",
    "        test = vm.tests.run_test(\n",
    "            f\"validmind.data_validation.TimeSeriesLinePlot:raw_dataset_{i}\",\n",
    "            inputs={\"dataset\": dataset}\n",
    "        )\n",
    "        test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run=True\n",
    "if run:\n",
    "\n",
    "    for i, dataset in enumerate(datasets, start=1):\n",
    "        test = vm.tests.run_test(\n",
    "            f\"validmind.data_validation.TimeSeriesFrequency:raw_dataset_{i}\",\n",
    "            inputs={\"dataset\": dataset}\n",
    "        )\n",
    "        test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run=True\n",
    "if run:\n",
    "\n",
    "    for i, dataset in enumerate(datasets, start=1):\n",
    "        test = vm.tests.run_test(\n",
    "            f\"validmind.data_validation.SeasonalDecompose:raw_dataset_{i}\",\n",
    "            inputs={\"dataset\": dataset}\n",
    "        )\n",
    "        test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit seasonality and random forest models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models for dataset 1\n",
    "prior_likelihood_1, prior_seasonality_1, posterior_likelihood_1, posterior_seasonality_1 = demo.fit_pymc_seasonality_model(raw_1_df, target_column, n_order=10)\n",
    "model_1, train_1_df, test_1_df = demo.process_and_train_random_forest(raw_1_df, posterior_seasonality_1, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models for dataset 2\n",
    "prior_likelihood_2, prior_seasonality_2, posterior_likelihood_2, posterior_seasonality_2 = demo.fit_pymc_seasonality_model(raw_2_df, target_column, n_order=10)\n",
    "model_2, train_2_df, test_2_df = demo.process_and_train_random_forest(raw_2_df, posterior_seasonality_2, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models for dataset 3\n",
    "prior_likelihood_3, prior_seasonality_3, posterior_likelihood_3, posterior_seasonality_3 = demo.fit_pymc_seasonality_model(raw_3_df, target_column, n_order=10)\n",
    "model_3, train_3_df, test_3_df = demo.process_and_train_random_forest(raw_3_df, posterior_seasonality_3, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models for dataset 4\n",
    "prior_likelihood_4, prior_seasonality_4, posterior_likelihood_4, posterior_seasonality_4 = demo.fit_pymc_seasonality_model(raw_4_df, target_column, n_order=10)\n",
    "model_4, train_4_df, test_4_df = demo.process_and_train_random_forest(raw_4_df, posterior_seasonality_4, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models for dataset 5\n",
    "prior_likelihood_5, prior_seasonality_5, posterior_likelihood_5, posterior_seasonality_5 = demo.fit_pymc_seasonality_model(raw_5_df, target_column, n_order=10)\n",
    "model_5, train_5_df, test_5_df = demo.process_and_train_random_forest(raw_5_df, posterior_seasonality_5, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create VM datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_1_ds = vm.init_dataset(dataset=train_1_df, input_id=\"train_1_ds\", target_column=target_column)\n",
    "vm_test_1_ds = vm.init_dataset(dataset=test_1_df, input_id=\"test_1_ds\", target_column=target_column)\n",
    "vm_model_1 = vm.init_model(model_1, input_id=\"random_forest_model_1\")\n",
    "\n",
    "vm_train_2_ds = vm.init_dataset(dataset=train_2_df, input_id=\"train_2_ds\", target_column=target_column)\n",
    "vm_test_2_ds = vm.init_dataset(dataset=test_2_df, input_id=\"test_2_ds\", target_column=target_column)\n",
    "vm_model_2 = vm.init_model(model_2, input_id=\"random_forest_model_2\")\n",
    "\n",
    "vm_train_3_ds = vm.init_dataset(dataset=train_3_df, input_id=\"train_3_ds\", target_column=target_column)\n",
    "vm_test_3_ds = vm.init_dataset(dataset=test_3_df, input_id=\"test_3_ds\", target_column=target_column)\n",
    "vm_model_3 = vm.init_model(model_3, input_id=\"random_forest_model_3\")\n",
    "\n",
    "vm_train_4_ds = vm.init_dataset(dataset=train_4_df, input_id=\"train_4_ds\", target_column=target_column)\n",
    "vm_test_4_ds = vm.init_dataset(dataset=test_4_df, input_id=\"test_4_ds\", target_column=target_column)\n",
    "vm_model_4 = vm.init_model(model_4, input_id=\"random_forest_model_4\")\n",
    "\n",
    "vm_train_5_ds = vm.init_dataset(dataset=train_5_df, input_id=\"train_5_ds\", target_column=target_column)\n",
    "vm_test_5_ds = vm.init_dataset(dataset=test_5_df, input_id=\"test_5_ds\", target_column=target_column)\n",
    "vm_model_5 = vm.init_model(model_5, input_id=\"random_forest_model_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_1_ds.assign_predictions(model=vm_model_1)\n",
    "vm_test_1_ds.assign_predictions(model=vm_model_1)\n",
    "\n",
    "vm_train_2_ds.assign_predictions(model=vm_model_2)\n",
    "vm_test_2_ds.assign_predictions(model=vm_model_2)\n",
    "\n",
    "vm_train_3_ds.assign_predictions(model=vm_model_3)\n",
    "vm_test_3_ds.assign_predictions(model=vm_model_3)\n",
    "\n",
    "vm_train_4_ds.assign_predictions(model=vm_model_4)\n",
    "vm_test_4_ds.assign_predictions(model=vm_model_4)\n",
    "\n",
    "vm_train_5_ds.assign_predictions(model=vm_model_5)\n",
    "vm_test_5_ds.assign_predictions(model=vm_model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model validation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [vm_model_1, vm_model_2, vm_model_3, vm_model_4, vm_model_5]\n",
    "raw_datasets = [vm_raw_1_ds, vm_raw_2_ds, vm_raw_3_ds, vm_raw_4_ds, vm_raw_5_ds]\n",
    "train_datasets = [vm_train_1_ds, vm_train_2_ds, vm_train_3_ds, vm_train_4_ds, vm_train_5_ds]\n",
    "test_datasets = [vm_test_1_ds, vm_test_2_ds, vm_test_3_ds, vm_test_4_ds, vm_test_5_ds]\n",
    "\n",
    "prior_likelihoods = [prior_likelihood_1, prior_likelihood_2, prior_likelihood_3, prior_likelihood_4, prior_likelihood_5]\n",
    "prior_seasonalities = [prior_seasonality_1, prior_seasonality_2, prior_seasonality_3, prior_seasonality_4, prior_seasonality_5]\n",
    "posterior_likelihoods = [posterior_likelihood_1, posterior_likelihood_2, posterior_likelihood_3, posterior_likelihood_4, posterior_likelihood_5]\n",
    "posterior_seasonalities = [posterior_seasonality_1, posterior_seasonality_2, posterior_seasonality_3, posterior_seasonality_4, posterior_seasonality_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyMC Seasonality Prior Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (dataset, prior_likelihood) in enumerate(zip(raw_datasets, prior_likelihoods), start=1):\n",
    "    result = vm.tests.run_test(\n",
    "        f\"deposits_test_provider.PyMCPlot:Prior_Likelihood_{i}\",\n",
    "        inputs={\"dataset\": dataset},\n",
    "        params={\"pymc_output\": prior_likelihood, \"title\": \"Prior Predictive Seasonality\"},\n",
    "    ).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (dataset, prior_seasonality) in enumerate(zip(raw_datasets, prior_seasonalities), start=1):\n",
    "    result = vm.tests.run_test(\n",
    "        f\"deposits_test_provider.PyMCSeasonalityPlot:Prior_Seasonality_{i}\",\n",
    "        inputs={\"dataset\": dataset},\n",
    "        params={\"seasonality\": prior_seasonality, \"title\": \"Prior Seasonality Lines\"},\n",
    "    ).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyMC Seasonality Posterior Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (dataset, posterior_likelihood) in enumerate(zip(raw_datasets, posterior_likelihoods), start=1):\n",
    "    result = vm.tests.run_test(\n",
    "        f\"deposits_test_provider.PyMCPlot:Posterior_Likelihood_{i}\",\n",
    "        inputs={\"dataset\": dataset},\n",
    "        params={\"pymc_output\": posterior_likelihood, \"title\": \"Posterior Predictive Seasonality\",\n",
    "        },\n",
    "    ).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (dataset, posterior_seasonality) in enumerate(zip(raw_datasets, posterior_seasonalities), start=1):\n",
    "    result = vm.tests.run_test(\n",
    "        f\"deposits_test_provider.PyMCSeasonalityPlot:Posterior_Seasonality_{i}\",\n",
    "        inputs={\"dataset\": dataset},\n",
    "        params={\"seasonality\": posterior_seasonality, \"title\": \"Posterior Seasonality Lines\"},\n",
    "    ).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"deposits_test_provider.ModelMetadataComparison\",\n",
    "    inputs={\"models\": models}\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models, start=1):\n",
    "    test = vm.tests.run_test(\n",
    "        f\"validmind.model_validation.ModelMetadata:model_{i}\",\n",
    "        inputs={\"model\": model}\n",
    "    )\n",
    "    test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_dataset, test_dataset) in enumerate(zip(train_datasets, test_datasets), start=1):\n",
    "    test = vm.tests.run_test(\n",
    "        f\"validmind.data_validation.DatasetSplit:dataset_{i}\",\n",
    "        inputs={\"datasets\": [train_dataset, test_dataset]}\n",
    "    )\n",
    "    test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"deposits_test_provider.RegressionErrorsComparison:train_datasets\",\n",
    "    inputs={\"datasets\": train_datasets, \"models\": models}\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"deposits_test_provider.RegressionErrorsComparison:test_datasets\",\n",
    "    inputs={\"datasets\": test_datasets, \"models\": models}\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_dataset, test_dataset, model) in enumerate(zip(train_datasets, test_datasets, models), start=1):\n",
    "    test = vm.tests.run_test(\n",
    "        f\"validmind.model_validation.sklearn.RegressionErrors:model_{i}\",\n",
    "        inputs={\"datasets\": [train_dataset, test_dataset], \"model\": model}\n",
    "    )\n",
    "    test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression R2 Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"deposits_test_provider.RegressionR2SquareComparison:train_datasets\",\n",
    "    inputs={\"datasets\": train_datasets, \"models\": models}\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"deposits_test_provider.RegressionR2SquareComparison:test_datasets\",\n",
    "    inputs={\"datasets\": test_datasets, \"models\": models}\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_dataset, test_dataset, model) in enumerate(zip(train_datasets, test_datasets, models), start=1):\n",
    "    test = vm.tests.run_test(\n",
    "        f\"validmind.model_validation.sklearn.RegressionR2Square:model_{i}\",\n",
    "        inputs={\"datasets\": [train_dataset, test_dataset], \"model\": model}\n",
    "    )\n",
    "    test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Residuals Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_dataset, model) in enumerate(zip(train_datasets, models), start=1):\n",
    "    test = vm.tests.run_test(\n",
    "        f\"validmind.model_validation.RegressionResidualsPlot:model_{i}\",\n",
    "        inputs={\"dataset\": train_dataset, \"model\": model}\n",
    "    )\n",
    "    test.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"deposits_test_provider.FeatureImportanceComparison:train_datasets\",\n",
    "    inputs={\"datasets\": train_datasets, \"models\": models}\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vm.tests.run_test(\n",
    "    \"deposits_test_provider.FeatureImportanceComparison:test_datasets\",\n",
    "    inputs={\"datasets\": test_datasets, \"models\": models}\n",
    ")\n",
    "test.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_dataset, model) in enumerate(zip(train_datasets, models), start=1):\n",
    "    test = vm.tests.run_test(\n",
    "        f\"validmind.model_validation.sklearn.PermutationFeatureImportance:train_dataset_{i}\",\n",
    "        inputs={\"dataset\": train_dataset, \"model\": model}\n",
    "    )\n",
    "    test.log()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-py3.10",
   "language": "python",
   "name": "validmind-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Model Validation POC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries\n",
    "import glob\n",
    "\n",
    "# ML libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from arch.unitroot import PhillipsPerron, DFGLS\n",
    "import xgboost as xgb\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Time Series Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/time_series/fred_loan_rates_model_1.pkl', 'rb') as f:\n",
    "    model_1 = pickle.load(f)\n",
    "print(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/time_series/fred_loan_rates_model_2.pkl', 'rb') as f:\n",
    "    model_2 = pickle.load(f)\n",
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/time_series/fred_loan_rates_model_3.pkl', 'rb') as f:\n",
    "    model_3 = pickle.load(f)\n",
    "print(model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/time_series/fred_loan_rates_model_4.pkl', 'rb') as f:\n",
    "    model_4 = pickle.load(f)\n",
    "print(model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/time_series/fred_loan_rates_model_5.pkl', 'rb') as f:\n",
    "    model_5 = pickle.load(f)\n",
    "print(model_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coef_stats(summary, model_name):\n",
    "    table = summary.tables[1].data\n",
    "    headers = table.pop(0)\n",
    "    headers[0] = 'Feature'\n",
    "    df = pd.DataFrame(table, columns=headers)\n",
    "    df['Model'] = model_name\n",
    "    return df\n",
    "\n",
    "def extract_coefficients_summary(summaries):\n",
    "    coef_stats_df = pd.DataFrame()\n",
    "\n",
    "    for i, summary in enumerate(summaries):\n",
    "        model_name = f'Model {i+1}'\n",
    "        coef_stats_df = pd.concat([coef_stats_df, extract_coef_stats(summary, model_name)])\n",
    "\n",
    "    # Reorder columns to have 'Model' as the first column and reset the index\n",
    "    coef_stats_df = coef_stats_df.reset_index(drop=True)[['Model'] + [col for col in coef_stats_df.columns if col != 'Model']]\n",
    "\n",
    "    return coef_stats_df\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "summaries = [model_1.summary(), model_2.summary(), model_3.summary()]\n",
    "coef_stats_df = extract_coefficients_summary(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_stats_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the endogenous (target) variable from the model fit\n",
    "train_df = pd.Series(model_1.model.endog, index=model_1.model.data.row_labels)\n",
    "train_df = train_df.to_frame()\n",
    "target_var_name = model_1.model.endog_names\n",
    "train_df.columns = [target_var_name]\n",
    "\n",
    "# Extract the exogenous (explanatory) variables from the model fit\n",
    "exog_df = pd.DataFrame(model_1.model.exog, index=model_1.model.data.row_labels, columns=model_1.model.exog_names)\n",
    "\n",
    "# Concatenate the endogenous (target) and exogenous (explanatory) variables\n",
    "train_df = pd.concat([train_df, exog_df], axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load raw test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../datasets/time_series/fred_loan_rates_test_1.csv'\n",
    "raw_test_df = pd.read_csv(file, parse_dates=['DATE'], index_col='DATE')\n",
    "display(raw_test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform raw test dataset using same transformation used in the train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_func = 'diff'\n",
    "if transform_func == 'diff':\n",
    "    test_df = raw_test_df.diff().dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_prediction(model_fits_dict, df_test):\n",
    "    # Extract the training data from the first model fit\n",
    "    first_model_fit = list(model_fits_dict.values())[0]\n",
    "    train_data = pd.Series(first_model_fit.model.endog, index=first_model_fit.model.data.row_labels)\n",
    "    train_data = train_data.to_frame()\n",
    "    target_var_name = first_model_fit.model.endog_names\n",
    "    train_data.columns = [f'{target_var_name}_train']\n",
    "\n",
    "    # Initialize an empty DataFrame to store the predictions\n",
    "    prediction_df = pd.DataFrame(index=df_test.index)\n",
    "    prediction_df[f'{target_var_name}_test'] = np.nan\n",
    "\n",
    "    # Concatenate the train_data and prediction_df\n",
    "    combined_df = pd.concat([train_data, prediction_df], axis=0)\n",
    "\n",
    "    # Loop through each model fit\n",
    "    for model_name, model_fit in model_fits_dict.items():\n",
    "        # Prepare the test dataset\n",
    "        exog_names = model_fit.model.exog_names\n",
    "        X_test = df_test.copy()\n",
    "\n",
    "        # Add the constant if it's missing\n",
    "        if 'const' in exog_names and 'const' not in X_test.columns:\n",
    "            X_test['const'] = 1.0\n",
    "\n",
    "        # Select the necessary columns\n",
    "        X_test = X_test[exog_names]\n",
    "\n",
    "        # Generate the predictions\n",
    "        predictions = model_fit.predict(X_test)\n",
    "\n",
    "        # Add the predictions to the DataFrame\n",
    "        combined_df[model_name] = np.nan\n",
    "        combined_df[model_name].iloc[len(train_data):] = predictions\n",
    "\n",
    "    # Add the test data to the '<target_variable>_test' column\n",
    "    combined_df[f'{target_var_name}_test'].iloc[len(train_data):] = df_test[target_var_name]\n",
    "\n",
    "    return combined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your list of model fits\n",
    "model_fits = {\n",
    "    'model_1': model_1,\n",
    "    'model_3': model_3\n",
    "}\n",
    "prediction_df = get_model_prediction(model_fits, test_df)\n",
    "display(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(prediction_df, subplot=True):\n",
    "    n_models = prediction_df.shape[1] - 2\n",
    "\n",
    "    if subplot:\n",
    "        fig, axes = plt.subplots(n_models, 1, figsize=(12, 6 * n_models), sharex=True)\n",
    "\n",
    "        for i in range(n_models):\n",
    "            axes[i].plot(prediction_df.index, prediction_df.iloc[:, 0], label=prediction_df.columns[0], color='grey')\n",
    "            axes[i].plot(prediction_df.index, prediction_df.iloc[:, 1], label=prediction_df.columns[1], color='lightgrey')\n",
    "            axes[i].plot(prediction_df.index, prediction_df.iloc[:, i + 2], label=prediction_df.columns[i + 2], linestyle='-')\n",
    "            axes[i].set_ylabel('Target Variable')\n",
    "            axes[i].set_title(f'Test Data vs. {prediction_df.columns[i + 2]}')\n",
    "            axes[i].legend()\n",
    "            axes[i].grid(True)\n",
    "        plt.xlabel('Date')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(prediction_df.index, prediction_df.iloc[:, 0], label=prediction_df.columns[0], color='grey')\n",
    "        plt.plot(prediction_df.index, prediction_df.iloc[:, 1], label=prediction_df.columns[1], color='lightgrey')\n",
    "\n",
    "        for i in range(2, prediction_df.shape[1]):\n",
    "            plt.plot(prediction_df.index, prediction_df.iloc[:, i], label=prediction_df.columns[i], linestyle='-')\n",
    "\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Target Variable')\n",
    "        plt.title('Test Data vs. Model Forecasts')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(prediction_df, subplot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-eEL8LtKG-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Validation for Large Language Models (LLMs)\n",
    "\n",
    "This notebook guides you through using a large language model (LLM) specialized in sentiment analysis for financial news. It shows you how to set up the ValidMind Developer Framework, initializes the client library, and uses a specific prompt template for analyzing the sentiment of given sentences. The notebook also includes example data to test the model's ability to correctly identify sentiment as positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ValidMind at a glance\n",
    "\n",
    "We offer a platform for managing model risk, including risk associated with AI and statistical models. As a model developer, you use the _ValidMind Developer Framework_ to automate documentation and validation tests, and then use the _ValidMind AI Risk Platform UI_ to collaborate on doucumentation projects. Together, these products simplify model risk management, facilitate compliance with regulations and institutional standards, and enhance collaboration between yourself and model validators.\n",
    "\n",
    "If this is your first time trying out ValidMind:\n",
    "\n",
    "- [Get started](https://docs.validmind.ai/guide/get-started.html) — The basics, including key concepts, and how our products work\n",
    "- [Get started with the ValidMind Developer Framework](https://docs.validmind.ai/guide/get-started-developer-framework.html) —  The path for developers, more code samples, and our developer reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "To use the ValidMind Developer Framework with a Jupyter notebook, you need to install and initialize the client library first, along with getting your Python environment ready. This includes installing any missing prerequisite modules that you discover with `pip install`. \n",
    "\n",
    "If you don't already have one, [create a documentation project](https://docs.validmind.ai/guide/create-your-first-documentation-project.html) for yourself in the Platform UI. You will use this project to upload your documentation and test results.\n",
    "\n",
    "## Install the client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "Every documentation project in the Platform UI comes with a _code snippet_ that lets the client library associate your documentation and tests with the right project on the Platform UI when you run this notebook.\n",
    "\n",
    "First, locate your code snippet: \n",
    "\n",
    "1. In a browser, log into the [Platform UI](https://app.prod.validmind.ai).\n",
    "\n",
    "2. Go to **Documentation Projects** > **YOUR_DOCUMENTATION_PROJECT** > **Getting Started** and click **Copy snippet to clipboard**.\n",
    "   \n",
    "   ::: {.callout-tip}\n",
    "   \n",
    "   This step requires a documentation project. [Learn how you can create one](https://docs.validmind.ai/guide/create-your-first-documentation-project.html).\n",
    "\n",
    "   :::\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace this placeholder with the code snippet from your project ## \n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
    "  api_key = \"...\",\n",
    "  api_secret = \"...\",\n",
    "  project = \"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the template\n",
    "\n",
    "A template predefines sections for your documentation project and provides a general outline to follow, making the documentation process much easier.\n",
    "\n",
    "You will upload documentation and test results into this template later on. For now, take a look at the structure that the template provides with the `vm.preview_template()` function from the ValidMind library and note the empty sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.preview_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the test dataset\n",
    "https://www.kaggle.com/datasets/ankurzing/sentiment-analysis-for-financial-news\n",
    "Download the dataset in the above link and move it into the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.models import FoundationModel, Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    raise Exception(\"OPENAI_API_KEY not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def call_model(prompt):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    ).choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an AI with expertise in sentiment analysis, particularly in the context of financial news.\n",
    "Your task is to analyze the sentiment of a specific sentence provided below.\n",
    "Before proceeding, take a moment to understand the context and nuances of the financial terminology used in the sentence.\n",
    "\n",
    "Sentence to Analyze:\n",
    "```\n",
    "{Sentence}\n",
    "```\n",
    "\n",
    "Please respond with the sentiment of the sentence denoted by one of either 'positive', 'negative', or 'neutral'.\n",
    "Please respond only with the sentiment enum value. Do not include any other text in your response.\n",
    "\n",
    "Note: Ensure that your analysis is based on the content of the sentence and not on external information or assumptions.\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_variables = [\"Sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/sentiments.csv')\n",
    "\n",
    "df_test = df[:10].reset_index(drop=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=df_test,\n",
    "    text_column=\"Sentence\",\n",
    "    target_column=\"Sentiment\",\n",
    ")\n",
    "\n",
    "vm_model = FoundationModel(\n",
    "    predict_fn=call_model,\n",
    "    prompt=Prompt(\n",
    "        template=prompt_template,\n",
    "        variables=prompt_variables,\n",
    "    ),\n",
    "    test_ds=vm_test_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full suite with the following command (it will take a while):\n",
    "#\n",
    "# suite_results = vm.run_documentation_tests(dataset=vm_test_ds, model=vm_model)\n",
    "#\n",
    "# By default the tests will use GPT-3.5 as the evaluation model, to get better results use GPT:\n",
    "# os.environ[\"VM_OPENAI_MODEL\"] = \"gpt4\"\n",
    "\n",
    "test_plan_results = vm.run_test_plan(\"prompt_validation\", model=vm_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization of financial data using a Large Language Model (LLM)\n",
    "\n",
    "This notebook aims to provide an introduction to documenting an LLM using the ValidMind Developer Framework. The use case presented is a summarization of financial news (https://huggingface.co/datasets/cnn_dailymail).\n",
    "\n",
    "- Initializing the ValidMind Developer Framework\n",
    "- Running a test various tests to quickly generate documentation about the data and model\n",
    "\n",
    "## Before you begin\n",
    "\n",
    "To use the ValidMind Developer Framework with a Jupyter notebook, you need to install and initialize the client library first, along with getting your Python environment ready.\n",
    "\n",
    "If you don't already have one, you should also [create a documentation project](https://docs.validmind.ai/guide/create-your-first-documentation-project.html) on the ValidMind platform. You will use this project to upload your documentation and test results.\n",
    "\n",
    "## Install the client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "In a browser, go to the **Client Integration** page of your documentation project and click **Copy to clipboard** next to the code snippet. This code snippet gives you the API key, API secret, and project identifier to link your notebook to your documentation project.\n",
    "\n",
    "::: {.column-margin}\n",
    "::: {.callout-tip}\n",
    "This step requires a documentation project. [Learn how you can create one](https://docs.validmind.ai/guide/create-your-first-documentation-project.html).\n",
    ":::\n",
    ":::\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 18:32:32,431 - INFO(validmind.api_client): Connected to ValidMind. Project: [12] Credit Risk Scorecard - Initial Validation (clmotr3oa000aesy6c54wqb6g)\n"
     ]
    }
   ],
   "source": [
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
    "  api_key = \"2494c3838f48efe590d531bfe225d90b\",\n",
    "  api_secret = \"4f692f8161f128414fef542cab2a4e74834c75d01b3a8e088a1834f2afcfe838\",\n",
    "  project = \"clmotr3oa000aesy6c54wqb6g\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "Let's define the following functions to help visualize datasets with long text fields."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN dataset\n",
    "\n",
    "The CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cnn_dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
    "\n",
    "train_df = cnn_dataset.data['train'].to_pandas()\n",
    "test_df = cnn_dataset.data['test'].to_pandas()\n",
    "val_df = cnn_dataset.data['validation'].to_pandas()\n",
    "\n",
    "train_df = train_df[['article','highlights']]\n",
    "test_df = test_df[['article','highlights']]\n",
    "\n",
    "train_df = train_df.head(10)\n",
    "test_df = test_df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.models import FoundationModel, Prompt\n",
    "import os\n",
    "import dotenv\n",
    "import openai\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    raise Exception(\"OPENAI_API_KEY not found\")\n",
    "\n",
    "\n",
    "def call_model(prompt):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    ).choices[0].message[\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an AI with expertise in summarizing financial news. \n",
    "Your task is to provide a concise summary of the specific news article provided below.\n",
    "Before proceeding, take a moment to understand the context and nuances of the financial terminology used in the article.\n",
    "\n",
    "Article to Summarize:\n",
    "\n",
    "```\n",
    "{article}\n",
    "```\n",
    "\n",
    "Please respond with a concise summary of the article's main points.\n",
    "Ensure that your summary is based on the content of the article and not on external information or assumptions.\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_variables = [\"article\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ValidMind datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 18:32:35,181 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n",
      "2023-10-07 18:32:35,194 - INFO(validmind.models.foundation): Running predict() for `test_ds`... This may take a while\n"
     ]
    }
   ],
   "source": [
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=test_df,\n",
    "    text_column=\"article\",\n",
    "    target_column=\"highlights\",\n",
    ")\n",
    "\n",
    "vm_model = FoundationModel(\n",
    "    predict_fn=call_model,\n",
    "    prompt=Prompt(\n",
    "        template=prompt_template,\n",
    "        variables=prompt_variables,\n",
    "    ),\n",
    "    test_ds=vm_test_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vm.test_suites.describe_suite(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bb1d79eaba4c6f930824be9522fdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<p><strong>Purpose:</strong> The DisplayTextDataset metric provides a tabulated vis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"display_limit\": 1,\n",
    "    \"text_columns\": None\n",
    "}\n",
    "\n",
    "metric = vm.tests.run_test(\"validmind.model_validation.DisplayTextDataset\", \n",
    "                  dataset=vm_test_ds, \n",
    "                  params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94d248179ed49e78ec4d22287cc555f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<p><strong>Purpose:</strong> The SummarizationPredictions metric provides a compari…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"display_limit\": 1\n",
    "}\n",
    "\n",
    "metric = vm.tests.run_test(\"validmind.model_validation.SummarizationPredictions\", \n",
    "                  model=vm_model, \n",
    "                  params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6276b192f5184f738c20eb5d471b8171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<p><strong>Purpose:</strong> The ToxicityHistogram metric visualizes and analyzes t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = vm.tests.run_test(\n",
    "    \"validmind.model_validation.ToxicityHistogram\", \n",
    "    model=vm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005e61c2ca4b4fe182fa24320763bfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<p><strong>Purpose:</strong> The ToxicityLinePlot metric is designed to present a s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = vm.tests.run_test(\n",
    "    \"validmind.model_validation.ToxicityLinePlot\", \n",
    "    model=vm_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Developer Framework (Python 3.10.13)",
   "language": "python",
   "name": "dev-framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

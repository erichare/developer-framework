{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization of financial data using Hugging Face NLP models\n",
    "\n",
    "This notebook aims to provide an introduction to documenting an NLP model using the ValidMind Developer Framework. The use case presented is a summarization of financial news (https://huggingface.co/datasets/cnn_dailymail).\n",
    "\n",
    "- Initializing the ValidMind Developer Framework\n",
    "- Running a test various tests to quickly generate document about the data and model\n",
    "\n",
    "## Before you begin\n",
    "\n",
    "To use the ValidMind Developer Framework with a Jupyter notebook, you need to install and initialize the client library first, along with getting your Python environment ready.\n",
    "\n",
    "If you don't already have one, you should also [create a documentation project](https://docs.validmind.ai/guide/create-your-first-documentation-project.html) on the ValidMind platform. You will use this project to upload your documentation and test results.\n",
    "\n",
    "## Install the client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "In a browser, go to the **Client Integration** page of your documentation project and click **Copy to clipboard** next to the code snippet. This code snippet gives you the API key, API secret, and project identifier to link your notebook to your documentation project.\n",
    "\n",
    "::: {.column-margin}\n",
    "::: {.callout-tip}\n",
    "This step requires a documentation project. [Learn how you can create one](https://docs.validmind.ai/guide/create-your-first-documentation-project.html).\n",
    ":::\n",
    ":::\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 22:18:29,149 - INFO(validmind.api_client): Connected to ValidMind. Project: Summarization (Hugging Face) - Initial Validation (clmqvzvql0005v28hl2tjzf4e)\n"
     ]
    }
   ],
   "source": [
    "## Replace the code below with the code snippet from your project ## \n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"....\",\n",
    "  api_key = \"...\",\n",
    "  api_secret = \"...\",\n",
    "  project = \"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN dataset\n",
    "\n",
    "The CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "cnn_dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
    "train_df = cnn_dataset.data['train'].to_pandas()\n",
    "val_df = cnn_dataset.data['validation'].to_pandas()\n",
    "test_df = cnn_dataset.data['test'].to_pandas()\n",
    "train_df = train_df[['article','highlights']]\n",
    "train_df = train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 22:18:37,294 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n"
     ]
    }
   ],
   "source": [
    "df = train_df.head(100)\n",
    "# Load a test dataset with 100 rows only\n",
    "vm_ds = vm.init_dataset(\n",
    "    dataset=df,\n",
    "    text_column=\"article\",\n",
    "    target_column=\"highlights\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b5fcc3c4684541b62e0623acad4c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Running test plan...'), IntProgress(value=0, max=14)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andres/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andres/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2f7d134eb244a2b006109ce859970b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Results for <i>Text Data Quality</i> Test Plan:</h2><hr>'), HTML(value='<div clâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_data_test_plan = vm.run_test_plan(\"text_data_quality\",\n",
    "                                       dataset=vm_ds,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "summarizer_model = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=model,\n",
    "    tokenizer = tokenizer,\n",
    "    min_length=0,\n",
    "    max_length=60,\n",
    "    truncation=True,\n",
    "    model_kwargs={\"cache_dir\": '/Documents/Huggin_Face/'},\n",
    ")  # Note: We specify cache_dir to use predownloaded models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 22:18:44,964 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n"
     ]
    }
   ],
   "source": [
    "df_test = df.head(10)\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=train_df,\n",
    "    text_column=\"article\",\n",
    "    target_column=\"highlights\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_model = vm.init_model(\n",
    "    summarizer_model,\n",
    "    test_ds=vm_test_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8b2b8 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8b2b8_row0_col0, #T_8b2b8_row0_col1, #T_8b2b8_row0_col2, #T_8b2b8_row1_col0, #T_8b2b8_row1_col1, #T_8b2b8_row1_col2, #T_8b2b8_row2_col0, #T_8b2b8_row2_col1, #T_8b2b8_row2_col2, #T_8b2b8_row3_col0, #T_8b2b8_row3_col1, #T_8b2b8_row3_col2, #T_8b2b8_row4_col0, #T_8b2b8_row4_col1, #T_8b2b8_row4_col2, #T_8b2b8_row5_col0, #T_8b2b8_row5_col1, #T_8b2b8_row5_col2, #T_8b2b8_row6_col0, #T_8b2b8_row6_col1, #T_8b2b8_row6_col2, #T_8b2b8_row7_col0, #T_8b2b8_row7_col1, #T_8b2b8_row7_col2, #T_8b2b8_row8_col0, #T_8b2b8_row8_col1, #T_8b2b8_row8_col2, #T_8b2b8_row9_col0, #T_8b2b8_row9_col1, #T_8b2b8_row9_col2, #T_8b2b8_row10_col0, #T_8b2b8_row10_col1, #T_8b2b8_row10_col2, #T_8b2b8_row11_col0, #T_8b2b8_row11_col1, #T_8b2b8_row11_col2, #T_8b2b8_row12_col0, #T_8b2b8_row12_col1, #T_8b2b8_row12_col2, #T_8b2b8_row13_col0, #T_8b2b8_row13_col1, #T_8b2b8_row13_col2, #T_8b2b8_row14_col0, #T_8b2b8_row14_col1, #T_8b2b8_row14_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8b2b8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_8b2b8_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_8b2b8_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_8b2b8_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row0_col0\" class=\"data row0 col0\" >classifier_metrics</td>\n",
       "      <td id=\"T_8b2b8_row0_col1\" class=\"data row0 col1\" >ClassifierMetrics</td>\n",
       "      <td id=\"T_8b2b8_row0_col2\" class=\"data row0 col2\" >Test plan for sklearn classifier metrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row1_col0\" class=\"data row1 col0\" >classifier_validation</td>\n",
       "      <td id=\"T_8b2b8_row1_col1\" class=\"data row1 col1\" >ClassifierPerformance</td>\n",
       "      <td id=\"T_8b2b8_row1_col2\" class=\"data row1 col2\" >Test plan for sklearn classifier models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row2_col0\" class=\"data row2 col0\" >classifier_model_diagnosis</td>\n",
       "      <td id=\"T_8b2b8_row2_col1\" class=\"data row2 col1\" >ClassifierDiagnosis</td>\n",
       "      <td id=\"T_8b2b8_row2_col2\" class=\"data row2 col2\" >Test plan for sklearn classifier model diagnosis tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row3_col0\" class=\"data row3 col0\" >prompt_validation</td>\n",
       "      <td id=\"T_8b2b8_row3_col1\" class=\"data row3 col1\" >PromptValidation</td>\n",
       "      <td id=\"T_8b2b8_row3_col2\" class=\"data row3 col2\" >Test plan for prompt validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row4_col0\" class=\"data row4 col0\" >tabular_dataset_description</td>\n",
       "      <td id=\"T_8b2b8_row4_col1\" class=\"data row4 col1\" >TabularDatasetDescription</td>\n",
       "      <td id=\"T_8b2b8_row4_col2\" class=\"data row4 col2\" >Test plan to extract metadata and descriptive\n",
       "    statistics from a tabular dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row5_col0\" class=\"data row5 col0\" >tabular_data_quality</td>\n",
       "      <td id=\"T_8b2b8_row5_col1\" class=\"data row5 col1\" >TabularDataQuality</td>\n",
       "      <td id=\"T_8b2b8_row5_col2\" class=\"data row5 col2\" >Test plan for data quality on tabular datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row6_col0\" class=\"data row6 col0\" >time_series_data_quality</td>\n",
       "      <td id=\"T_8b2b8_row6_col1\" class=\"data row6 col1\" >TimeSeriesDataQuality</td>\n",
       "      <td id=\"T_8b2b8_row6_col2\" class=\"data row6 col2\" >Test plan for data quality on time series datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row7_col0\" class=\"data row7 col0\" >time_series_univariate</td>\n",
       "      <td id=\"T_8b2b8_row7_col1\" class=\"data row7 col1\" >TimeSeriesUnivariate</td>\n",
       "      <td id=\"T_8b2b8_row7_col2\" class=\"data row7 col2\" >Test plan to perform time series univariate analysis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row8_col0\" class=\"data row8 col0\" >time_series_multivariate</td>\n",
       "      <td id=\"T_8b2b8_row8_col1\" class=\"data row8 col1\" >TimeSeriesMultivariate</td>\n",
       "      <td id=\"T_8b2b8_row8_col2\" class=\"data row8 col2\" >Test plan to perform time series multivariate analysis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row9_col0\" class=\"data row9 col0\" >time_series_forecast</td>\n",
       "      <td id=\"T_8b2b8_row9_col1\" class=\"data row9 col1\" >TimeSeriesForecast</td>\n",
       "      <td id=\"T_8b2b8_row9_col2\" class=\"data row9 col2\" >Test plan to perform time series forecast tests.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row10_col0\" class=\"data row10 col0\" >time_series_sensitivity</td>\n",
       "      <td id=\"T_8b2b8_row10_col1\" class=\"data row10 col1\" >TimeSeriesSensitivity</td>\n",
       "      <td id=\"T_8b2b8_row10_col2\" class=\"data row10 col2\" >Test plan to perform time series forecast tests.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row11_col0\" class=\"data row11 col0\" >regression_model_description</td>\n",
       "      <td id=\"T_8b2b8_row11_col1\" class=\"data row11 col1\" >RegressionModelDescription</td>\n",
       "      <td id=\"T_8b2b8_row11_col2\" class=\"data row11 col2\" >Test plan for performance metric of regression model of statsmodels library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row12_col0\" class=\"data row12 col0\" >regression_models_evaluation</td>\n",
       "      <td id=\"T_8b2b8_row12_col1\" class=\"data row12 col1\" >RegressionModelsEvaluation</td>\n",
       "      <td id=\"T_8b2b8_row12_col2\" class=\"data row12 col2\" >Test plan for metrics comparison of regression model of statsmodels library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row13_col0\" class=\"data row13 col0\" >text_data_quality</td>\n",
       "      <td id=\"T_8b2b8_row13_col1\" class=\"data row13 col1\" >TextDataQuality</td>\n",
       "      <td id=\"T_8b2b8_row13_col2\" class=\"data row13 col2\" >Test plan for data quality on text data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8b2b8_row14_col0\" class=\"data row14 col0\" >summarization_metrics</td>\n",
       "      <td id=\"T_8b2b8_row14_col1\" class=\"data row14 col1\" >SummarizationMetrics</td>\n",
       "      <td id=\"T_8b2b8_row14_col2\" class=\"data row14 col2\" >Test plan for Summarization metrics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2fc195f40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.list_plans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_90b93 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_90b93_row0_col0, #T_90b93_row0_col1, #T_90b93_row0_col2, #T_90b93_row0_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_90b93\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_90b93_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_90b93_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_90b93_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_90b93_level0_col3\" class=\"col_heading level0 col3\" >Tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_90b93_row0_col0\" class=\"data row0 col0\" >summarization_metrics</td>\n",
       "      <td id=\"T_90b93_row0_col1\" class=\"data row0 col1\" >SummarizationMetrics</td>\n",
       "      <td id=\"T_90b93_row0_col2\" class=\"data row0 col2\" >Test plan for Summarization metrics</td>\n",
       "      <td id=\"T_90b93_row0_col3\" class=\"data row0 col3\" >RougeMetrics (Metric)<br>TokenDisparity (Metric)<br>BleuScore (Metric)<br>BertScore (Metric)<br>ContextualRecall (Metric)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x175d43460>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.test_plans.describe_plan(\"summarization_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9d5d53635d440e8bd6742c533d26f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Running test plan...'), IntProgress(value=0, max=10)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187a90c4a63b40d19d77bf078ea6906a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Results for <i>Summarization Metrics</i> Test Plan:</h2><hr>'), HTML(value='<diâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config={\n",
    "    \"rouge_metric\": {\n",
    "        \"rouge_metrics\": [\"rouge-1\",\"rouge-2\", \"rouge-l\"],\n",
    "    },\n",
    "}\n",
    "summarization_metrics = vm.run_test_plan(\"summarization_metrics\", \n",
    "                                             model=vm_model,\n",
    "                                             config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dev Framework 3.9.16",
   "language": "python",
   "name": "dev-framework-3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

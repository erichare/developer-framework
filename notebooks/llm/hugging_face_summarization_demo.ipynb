{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization of financial data using Hugging Face LLM models\n",
    "This notebook aims to provide an introduction to documenting an LLM model using the ValidMind Developer Framework. The use case presented is a summarization of financial data (https://huggingface.co/datasets/financial_phrasebank).\n",
    "\n",
    "- Initializing the ValidMind Developer Framework\n",
    "- Running a test various tests to quickly generate document about the data and model\n",
    "\n",
    "## Before you begin\n",
    "\n",
    "To use the ValidMind Developer Framework with a Jupyter notebook, you need to install and initialize the client library first, along with getting your Python environment ready.\n",
    "\n",
    "If you don't already have one, you should also [create a documentation project](https://docs.validmind.ai/guide/create-your-first-documentation-project.html) on the ValidMind platform. You will use this project to upload your documentation and test results.\n",
    "\n",
    "## Install the client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade validmind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "In a browser, go to the **Client Integration** page of your documentation project and click **Copy to clipboard** next to the code snippet. This code snippet gives you the API key, API secret, and project identifier to link your notebook to your documentation project.\n",
    "\n",
    "::: {.column-margin}\n",
    "::: {.callout-tip}\n",
    "This step requires a documentation project. [Learn how you can create one](https://docs.validmind.ai/guide/create-your-first-documentation-project.html).\n",
    ":::\n",
    ":::\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 17:28:33,136 - INFO(validmind.api_client): Connected to ValidMind. Project: [11] Credit Risk Scorecard - Initial Validation (cllnq0ckr000273y6ev40pmb5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/juanvalidmind/Library/Caches/pypoetry/virtualenvs/validmind-X_uvMH0R-py3.10/bin/python\n"
     ]
    }
   ],
   "source": [
    "## Replace the code below with the code snippet from your project ## \n",
    "\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"http://localhost:3000/api/v1/tracking\",\n",
    "  api_key = \"2494c3838f48efe590d531bfe225d90b\",\n",
    "  api_secret = \"4f692f8161f128414fef542cab2a4e74834c75d01b3a8e088a1834f2afcfe838\",\n",
    "  project = \"cllnq0ckr000273y6ev40pmb5\"\n",
    ")\n",
    "\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import torch\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def _format_cell_text(text, width=50):  \n",
    "    \"\"\"Private function to format a cell's text.\"\"\"\n",
    "    return '\\n'.join([textwrap.fill(line, width=width) for line in text.split('\\n')])\n",
    "\n",
    "def _format_dataframe_for_tabulate(df):\n",
    "    \"\"\"Private function to format the entire DataFrame for tabulation.\"\"\"\n",
    "    df_out = df.copy()\n",
    "    \n",
    "    # Format all string columns\n",
    "    for column in df_out.columns:\n",
    "        if df_out[column].dtype == object:  # Check if column is of type object (likely strings)\n",
    "            df_out[column] = df_out[column].apply(_format_cell_text)\n",
    "    return df_out\n",
    "\n",
    "def _dataframe_to_html_table(df):\n",
    "    \"\"\"Private function to convert a DataFrame to an HTML table.\"\"\"\n",
    "    headers = df.columns.tolist()\n",
    "    table_data = df.values.tolist()\n",
    "    return tabulate(table_data, headers=headers, tablefmt=\"html\")\n",
    "\n",
    "def display_formatted_dataframe(df, num_rows=None):\n",
    "    \"\"\"Primary function to format and display a DataFrame.\"\"\"\n",
    "    if num_rows is not None:\n",
    "        df = df.head(num_rows)\n",
    "    formatted_df = _format_dataframe_for_tabulate(df)\n",
    "    html_table = _dataframe_to_html_table(formatted_df)\n",
    "    display(HTML(html_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_summaries_to_df(df, summaries):\n",
    "    \"\"\"\n",
    "    Adds a new column 'summary_X' to the dataframe df that contains the given summaries, where X is an incremental number.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The original pandas DataFrame.\n",
    "    - summaries: List/array of summarized texts.\n",
    "\n",
    "    Returns:\n",
    "    - A new DataFrame with an additional summary column, with 'labels' being the first column followed by the original 'text'.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()  # Make an explicit copy of the DataFrame\n",
    "\n",
    "    # Check if the length of summaries matches the number of rows in the DataFrame\n",
    "    if len(summaries) != len(df):\n",
    "        raise ValueError(f\"The number of summaries ({len(summaries)}) does not match the number of rows in the DataFrame ({len(df)}).\")\n",
    "\n",
    "    # Determine the name for the new summary column\n",
    "    col_index = 1\n",
    "    col_name = 'summary_1'\n",
    "    while col_name in df.columns:\n",
    "        col_index += 1\n",
    "        col_name = f'summary_{col_index}'\n",
    "\n",
    "    # Add the summaries to the DataFrame\n",
    "    df[col_name] = summaries\n",
    "\n",
    "    # Rearrange the DataFrame columns to have 'topic' first, then the original 'input', followed by summary columns\n",
    "    summary_columns = [col for col in df.columns if col.startswith('summary')]\n",
    "    other_columns = [col for col in df.columns if col not in summary_columns + ['topic', 'input', 'reference_summary']]\n",
    "    \n",
    "    columns_order = ['topic', 'input', 'reference_summary'] + sorted(summary_columns) + other_columns\n",
    "    df = df[columns_order]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def calculate_rouge_scores(df, ref_column, gen_column, metric=\"rouge-2\"):\n",
    "    \"\"\"\n",
    "    Compute ROUGE scores for each row in the DataFrame.\n",
    "\n",
    "    :param df: DataFrame containing the summaries\n",
    "    :param ref_column: Column name for the reference summaries\n",
    "    :param gen_column: Column name for the generated summaries\n",
    "    :param metric: Type of ROUGE metric (\"rouge-1\", \"rouge-2\", \"rouge-l\", \"rouge-s\")\n",
    "    :return: DataFrame with ROUGE scores for each row\n",
    "    \"\"\"\n",
    "    if metric not in [\"rouge-1\", \"rouge-2\", \"rouge-l\", \"rouge-s\"]:\n",
    "        raise ValueError(\"Invalid metric. Choose from 'rouge-1', 'rouge-2', 'rouge-l', 'rouge-s'.\")\n",
    "    \n",
    "    rouge = Rouge(metrics=[metric])\n",
    "    score_list = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        scores = rouge.get_scores(row[gen_column], row[ref_column], avg=True)[metric]\n",
    "        score_list.append(scores)\n",
    "    \n",
    "    return pd.DataFrame(score_list)\n",
    "\n",
    "def visualize_rouge_scores(df_scores):\n",
    "    \"\"\"\n",
    "    Visualize ROUGE scores using Plotly line plots for each row.\n",
    "\n",
    "    :param df_scores: DataFrame of ROUGE scores.\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adding the line plots\n",
    "    fig.add_trace(go.Scatter(x=df_scores.index, y=df_scores['p'], mode='lines+markers', name='Precision'))\n",
    "    fig.add_trace(go.Scatter(x=df_scores.index, y=df_scores['r'], mode='lines+markers', name='Recall'))\n",
    "    fig.add_trace(go.Scatter(x=df_scores.index, y=df_scores['f'], mode='lines+markers', name='F1 Score'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"ROUGE Scores for Each Row\",\n",
    "        xaxis_title=\"Row Index\",\n",
    "        yaxis_title=\"Score\"\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POC Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "import plotly.express as px\n",
    "from itertools import combinations\n",
    "\n",
    "# First function\n",
    "def general_text_metrics(df, text_column):\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for text in df[text_column]:\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        words = nltk.word_tokenize(text)\n",
    "        paragraphs = text.split(\"\\n\\n\")\n",
    "\n",
    "        total_words = len(words)\n",
    "        total_sentences = len(sentences)\n",
    "        avg_sentence_length = round(sum(len(sentence.split()) for sentence in sentences) / total_sentences if total_sentences else 0, 1)\n",
    "        total_paragraphs = len(paragraphs)\n",
    "\n",
    "        results.append([total_words, total_sentences, avg_sentence_length, total_paragraphs])\n",
    "\n",
    "    return pd.DataFrame(results, columns=[\"Total Words\", \"Total Sentences\", \"Avg Sentence Length\", \"Total Paragraphs\"])\n",
    "\n",
    "# Second function\n",
    "def vocabulary_structure_metrics(df, text_column, unwanted_tokens, num_top_words, lang):\n",
    "    stop_words = set(word.lower() for word in stopwords.words(lang))\n",
    "    unwanted_tokens = set(token.lower() for token in unwanted_tokens)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for text in df[text_column]:\n",
    "        words = nltk.word_tokenize(text)\n",
    "\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words and word.lower() not in unwanted_tokens and word not in string.punctuation]\n",
    "\n",
    "        total_unique_words = len(set(filtered_words))\n",
    "        total_punctuations = sum(1 for word in words if word in string.punctuation)\n",
    "        lexical_diversity = round(total_unique_words / len(filtered_words) if filtered_words else 0, 1)\n",
    "\n",
    "        results.append([total_unique_words, total_punctuations, lexical_diversity])\n",
    "\n",
    "    return pd.DataFrame(results, columns=[\"Total Unique Words\", \"Total Punctuations\", \"Lexical Diversity\"])\n",
    "\n",
    "# Wrapper function that combines the outputs\n",
    "def text_metrics_summary_table(df, params):\n",
    "    text_column = params[\"text_column\"]\n",
    "    unwanted_tokens = params[\"unwanted_tokens\"]\n",
    "    num_top_words = params[\"num_top_words\"]\n",
    "    lang = params[\"lang\"]\n",
    "    \n",
    "    gen_metrics_df = general_text_metrics(df, text_column)\n",
    "    vocab_metrics_df = vocabulary_structure_metrics(df, text_column, unwanted_tokens, num_top_words, lang)\n",
    "    \n",
    "    combined_df = pd.concat([gen_metrics_df, vocab_metrics_df], axis=1)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Function to plot scatter plots for specified combinations using Plotly\n",
    "def plot_specified_scatter(df, combinations_to_plot):\n",
    "    for metric1, metric2 in combinations_to_plot:\n",
    "        fig = px.scatter(df, x=metric1, y=metric2, title=f\"Scatter Plot: {metric1} vs {metric2}\")\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "def text_metrics_summary_plot(df, text_column, num_docs_to_plot=None):\n",
    "    # Ensure the nltk punkt tokenizer is downloaded\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    \n",
    "    # Decide on the number of documents to plot\n",
    "    if not num_docs_to_plot or num_docs_to_plot > len(df):\n",
    "        num_docs_to_plot = len(df)\n",
    "\n",
    "    # Colors for each subplot\n",
    "    colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "    # Axis titles for clarity\n",
    "    x_titles = [\n",
    "        \"Word Frequencies\",\n",
    "        \"Sentence Position in Document\",\n",
    "        \"Sentence Lengths (Words)\",\n",
    "        \"Word Lengths (Characters)\"\n",
    "    ]\n",
    "    y_titles = [\n",
    "        \"Number of Words\",\n",
    "        \"Sentence Length (Words)\",\n",
    "        \"Number of Sentences\",\n",
    "        \"Number of Words\"\n",
    "    ]\n",
    "\n",
    "    # Iterate over each document in the DataFrame up to the user-specified limit\n",
    "    for index, (idx, row) in enumerate(df.head(num_docs_to_plot).iterrows()):\n",
    "        # Create subplots with a 2x2 grid for each metric\n",
    "        fig = sp.make_subplots(\n",
    "            rows=2, cols=2, \n",
    "            subplot_titles=[\n",
    "                \"Word Frequencies\", \n",
    "                \"Sentence Positions\",\n",
    "                \"Sentence Lengths\", \n",
    "                \"Word Lengths\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Tokenize document into sentences and words\n",
    "        sentences = nltk.sent_tokenize(row[text_column])\n",
    "        words = nltk.word_tokenize(row[text_column])\n",
    "        \n",
    "        # Metrics computation\n",
    "        word_freq = Counter(words)\n",
    "        freq_counts = Counter(word_freq.values())\n",
    "        word_frequencies = list(freq_counts.keys())\n",
    "        word_frequency_counts = list(freq_counts.values())\n",
    "        \n",
    "        sentence_positions = list(range(1, len(sentences) + 1))\n",
    "        sentence_lengths = [len(sentence.split()) for sentence in sentences]\n",
    "        word_lengths = [len(word) for word in words]\n",
    "        \n",
    "        # Adding data to subplots\n",
    "        fig.add_trace(go.Bar(x=word_frequencies, y=word_frequency_counts, marker_color=colors[0], showlegend=False), row=1, col=1)\n",
    "        fig.add_trace(go.Bar(x=sentence_positions, y=sentence_lengths, marker_color=colors[1], showlegend=False), row=1, col=2)\n",
    "        fig.add_trace(go.Histogram(x=sentence_lengths, nbinsx=50, opacity=0.75, marker_color=colors[2], showlegend=False), row=2, col=1)\n",
    "        fig.add_trace(go.Histogram(x=word_lengths, nbinsx=50, opacity=0.75, marker_color=colors[3], showlegend=False), row=2, col=2)\n",
    "\n",
    "        # Update x and y axis titles\n",
    "        for i, (x_title, y_title) in enumerate(zip(x_titles, y_titles)):\n",
    "            fig['layout'][f'xaxis{i+1}'].update(title=x_title, titlefont=dict(size=10))\n",
    "            fig['layout'][f'yaxis{i+1}'].update(title=y_title, titlefont=dict(size=10))\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f\"Summary Metrics for Document {index+1}\",\n",
    "            barmode='overlay',\n",
    "            height=800\n",
    "        )\n",
    "        \n",
    "        fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face summarisation wrappers\n",
    "\n",
    "The following code template showcases how to wrap a Hugging Face model for compatibility with the ValidMind Developer Framework. We will load an example model using the transformers API and then run some predictions on our test dataset.\n",
    "\n",
    "The ValidMind developer framework provides support for Hugging Face transformers out of the box, so in the following section we will show how to initialize multiple transformers models with the `init_model` function, removing the need for a custom wrapper. In cases where you need extra pre-processing or post-processing steps, you can use the following code template as a starting point to wrap your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "@dataclass\n",
    "\n",
    "class AbstractSummarization_HuggingFace:\n",
    "    \"\"\"\n",
    "    A VM Model instance wrapper only requires a predict \n",
    "    \"\"\"\n",
    "\n",
    "    predicted_prob_values = None\n",
    "\n",
    "    def __init__(self, pipeline_task, model_name=None, model=None, tokenizer=None):\n",
    "        self.model_name = model_name\n",
    "        self.pipeline_task = pipeline_task\n",
    "        self.model = pipeline(pipeline_task, model=model, tokenizer=tokenizer)\n",
    "\n",
    "    def predict(self, data):\n",
    "        data = [str(datapoint) for datapoint in data]\n",
    "        results = []\n",
    "        results = self.model(data)\n",
    "        results_df = pd.DataFrame(results)\n",
    "        self.predicted_prob_values = results_df.score.values\n",
    "        return results_df.label.values\n",
    "\n",
    "    def predict_proba(self):\n",
    "        if self.predicted_prob_values is None:\n",
    "            raise ValueError(\"First run predict method to retrieve predicted probabilities\")\n",
    "        return self.predicted_prob_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ExtractiveSummarization_BERT:\n",
    "    model: any\n",
    "    tokenizer: any\n",
    "\n",
    "    def _get_embedding(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding='max_length')\n",
    "        with torch.no_grad():\n",
    "            output = self.model(**inputs)\n",
    "        return output['last_hidden_state'].mean(dim=1).squeeze().detach().numpy()\n",
    "\n",
    "    def predict(self, texts, params):\n",
    "        summaries = []\n",
    "        \n",
    "        for text in texts:\n",
    "            sentences = text.split(\"\\n\\n\") # Breaking at double newline to get individual sentences.\n",
    "            \n",
    "            document_embedding = self._get_embedding(' '.join(sentences))\n",
    "            sentence_embeddings = [self._get_embedding(sentence) for sentence in sentences]\n",
    "            similarities = cosine_similarity(sentence_embeddings, [document_embedding])\n",
    "            sorted_indices = np.argsort(similarities, axis=0)[::-1].squeeze()\n",
    "\n",
    "            if params[\"method\"] == \"percentage\":\n",
    "                top_k = int(len(sentences) * params[\"value\"])\n",
    "                selected_sentences = [sentences[i] for i in sorted_indices[:top_k]]\n",
    "\n",
    "            elif params[\"method\"] == \"fixed_sentences\":\n",
    "                top_k = params[\"value\"]\n",
    "                selected_sentences = [sentences[i] for i in sorted_indices[:top_k]]\n",
    "\n",
    "            elif params[\"method\"] == \"word_count\":\n",
    "                selected_sentences = []\n",
    "                total_words = 0\n",
    "                for index in sorted_indices:\n",
    "                    current_sentence_words = len(sentences[index].split())\n",
    "                    # If adding the current sentence doesn't exceed the word limit, add it.\n",
    "                    if total_words + current_sentence_words <= params[\"value\"]:\n",
    "                        total_words += current_sentence_words\n",
    "                        selected_sentences.append(sentences[index])\n",
    "                    # Once the word limit is reached or exceeded, stop adding more sentences.\n",
    "                    if total_words >= params[\"value\"]:\n",
    "                        break\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"Invalid method specified.\")\n",
    "            \n",
    "            summaries.append(' '.join(selected_sentences))\n",
    "        \n",
    "        return summaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll load the financial dataset, which will be the foundation for our summarization analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/bbc_text_cls_reference.csv')\n",
    "df = df.head(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extractive Summarization: Hugging Face-BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-uncased\")  \n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "extractive_model = ExtractiveSummarization_BERT(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df.copy()\n",
    "data = df_raw.input.values.tolist()\n",
    "\n",
    "params = {\n",
    "    \"method\": \"word_count\",\n",
    "    \"value\": 200\n",
    "}\n",
    "\n",
    "list_summary_1 = extractive_model.predict(data, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>topic   </th><th>input  </th><th>reference_summary  </th><th>summary_1  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>business</td><td>Ad sales boost Time Warner profit\n",
       "\n",
       "Quarterly profits at US media giant TimeWarner\n",
       "jumped 76% to $1.13bn (£600m) for the three months\n",
       "to December, from $639m year-earlier.\n",
       "\n",
       "The firm, which is now one of the biggest\n",
       "investors in Google, benefited from sales of high-\n",
       "speed internet connections and higher advert\n",
       "sales. TimeWarner said fourth quarter sales rose\n",
       "2% to $11.1bn from $10.9bn. Its profits were\n",
       "buoyed by one-off gains which offset a profit dip\n",
       "at Warner Bros, and less users for AOL.\n",
       "\n",
       "Time Warner said on Friday that it now owns 8% of\n",
       "search-engine Google. But its own internet\n",
       "business, AOL, had has mixed fortunes. It lost\n",
       "464,000 subscribers in the fourth quarter profits\n",
       "were lower than in the preceding three quarters.\n",
       "However, the company said AOL&#x27;s underlying profit\n",
       "before exceptional items rose 8% on the back of\n",
       "stronger internet advertising revenues. It hopes\n",
       "to increase subscribers by offering the online\n",
       "service free to TimeWarner internet customers and\n",
       "will try to sign up AOL&#x27;s existing customers for\n",
       "high-speed broadband. TimeWarner also has to\n",
       "restate 2000 and 2003 results following a probe by\n",
       "the US Securities Exchange Commission (SEC), which\n",
       "is close to concluding.\n",
       "\n",
       "Time Warner&#x27;s fourth quarter profits were slightly\n",
       "better than analysts&#x27; expectations. But its film\n",
       "division saw profits slump 27% to $284m, helped by\n",
       "box-office flops Alexander and Catwoman, a sharp\n",
       "contrast to year-earlier, when the third and final\n",
       "film in the Lord of the Rings trilogy boosted\n",
       "results. For the full-year, TimeWarner posted a\n",
       "profit of $3.36bn, up 27% from its 2003\n",
       "performance, while revenues grew 6.4% to $42.09bn.\n",
       "&quot;Our financial performance was strong, meeting or\n",
       "exceeding all of our full-year objectives and\n",
       "greatly enhancing our flexibility,&quot; chairman and\n",
       "chief executive Richard Parsons said. For 2005,\n",
       "TimeWarner is projecting operating earnings growth\n",
       "of around 5%, and also expects higher revenue and\n",
       "wider profit margins.\n",
       "\n",
       "TimeWarner is to restate its accounts as part of\n",
       "efforts to resolve an inquiry into AOL by US\n",
       "market regulators. It has already offered to pay\n",
       "$300m to settle charges, in a deal that is under\n",
       "review by the SEC. The company said it was unable\n",
       "to estimate the amount it needed to set aside for\n",
       "legal reserves, which it previously set at $500m.\n",
       "It intends to adjust the way it accounts for a\n",
       "deal with German music publisher Bertelsmann&#x27;s\n",
       "purchase of a stake in AOL Europe, which it had\n",
       "reported as advertising revenue. It will now book\n",
       "the sale of its stake in AOL Europe as a loss on\n",
       "the value of that stake.        </td><td>The firm, which is now one of the biggest\n",
       "investors in Google, benefited from sales of high-\n",
       "speed internet connections and higher advert\n",
       "sales. TimeWarner said fourth quarter sales rose\n",
       "2% to $11.1bn from $10.9bn. Its profits were\n",
       "buoyed by one-off gains which offset a profit dip\n",
       "at Warner Bros, and less users for AOL. Quarterly\n",
       "profits at US media giant TimeWarner jumped 76% to\n",
       "$1.13bn (£600m) for the three months to December,\n",
       "from $639m year-earlier. Ad sales boost Time\n",
       "Warner profit                    </td><td>Time Warner&#x27;s fourth quarter profits were slightly\n",
       "better than analysts&#x27; expectations. But its film\n",
       "division saw profits slump 27% to $284m, helped by\n",
       "box-office flops Alexander and Catwoman, a sharp\n",
       "contrast to year-earlier, when the third and final\n",
       "film in the Lord of the Rings trilogy boosted\n",
       "results. For the full-year, TimeWarner posted a\n",
       "profit of $3.36bn, up 27% from its 2003\n",
       "performance, while revenues grew 6.4% to $42.09bn.\n",
       "&quot;Our financial performance was strong, meeting or\n",
       "exceeding all of our full-year objectives and\n",
       "greatly enhancing our flexibility,&quot; chairman and\n",
       "chief executive Richard Parsons said. For 2005,\n",
       "TimeWarner is projecting operating earnings growth\n",
       "of around 5%, and also expects higher revenue and\n",
       "wider profit margins. The firm, which is now one\n",
       "of the biggest investors in Google, benefited from\n",
       "sales of high-speed internet connections and\n",
       "higher advert sales. TimeWarner said fourth\n",
       "quarter sales rose 2% to $11.1bn from $10.9bn. Its\n",
       "profits were buoyed by one-off gains which offset\n",
       "a profit dip at Warner Bros, and less users for\n",
       "AOL. Quarterly profits at US media giant\n",
       "TimeWarner jumped 76% to $1.13bn (£600m) for the\n",
       "three months to December, from $639m year-earlier.\n",
       "Ad sales boost Time Warner profit            </td></tr>\n",
       "<tr><td>business</td><td>Dollar gains on Greenspan speech\n",
       "\n",
       "The dollar has hit its highest level against the\n",
       "euro in almost three months after the Federal\n",
       "Reserve head said the US trade deficit is set to\n",
       "stabilise.\n",
       "\n",
       "And Alan Greenspan highlighted the US government&#x27;s\n",
       "willingness to curb spending and rising household\n",
       "savings as factors which may help to reduce it. In\n",
       "late trading in New York, the dollar reached\n",
       "$1.2871 against the euro, from $1.2974 on\n",
       "Thursday. Market concerns about the deficit has\n",
       "hit the greenback in recent months. On Friday,\n",
       "Federal Reserve chairman Mr Greenspan&#x27;s speech in\n",
       "London ahead of the meeting of G7 finance\n",
       "ministers sent the dollar higher after it had\n",
       "earlier tumbled on the back of worse-than-expected\n",
       "US jobs data. &quot;I think the chairman&#x27;s taking a\n",
       "much more sanguine view on the current account\n",
       "deficit than he&#x27;s taken for some time,&quot; said\n",
       "Robert Sinche, head of currency strategy at Bank\n",
       "of America in New York. &quot;He&#x27;s taking a longer-term\n",
       "view, laying out a set of conditions under which\n",
       "the current account deficit can improve this year\n",
       "and next.&quot;\n",
       "\n",
       "Worries about the deficit concerns about China do,\n",
       "however, remain. China&#x27;s currency remains pegged\n",
       "to the dollar and the US currency&#x27;s sharp falls in\n",
       "recent months have therefore made Chinese export\n",
       "prices highly competitive. But calls for a shift\n",
       "in Beijing&#x27;s policy have fallen on deaf ears,\n",
       "despite recent comments in a major Chinese\n",
       "newspaper that the &quot;time is ripe&quot; for a loosening\n",
       "of the peg. The G7 meeting is thought unlikely to\n",
       "produce any meaningful movement in Chinese policy.\n",
       "In the meantime, the US Federal Reserve&#x27;s decision\n",
       "on 2 February to boost interest rates by a quarter\n",
       "of a point - the sixth such move in as many months\n",
       "- has opened up a differential with European\n",
       "rates. The half-point window, some believe, could\n",
       "be enough to keep US assets looking more\n",
       "attractive, and could help prop up the dollar. The\n",
       "recent falls have partly been the result of big\n",
       "budget deficits, as well as the US&#x27;s yawning\n",
       "current account gap, both of which need to be\n",
       "funded by the buying of US bonds and assets by\n",
       "foreign firms and governments. The White House\n",
       "will announce its budget on Monday, and many\n",
       "commentators believe the deficit will remain at\n",
       "close to half a trillion dollars.        </td><td>The dollar has hit its highest level against the\n",
       "euro in almost three months after the Federal\n",
       "Reserve head said the US trade deficit is set to\n",
       "stabilise. Dollar gains on Greenspan speech                    </td><td>And Alan Greenspan highlighted the US government&#x27;s\n",
       "willingness to curb spending and rising household\n",
       "savings as factors which may help to reduce it. In\n",
       "late trading in New York, the dollar reached\n",
       "$1.2871 against the euro, from $1.2974 on\n",
       "Thursday. Market concerns about the deficit has\n",
       "hit the greenback in recent months. On Friday,\n",
       "Federal Reserve chairman Mr Greenspan&#x27;s speech in\n",
       "London ahead of the meeting of G7 finance\n",
       "ministers sent the dollar higher after it had\n",
       "earlier tumbled on the back of worse-than-expected\n",
       "US jobs data. &quot;I think the chairman&#x27;s taking a\n",
       "much more sanguine view on the current account\n",
       "deficit than he&#x27;s taken for some time,&quot; said\n",
       "Robert Sinche, head of currency strategy at Bank\n",
       "of America in New York. &quot;He&#x27;s taking a longer-term\n",
       "view, laying out a set of conditions under which\n",
       "the current account deficit can improve this year\n",
       "and next.&quot; The dollar has hit its highest level\n",
       "against the euro in almost three months after the\n",
       "Federal Reserve head said the US trade deficit is\n",
       "set to stabilise. Dollar gains on Greenspan speech            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all_summaries = add_summaries_to_df(df_raw, list_summary_1)\n",
    "display_formatted_dataframe(df_all_summaries, num_rows=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Text Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Total Words:** Assess the length and complexity of the input text. Longer documents might require more sophisticated summarization techniques, while shorter ones may need more concise summaries.\n",
    "\n",
    "- **Total Sentences:** Understand the structural makeup of the content. Longer texts with numerous sentences might require the model to generate longer summaries to capture essential information.\n",
    "\n",
    "- **Avg Sentence Length:** Determine the average length of sentences in the text. This can help the model decide on the appropriate length for generated summaries, ensuring they are coherent and readable.\n",
    "\n",
    "- **Total Paragraphs:** Analyze how the content is organized into paragraphs. The model should be able to maintain the logical structure of the content when producing summaries.\n",
    "\n",
    "- **Total Unique Words:** Measure the diversity of vocabulary in the text. A higher count of unique words could indicate more complex content, which the model needs to capture accurately.\n",
    "\n",
    "- **Most Common Words:** Identify frequently occurring words that likely represent key themes. The model should pay special attention to including these words and concepts in its summaries.\n",
    "\n",
    "- **Total Punctuations:** Evaluate the usage of punctuation marks, which contribute to the tone and structure of the content. The model should be able to maintain appropriate punctuation in summaries.\n",
    "\n",
    "- **Lexical Diversity:** Calculate the richness of vocabulary in relation to the overall text length. A higher lexical diversity suggests a broader range of ideas and concepts that the model needs to capture in its summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"text_column\": \"input\",\n",
    "    \"unwanted_tokens\": {'s', 's\\'', 'mr', 'ms', 'mrs', 'dr', '\\'s', ' ', \"''\", 'dollar', 'us', '``'},\n",
    "    \"num_top_words\": 3,\n",
    "    \"lang\": \"english\"\n",
    "}\n",
    "\n",
    "summary_table = text_metrics_summary_table(df_raw, params)\n",
    "display(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the combinations you want to plot\n",
    "combinations_to_plot = [\n",
    "    (\"Total Words\", \"Total Sentences\"),\n",
    "    (\"Total Words\", \"Total Unique Words\"),\n",
    "    (\"Total Sentences\", \"Avg Sentence Length\"),\n",
    "    (\"Total Unique Words\", \"Lexical Diversity\")\n",
    "]\n",
    "\n",
    "plot_specified_scatter(summary_table, combinations_to_plot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Metrics Distributions\n",
    "\n",
    "- **Word Frequencies:** This metric provides a histogram of how often words appear with a given frequency. For example, if a lot of words appear only once in a document, it might be indicative of a text rich in unique words. On the other hand, a small set of words appearing very frequently might indicate repetitive content or a certain theme or pattern in the text.\n",
    "\n",
    "- **Sentence Positions vs. Sentence Lengths:** This bar chart showcases the length of each sentence (in terms of word count) in their order of appearance in the document. This can give insights into the flow of information in a text, highlighting any long, detailed sections or brief, potentially superficial areas.\n",
    "\n",
    "- **Sentence Lengths Distribution:** A histogram showing the frequency of sentence lengths across the document. Long sentences might contain a lot of information but could be harder for summarization models to digest and for readers to comprehend. Conversely, many short sentences might indicate fragmented information.\n",
    "\n",
    "- **Word Lengths Distribution:** A histogram of the lengths of words in the document. Extremely long words might be anomalies, technical terms, or potential errors in the corpus. Conversely, a majority of very short words might denote lack of depth or specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_metrics_summary_plot(df_raw, \"input\", 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROUGE Score (Recall-Oriented Understudy for Gisting Evaluation)**\n",
    "\n",
    "The ROUGE score is a widely adopted set of metrics used for evaluating automatic summarization and machine translation. It fundamentally measures the overlap between the n-grams in the generated summary and those in the reference summary.\n",
    "\n",
    "- **ROUGE-N**: This evaluates the overlap of n-grams between the produced summary and reference summary. It calculates precision (the proportion of n-grams in the generated summary that are also present in the reference summary), recall (the proportion of n-grams in the reference summary that are also present in the generated summary), and F1 score (the harmonic mean of precision and recall).\n",
    "\n",
    "- **ROUGE-L**: This metric is based on the Longest Common Subsequence (LCS) between the generated and reference summaries. LCS measures the longest sequence of tokens in the generated summary that matches the reference, without considering the order. It's beneficial because it can identify and reward longer coherent matching sequences.\n",
    "\n",
    "- **ROUGE-S**: This measures the skip-bigram overlap, considering the pair of words in order as \"bigrams\" while allowing arbitrary gaps or \"skips\". This can be valuable to capture sentence-level structure similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"rouge-2\"\n",
    "df_scores = calculate_rouge_scores(\n",
    "    df_all_summaries, \n",
    "    ref_column=\"reference_summary\", \n",
    "    gen_column=\"summary_1\", \n",
    "    metric=metric)\n",
    "visualize_rouge_scores(df_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Abstract Summarization: Hugging Face-T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-framework",
   "language": "python",
   "name": "dev-framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

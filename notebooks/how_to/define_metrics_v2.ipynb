{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "  api_host = \"https://api.dev.vm.validmind.ai/api/v1/tracking\",\n",
    "  api_key = \"...\",\n",
    "  api_secret = \"...\",\n",
    "  project = \"...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.datasets.classification import customer_churn as demo_dataset\n",
    "\n",
    "print(f\"Loaded demo dataset with: \\n\\n\\t• Target column: '{demo_dataset.target_column}' \\n\\t• Class labels: {demo_dataset.class_labels}\")\n",
    "\n",
    "raw_df = demo_dataset.load_data()\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = demo_dataset.preprocess(raw_df)\n",
    "\n",
    "x_train = train_df.drop(demo_dataset.target_column, axis=1)\n",
    "y_train = train_df[demo_dataset.target_column]\n",
    "x_val = validation_df.drop(demo_dataset.target_column, axis=1)\n",
    "y_val = validation_df[demo_dataset.target_column]\n",
    "\n",
    "model = xgb.XGBClassifier(early_stopping_rounds=10)\n",
    "model.set_params(\n",
    "    eval_metric=[\"error\", \"logloss\", \"auc\"],\n",
    ")\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    eval_set=[(x_val, y_val)],\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_df['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in test_df.columns if col != demo_dataset.target_column]\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictive probabilities for the test dataset\n",
    "# Here, we only use the probabilities for the positive class (class 1)\n",
    "predictive_probabilities = model.predict_proba(test_df.drop(demo_dataset.target_column, axis=1))[:, 1]\n",
    "\n",
    "# Add the predictive probabilities as a new column to the test dataframe\n",
    "test_df['PredictiveProbabilities'] = predictive_probabilities\n",
    "\n",
    "# Add the predictions from the predictive probabilities as a new column to the test dataframe\n",
    "test_df['Predictions'] = (predictive_probabilities > 0.5).astype(int)\n",
    "\n",
    "# Display the first few rows of the updated dataframe to verify\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    test_df, \n",
    "    target_column=demo_dataset.target_column,\n",
    "    feature_columns=feature_columns,\n",
    "    extra_columns={\"prediction_column\": \"Predictions\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_test_ds.prediction_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_test_ds.feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_test_ds.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_test_ds._df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_model = vm.init_model(\n",
    "    model,\n",
    "    input_id=\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "metric_id = \"validmind.metrics.sklearn.classification.F1\"\n",
    "\n",
    "inputs = {\n",
    "    \"model\": vm_model,\n",
    "    \"dataset\": vm_test_ds\n",
    "}\n",
    "\n",
    "params = {\"average\": \"macro\"}\n",
    "\n",
    "result = vm.run_metric(\n",
    "\n",
    "    metric_id=metric_id, \n",
    "    inputs=inputs,\n",
    "    params=params\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "metric_id = \"validmind.metrics.sklearn.classification.F1\"\n",
    "\n",
    "inputs = {\n",
    "    \"model\": None,\n",
    "    \"dataset\": vm_test_ds\n",
    "}\n",
    "\n",
    "params = {\"average\": \"macro\"}\n",
    "\n",
    "result = vm.run_metric(\n",
    "\n",
    "    metric_id=metric_id, \n",
    "    inputs=inputs,\n",
    "    params=params\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metric.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metric.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "metric_id = \"validmind.metrics.sklearn.classification.Precision\"\n",
    "\n",
    "inputs = {\"dataset\": vm_test_ds}\n",
    "\n",
    "result = vm.run_metric(\n",
    "\n",
    "    metric_id=metric_id, \n",
    "    inputs=inputs,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "metric_id = \"validmind.metrics.sklearn.classification.Precision\"\n",
    "\n",
    "inputs = {\"dataset\": vm_test_ds}\n",
    "\n",
    "result = vm.run_metric(\n",
    "\n",
    "    metric_id=metric_id, \n",
    "    inputs=inputs,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "metric_id = \"validmind.metrics.sklearn.classification.Recall\"\n",
    "\n",
    "inputs = {\"dataset\": vm_test_ds}\n",
    "\n",
    "result = vm.run_metric(\n",
    "\n",
    "    metric_id=metric_id, \n",
    "    inputs=inputs,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "metric_id = \"validmind.metrics.sklearn.classification.Accuracy\"\n",
    "\n",
    "inputs = {\"dataset\": vm_test_ds}\n",
    "\n",
    "result = vm.run_metric(\n",
    "\n",
    "    metric_id=metric_id, \n",
    "    inputs=inputs,\n",
    "    \n",
    ")\n",
    "result.metric.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "metric_id = \"validmind.metrics.sklearn.classification.Accuracy\"\n",
    "\n",
    "params = {\"normalize\": False}\n",
    "\n",
    "inputs = {\n",
    "    \"model\": vm_model,\n",
    "    \"dataset\": vm_test_ds\n",
    "}\n",
    "\n",
    "result = vm.run_metric(\n",
    "\n",
    "    metric_id=metric_id, \n",
    "    inputs=inputs,\n",
    "    params=params\n",
    "    \n",
    ")\n",
    "result.metric.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm\n",
    "\n",
    "metric_id = \"validmind.metrics.sklearn.classification.ROC_AUC\"\n",
    "\n",
    "params = {\n",
    "    \"average\": \"macro\",\n",
    "    \"multi_class\": \"raise\"\n",
    "}\n",
    "\n",
    "inputs = {\n",
    "    \"model\": None,\n",
    "    \"dataset\": vm_test_ds\n",
    "}\n",
    "\n",
    "result = vm.run_metric(\n",
    "\n",
    "    metric_id=metric_id, \n",
    "    inputs=inputs,\n",
    "    params=params\n",
    "    \n",
    ")\n",
    "result.metric.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validmind-py3.10",
   "language": "python",
   "name": "validmind-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_92f42 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_92f42_row0_col0, #T_92f42_row0_col1, #T_92f42_row0_col2, #T_92f42_row0_col3, #T_92f42_row1_col0, #T_92f42_row1_col1, #T_92f42_row1_col2, #T_92f42_row1_col3, #T_92f42_row2_col0, #T_92f42_row2_col1, #T_92f42_row2_col2, #T_92f42_row2_col3, #T_92f42_row3_col0, #T_92f42_row3_col1, #T_92f42_row3_col2, #T_92f42_row3_col3, #T_92f42_row4_col0, #T_92f42_row4_col1, #T_92f42_row4_col2, #T_92f42_row4_col3, #T_92f42_row5_col0, #T_92f42_row5_col1, #T_92f42_row5_col2, #T_92f42_row5_col3, #T_92f42_row6_col0, #T_92f42_row6_col1, #T_92f42_row6_col2, #T_92f42_row6_col3, #T_92f42_row7_col0, #T_92f42_row7_col1, #T_92f42_row7_col2, #T_92f42_row7_col3, #T_92f42_row8_col0, #T_92f42_row8_col1, #T_92f42_row8_col2, #T_92f42_row8_col3, #T_92f42_row9_col0, #T_92f42_row9_col1, #T_92f42_row9_col2, #T_92f42_row9_col3, #T_92f42_row10_col0, #T_92f42_row10_col1, #T_92f42_row10_col2, #T_92f42_row10_col3, #T_92f42_row11_col0, #T_92f42_row11_col1, #T_92f42_row11_col2, #T_92f42_row11_col3, #T_92f42_row12_col0, #T_92f42_row12_col1, #T_92f42_row12_col2, #T_92f42_row12_col3, #T_92f42_row13_col0, #T_92f42_row13_col1, #T_92f42_row13_col2, #T_92f42_row13_col3, #T_92f42_row14_col0, #T_92f42_row14_col1, #T_92f42_row14_col2, #T_92f42_row14_col3, #T_92f42_row15_col0, #T_92f42_row15_col1, #T_92f42_row15_col2, #T_92f42_row15_col3, #T_92f42_row16_col0, #T_92f42_row16_col1, #T_92f42_row16_col2, #T_92f42_row16_col3, #T_92f42_row17_col0, #T_92f42_row17_col1, #T_92f42_row17_col2, #T_92f42_row17_col3, #T_92f42_row18_col0, #T_92f42_row18_col1, #T_92f42_row18_col2, #T_92f42_row18_col3, #T_92f42_row19_col0, #T_92f42_row19_col1, #T_92f42_row19_col2, #T_92f42_row19_col3, #T_92f42_row20_col0, #T_92f42_row20_col1, #T_92f42_row20_col2, #T_92f42_row20_col3, #T_92f42_row21_col0, #T_92f42_row21_col1, #T_92f42_row21_col2, #T_92f42_row21_col3, #T_92f42_row22_col0, #T_92f42_row22_col1, #T_92f42_row22_col2, #T_92f42_row22_col3, #T_92f42_row23_col0, #T_92f42_row23_col1, #T_92f42_row23_col2, #T_92f42_row23_col3, #T_92f42_row24_col0, #T_92f42_row24_col1, #T_92f42_row24_col2, #T_92f42_row24_col3, #T_92f42_row25_col0, #T_92f42_row25_col1, #T_92f42_row25_col2, #T_92f42_row25_col3, #T_92f42_row26_col0, #T_92f42_row26_col1, #T_92f42_row26_col2, #T_92f42_row26_col3, #T_92f42_row27_col0, #T_92f42_row27_col1, #T_92f42_row27_col2, #T_92f42_row27_col3, #T_92f42_row28_col0, #T_92f42_row28_col1, #T_92f42_row28_col2, #T_92f42_row28_col3, #T_92f42_row29_col0, #T_92f42_row29_col1, #T_92f42_row29_col2, #T_92f42_row29_col3, #T_92f42_row30_col0, #T_92f42_row30_col1, #T_92f42_row30_col2, #T_92f42_row30_col3, #T_92f42_row31_col0, #T_92f42_row31_col1, #T_92f42_row31_col2, #T_92f42_row31_col3, #T_92f42_row32_col0, #T_92f42_row32_col1, #T_92f42_row32_col2, #T_92f42_row32_col3, #T_92f42_row33_col0, #T_92f42_row33_col1, #T_92f42_row33_col2, #T_92f42_row33_col3, #T_92f42_row34_col0, #T_92f42_row34_col1, #T_92f42_row34_col2, #T_92f42_row34_col3, #T_92f42_row35_col0, #T_92f42_row35_col1, #T_92f42_row35_col2, #T_92f42_row35_col3, #T_92f42_row36_col0, #T_92f42_row36_col1, #T_92f42_row36_col2, #T_92f42_row36_col3, #T_92f42_row37_col0, #T_92f42_row37_col1, #T_92f42_row37_col2, #T_92f42_row37_col3, #T_92f42_row38_col0, #T_92f42_row38_col1, #T_92f42_row38_col2, #T_92f42_row38_col3, #T_92f42_row39_col0, #T_92f42_row39_col1, #T_92f42_row39_col2, #T_92f42_row39_col3, #T_92f42_row40_col0, #T_92f42_row40_col1, #T_92f42_row40_col2, #T_92f42_row40_col3, #T_92f42_row41_col0, #T_92f42_row41_col1, #T_92f42_row41_col2, #T_92f42_row41_col3, #T_92f42_row42_col0, #T_92f42_row42_col1, #T_92f42_row42_col2, #T_92f42_row42_col3, #T_92f42_row43_col0, #T_92f42_row43_col1, #T_92f42_row43_col2, #T_92f42_row43_col3, #T_92f42_row44_col0, #T_92f42_row44_col1, #T_92f42_row44_col2, #T_92f42_row44_col3, #T_92f42_row45_col0, #T_92f42_row45_col1, #T_92f42_row45_col2, #T_92f42_row45_col3, #T_92f42_row46_col0, #T_92f42_row46_col1, #T_92f42_row46_col2, #T_92f42_row46_col3, #T_92f42_row47_col0, #T_92f42_row47_col1, #T_92f42_row47_col2, #T_92f42_row47_col3, #T_92f42_row48_col0, #T_92f42_row48_col1, #T_92f42_row48_col2, #T_92f42_row48_col3, #T_92f42_row49_col0, #T_92f42_row49_col1, #T_92f42_row49_col2, #T_92f42_row49_col3, #T_92f42_row50_col0, #T_92f42_row50_col1, #T_92f42_row50_col2, #T_92f42_row50_col3, #T_92f42_row51_col0, #T_92f42_row51_col1, #T_92f42_row51_col2, #T_92f42_row51_col3, #T_92f42_row52_col0, #T_92f42_row52_col1, #T_92f42_row52_col2, #T_92f42_row52_col3, #T_92f42_row53_col0, #T_92f42_row53_col1, #T_92f42_row53_col2, #T_92f42_row53_col3, #T_92f42_row54_col0, #T_92f42_row54_col1, #T_92f42_row54_col2, #T_92f42_row54_col3, #T_92f42_row55_col0, #T_92f42_row55_col1, #T_92f42_row55_col2, #T_92f42_row55_col3, #T_92f42_row56_col0, #T_92f42_row56_col1, #T_92f42_row56_col2, #T_92f42_row56_col3, #T_92f42_row57_col0, #T_92f42_row57_col1, #T_92f42_row57_col2, #T_92f42_row57_col3, #T_92f42_row58_col0, #T_92f42_row58_col1, #T_92f42_row58_col2, #T_92f42_row58_col3, #T_92f42_row59_col0, #T_92f42_row59_col1, #T_92f42_row59_col2, #T_92f42_row59_col3, #T_92f42_row60_col0, #T_92f42_row60_col1, #T_92f42_row60_col2, #T_92f42_row60_col3, #T_92f42_row61_col0, #T_92f42_row61_col1, #T_92f42_row61_col2, #T_92f42_row61_col3, #T_92f42_row62_col0, #T_92f42_row62_col1, #T_92f42_row62_col2, #T_92f42_row62_col3, #T_92f42_row63_col0, #T_92f42_row63_col1, #T_92f42_row63_col2, #T_92f42_row63_col3, #T_92f42_row64_col0, #T_92f42_row64_col1, #T_92f42_row64_col2, #T_92f42_row64_col3, #T_92f42_row65_col0, #T_92f42_row65_col1, #T_92f42_row65_col2, #T_92f42_row65_col3, #T_92f42_row66_col0, #T_92f42_row66_col1, #T_92f42_row66_col2, #T_92f42_row66_col3, #T_92f42_row67_col0, #T_92f42_row67_col1, #T_92f42_row67_col2, #T_92f42_row67_col3, #T_92f42_row68_col0, #T_92f42_row68_col1, #T_92f42_row68_col2, #T_92f42_row68_col3, #T_92f42_row69_col0, #T_92f42_row69_col1, #T_92f42_row69_col2, #T_92f42_row69_col3, #T_92f42_row70_col0, #T_92f42_row70_col1, #T_92f42_row70_col2, #T_92f42_row70_col3, #T_92f42_row71_col0, #T_92f42_row71_col1, #T_92f42_row71_col2, #T_92f42_row71_col3, #T_92f42_row72_col0, #T_92f42_row72_col1, #T_92f42_row72_col2, #T_92f42_row72_col3, #T_92f42_row73_col0, #T_92f42_row73_col1, #T_92f42_row73_col2, #T_92f42_row73_col3, #T_92f42_row74_col0, #T_92f42_row74_col1, #T_92f42_row74_col2, #T_92f42_row74_col3, #T_92f42_row75_col0, #T_92f42_row75_col1, #T_92f42_row75_col2, #T_92f42_row75_col3, #T_92f42_row76_col0, #T_92f42_row76_col1, #T_92f42_row76_col2, #T_92f42_row76_col3, #T_92f42_row77_col0, #T_92f42_row77_col1, #T_92f42_row77_col2, #T_92f42_row77_col3, #T_92f42_row78_col0, #T_92f42_row78_col1, #T_92f42_row78_col2, #T_92f42_row78_col3, #T_92f42_row79_col0, #T_92f42_row79_col1, #T_92f42_row79_col2, #T_92f42_row79_col3, #T_92f42_row80_col0, #T_92f42_row80_col1, #T_92f42_row80_col2, #T_92f42_row80_col3, #T_92f42_row81_col0, #T_92f42_row81_col1, #T_92f42_row81_col2, #T_92f42_row81_col3, #T_92f42_row82_col0, #T_92f42_row82_col1, #T_92f42_row82_col2, #T_92f42_row82_col3, #T_92f42_row83_col0, #T_92f42_row83_col1, #T_92f42_row83_col2, #T_92f42_row83_col3, #T_92f42_row84_col0, #T_92f42_row84_col1, #T_92f42_row84_col2, #T_92f42_row84_col3, #T_92f42_row85_col0, #T_92f42_row85_col1, #T_92f42_row85_col2, #T_92f42_row85_col3, #T_92f42_row86_col0, #T_92f42_row86_col1, #T_92f42_row86_col2, #T_92f42_row86_col3, #T_92f42_row87_col0, #T_92f42_row87_col1, #T_92f42_row87_col2, #T_92f42_row87_col3, #T_92f42_row88_col0, #T_92f42_row88_col1, #T_92f42_row88_col2, #T_92f42_row88_col3, #T_92f42_row89_col0, #T_92f42_row89_col1, #T_92f42_row89_col2, #T_92f42_row89_col3, #T_92f42_row90_col0, #T_92f42_row90_col1, #T_92f42_row90_col2, #T_92f42_row90_col3, #T_92f42_row91_col0, #T_92f42_row91_col1, #T_92f42_row91_col2, #T_92f42_row91_col3, #T_92f42_row92_col0, #T_92f42_row92_col1, #T_92f42_row92_col2, #T_92f42_row92_col3, #T_92f42_row93_col0, #T_92f42_row93_col1, #T_92f42_row93_col2, #T_92f42_row93_col3, #T_92f42_row94_col0, #T_92f42_row94_col1, #T_92f42_row94_col2, #T_92f42_row94_col3, #T_92f42_row95_col0, #T_92f42_row95_col1, #T_92f42_row95_col2, #T_92f42_row95_col3, #T_92f42_row96_col0, #T_92f42_row96_col1, #T_92f42_row96_col2, #T_92f42_row96_col3, #T_92f42_row97_col0, #T_92f42_row97_col1, #T_92f42_row97_col2, #T_92f42_row97_col3, #T_92f42_row98_col0, #T_92f42_row98_col1, #T_92f42_row98_col2, #T_92f42_row98_col3, #T_92f42_row99_col0, #T_92f42_row99_col1, #T_92f42_row99_col2, #T_92f42_row99_col3, #T_92f42_row100_col0, #T_92f42_row100_col1, #T_92f42_row100_col2, #T_92f42_row100_col3, #T_92f42_row101_col0, #T_92f42_row101_col1, #T_92f42_row101_col2, #T_92f42_row101_col3, #T_92f42_row102_col0, #T_92f42_row102_col1, #T_92f42_row102_col2, #T_92f42_row102_col3, #T_92f42_row103_col0, #T_92f42_row103_col1, #T_92f42_row103_col2, #T_92f42_row103_col3, #T_92f42_row104_col0, #T_92f42_row104_col1, #T_92f42_row104_col2, #T_92f42_row104_col3, #T_92f42_row105_col0, #T_92f42_row105_col1, #T_92f42_row105_col2, #T_92f42_row105_col3, #T_92f42_row106_col0, #T_92f42_row106_col1, #T_92f42_row106_col2, #T_92f42_row106_col3, #T_92f42_row107_col0, #T_92f42_row107_col1, #T_92f42_row107_col2, #T_92f42_row107_col3, #T_92f42_row108_col0, #T_92f42_row108_col1, #T_92f42_row108_col2, #T_92f42_row108_col3, #T_92f42_row109_col0, #T_92f42_row109_col1, #T_92f42_row109_col2, #T_92f42_row109_col3, #T_92f42_row110_col0, #T_92f42_row110_col1, #T_92f42_row110_col2, #T_92f42_row110_col3, #T_92f42_row111_col0, #T_92f42_row111_col1, #T_92f42_row111_col2, #T_92f42_row111_col3, #T_92f42_row112_col0, #T_92f42_row112_col1, #T_92f42_row112_col2, #T_92f42_row112_col3, #T_92f42_row113_col0, #T_92f42_row113_col1, #T_92f42_row113_col2, #T_92f42_row113_col3, #T_92f42_row114_col0, #T_92f42_row114_col1, #T_92f42_row114_col2, #T_92f42_row114_col3, #T_92f42_row115_col0, #T_92f42_row115_col1, #T_92f42_row115_col2, #T_92f42_row115_col3, #T_92f42_row116_col0, #T_92f42_row116_col1, #T_92f42_row116_col2, #T_92f42_row116_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_92f42\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_92f42_level0_col0\" class=\"col_heading level0 col0\" >Test Type</th>\n",
       "      <th id=\"T_92f42_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_92f42_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_92f42_level0_col3\" class=\"col_heading level0 col3\" >ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row0_col0\" class=\"data row0 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row0_col1\" class=\"data row0 col1\" >Bias</td>\n",
       "      <td id=\"T_92f42_row0_col2\" class=\"data row0 col2\" >**Purpose:** Bias Evaluation is aimed at assessing if and how the distribution and order of exemplars (examples) within a few-shot learning prompt affect the Language Learning Model's (LLM) output, potentially introducing biases. By examining these influences, we can optimize the model's performance and mitigate unintended biases in its responses.\n",
       "\n",
       "**Test Mechanism:**\n",
       "\n",
       "1. **Distribution of Exemplars:** Check how varying the number of positive vs. negative examples in a prompt impacts the LLM's classification of a neutral or ambiguous statement. 2. **Order of Exemplars:** Examine if the sequence in which positive and negative examples are presented can sway the LLM's response.\n",
       "\n",
       "For each test case, an LLM is used to grade the input prompt on a scale from 1 to 10, based on whether the examples in the prompt may lead to biased responses. A minimum threshold must be met in order for the test to pass. By default, this threshold is set to 7, but it can be adjusted as needed via the test parameters.</td>\n",
       "      <td id=\"T_92f42_row0_col3\" class=\"data row0 col3\" >validmind.prompt_validation.Bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row1_col0\" class=\"data row1 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row1_col1\" class=\"data row1 col1\" >Clarity</td>\n",
       "      <td id=\"T_92f42_row1_col2\" class=\"data row1 col2\" >**Purpose:** The Clarity Evaluation is designed to assess whether prompts provided to a Language Learning Model (LLM) are unmistakably clear in their instructions. With clear prompts, the LLM is better suited to more accurately and effectively interpret and respond to instructions in the prompt\n",
       "\n",
       "**Test Mechanism:** Using an LLM, prompts are scrutinized for clarity, considering aspects like detail inclusion, persona adoption, step-by-step instructions, use of examples, and desired output length. Each prompt is graded on a scale from 1 to 10 based on its clarity. Prompts scoring at or above a predetermined threshold (default is 7) are marked as clear. This threshold can be adjusted via the test parameters.\n",
       "\n",
       "**Why Clarity Matters:** Clear prompts minimize the room for misinterpretation, allowing the LLM to generate more relevant and accurate responses. Ambiguous or vague instructions might leave the model guessing, leading to suboptimal outputs.\n",
       "\n",
       "**Tactics for Ensuring Clarity that will be referenced during evaluation:** 1. **Detail Inclusion:** Provide essential details or context to prevent the LLM from making assumptions. 2. **Adopt a Persona:** Use system messages to specify the desired persona for the LLM's responses. 3. **Specify Steps:** For certain tasks, delineate the required steps explicitly, helping the model in sequential understanding. 4. **Provide Examples:** While general instructions are efficient, in some scenarios, \"few-shot\" prompting or style examples can guide the LLM more effectively. 5. **Determine Output Length:** Define the targeted length of the response, whether in terms of paragraphs, bullet points, or other units. While word counts aren't always precise, specifying formats like paragraphs can offer more predictable results.</td>\n",
       "      <td id=\"T_92f42_row1_col3\" class=\"data row1 col3\" >validmind.prompt_validation.Clarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row2_col0\" class=\"data row2 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row2_col1\" class=\"data row2 col1\" >Specificity</td>\n",
       "      <td id=\"T_92f42_row2_col2\" class=\"data row2 col2\" >**Purpose:** The Specificity Test aims to assess the clarity, precision, and effectiveness of prompts provided to a Language Learning Model (LLM). Ensuring specificity in the prompts given to an LLM can significantly influence the accuracy and relevance of its outputs. The goal of this test is to ascertain that the instructions in a prompt are unmistakably clear and relevant, eliminating ambiguity and steering the LLM toward desired outcomes.\n",
       "\n",
       "**Test Mechanism:** Utilizing an LLM, each prompt is graded on a specificity scale ranging from 1 to 10. The grade reflects how well the prompt adheres to principles of clarity, detail, and relevancy without being overly verbose. Prompts that achieve a grade equal to or exceeding a predefined threshold (default set to 7) are deemed to pass the evaluation, while those falling below are marked as failing. This threshold can be adjusted as needed.\n",
       "\n",
       "**Why Specificity Matters:** Prompts that are detailed and descriptive often yield better and more accurate results from an LLM. Rather than relying on specific keywords or tokens, it's crucial to have a well-structured and descriptive prompt. Including relevant examples within the prompt can be particularly effective, guiding the LLM to produce outputs in desired formats. However, it's essential to strike a balance. While prompts need to be detailed, they shouldn't be overloaded with unnecessary information. The emphasis should always be on relevancy and conciseness, considering there are limitations to how long a prompt can be.\n",
       "\n",
       "**Example:** Imagine wanting an LLM to extract specific details from a given text. A vague prompt might yield varied results. However, with a prompt like, \"Extract the names of all characters and the cities they visited from the text\", the LLM is guided more precisely towards the desired information extraction.</td>\n",
       "      <td id=\"T_92f42_row2_col3\" class=\"data row2 col3\" >validmind.prompt_validation.Specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row3_col0\" class=\"data row3 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row3_col1\" class=\"data row3 col1\" >Robustness</td>\n",
       "      <td id=\"T_92f42_row3_col2\" class=\"data row3 col2\" >**Purpose:** The Robustness Integrity Assessment evaluates the resilience and reliability of prompts provided to a Language Learning Model (LLM). The primary objective is to ensure that prompts consistently produce accurate and desired outputs, even in diverse or challenging scenarios.\n",
       "\n",
       "**Test Mechanism:** Prompts are subjected to various conditions, alterations, and contexts to check their stability in eliciting consistent responses from the LLM. Factors such as different phrasings, inclusion of potential distractors, and varied input complexities are introduced to test the robustness of the prompt. By default, the test generates 10 inputs for the prompt but this can be adjusted via the test parameters.\n",
       "\n",
       "**Why Robustness Matters:** A robust prompt ensures consistent performance and reduces the likelihood of unexpected or off-tangent outputs. This consistency is vital for applications where predictability and reliability of the LLM's response are paramount.</td>\n",
       "      <td id=\"T_92f42_row3_col3\" class=\"data row3 col3\" >validmind.prompt_validation.Robustness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row4_col0\" class=\"data row4 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row4_col1\" class=\"data row4 col1\" >Negative Instruction</td>\n",
       "      <td id=\"T_92f42_row4_col2\" class=\"data row4 col2\" >**Purpose:** The Positive Instructional Assessment evaluates prompts provided to a Language Learning Model (LLM) to ensure they are framed using affirmative and proactive language. By focusing on what should be done rather than what should be avoided, prompts can guide the LLM more effectively towards generating appropriate and desired outputs.\n",
       "\n",
       "**Test Mechanism:** Employing an LLM as an evaluator, each prompt is meticulously analyzed and graded on use of positive instructions on a scale from 1 to 10. The grade indicates how well the prompt employs affirmative language while avoiding negative or prohibitive instructions. Prompts that achieve a grade equal to or exceeding a predetermined threshold (default set to 7) are recognized as adhering to positive instruction best practices. This threshold can be adjusted via the test parameters.\n",
       "\n",
       "**Why Positive Instructions Matter:** Prompts that are phrased in the affirmative, emphasizing what to do, tend to direct the LLM more clearly than those that focus on what not to do. Negative instructions can lead to ambiguities and undesired model responses. By emphasizing clarity and proactive guidance, we optimize the chances of obtaining relevant and targeted responses from the LLM.\n",
       "\n",
       "**Example:** Consider a scenario involving a chatbot designed to recommend movies. An instruction framed as, \"Don't recommend movies that are horror or thriller\" might cause the LLM to fixate on the genres mentioned, inadvertently producing undesired results. On the other hand, a positively-framed prompt like, \"Recommend family-friendly movies or romantic comedies\" provides clear guidance on the desired output.</td>\n",
       "      <td id=\"T_92f42_row4_col3\" class=\"data row4 col3\" >validmind.prompt_validation.NegativeInstruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row5_col0\" class=\"data row5 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row5_col1\" class=\"data row5 col1\" >Conciseness</td>\n",
       "      <td id=\"T_92f42_row5_col2\" class=\"data row5 col2\" >**Purpose:** The Conciseness Assessment is designed to evaluate the brevity and succinctness of prompts provided to a Language Learning Model (LLM). A concise prompt strikes a balance between offering clear instructions and eliminating redundant or unnecessary information, ensuring that the LLM receives relevant input without being overwhelmed.\n",
       "\n",
       "**Test Mechanism:** Using an LLM, this test puts input prompts through a conciseness analysis where it's graded on a scale from 1 to 10. The grade reflects how well the prompt maintains clarity while avoiding verbosity. Prompts that achieve a grade equal to or surpassing a predefined threshold (default set to 7) are considered successful in being concise. This threshold can be adjusted based on specific requirements.\n",
       "\n",
       "**Why Conciseness Matters:** While detailed prompts can guide an LLM towards accurate results, excessive details can clutter the instruction and potentially lead to undesired outputs. Concise prompts are straightforward, reducing ambiguity and focusing the LLM's attention on the primary task. This is especially important considering there are limitations to the length of prompts that can be fed to an LLM.\n",
       "\n",
       "**Example:** For an LLM tasked with summarizing a document, a verbose prompt might introduce unnecessary constraints or biases. A concise, effective prompt like, \"Provide a brief summary highlighting the main points of the document\" ensures that the LLM captures the essence of the content without being sidetracked.</td>\n",
       "      <td id=\"T_92f42_row5_col3\" class=\"data row5 col3\" >validmind.prompt_validation.Conciseness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row6_col0\" class=\"data row6 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row6_col1\" class=\"data row6 col1\" >Delimitation</td>\n",
       "      <td id=\"T_92f42_row6_col2\" class=\"data row6 col2\" >**Purpose:** The Delimitation Test ensures that prompts provided to the Language Learning Model (LLM) use delimiters correctly to distinctly mark sections of the input. Properly delimited prompts simplify the LLM's interpretation process, ensuring accurate and precise responses.\n",
       "\n",
       "**Test Mechanism:** Using an LLM, prompts are checked for their appropriate use of delimiters such as triple quotation marks, XML tags, and section titles. Each prompt receives a score from 1 to 10 based on its delimitation integrity. Prompts scoring at or above a set threshold (default is 7) pass the check. This threshold can be modified as needed.\n",
       "\n",
       "**Why Proper Delimitation Matters:** Delimiters play a crucial role in segmenting and organizing prompts, especially when diverse data or multiple tasks are involved. They help in clearly distinguishing between different parts of the input, reducing ambiguity for the LLM. As task complexity increases, the correct use of delimiters becomes even more critical to ensure the LLM understands the prompt's intent.\n",
       "\n",
       "**Example:** When given a prompt like:\n",
       "\n",
       "```USER: Summarize the text delimited by triple quotes. '''insert text here'''```\n",
       "\n",
       "or:\n",
       "\n",
       "```USER: <article> insert first article here </article> <article> insert second article here </article>```\n",
       "\n",
       "The LLM can more accurately discern sections of the text to be treated differently, thanks to the clear delimitation.</td>\n",
       "      <td id=\"T_92f42_row6_col3\" class=\"data row6 col3\" >validmind.prompt_validation.Delimitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row7_col0\" class=\"data row7 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row7_col1\" class=\"data row7 col1\" >Model Metadata</td>\n",
       "      <td id=\"T_92f42_row7_col2\" class=\"data row7 col2\" >This section describes attributes of the selected model such as its modeling technique, training parameters, and task type. This helps understand the model's capabilities and limitations in the context of a modeling framework.</td>\n",
       "      <td id=\"T_92f42_row7_col3\" class=\"data row7 col3\" >validmind.model_validation.ModelMetadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row8_col0\" class=\"data row8 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row8_col1\" class=\"data row8 col1\" >Classifier Out Of Sample Performance</td>\n",
       "      <td id=\"T_92f42_row8_col2\" class=\"data row8 col2\" >This section shows the performance of the model on the test data. Popular metrics such as the accuracy, precision, recall, F1 score, etc. are used to evaluate the model.</td>\n",
       "      <td id=\"T_92f42_row8_col3\" class=\"data row8 col3\" >validmind.model_validation.sklearn.ClassifierOutOfSamplePerformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row9_col0\" class=\"data row9 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row9_col1\" class=\"data row9 col1\" >Robustness Diagnosis</td>\n",
       "      <td id=\"T_92f42_row9_col2\" class=\"data row9 col2\" >The robustness of a machine learning model refers to its ability to maintain performance in the face of perturbations or changes to the input data. One way to test the robustness of a model is by perturbing its input features and observing how the model's performance changes.\n",
       "\n",
       "To perturb the input features, one can add random noise or modify the values of the features within a certain range. By perturbing the input features, one can simulate different scenarios in which the input data may be corrupted or incomplete, and test whether the model is able to handle such scenarios.\n",
       "\n",
       "The performance of the model can be measured in terms of its accuracy, precision, recall, or any other relevant metric, both before and after perturbing the input features. A model that is robust to perturbations should maintain a high level of performance even after the input features have been perturbed.</td>\n",
       "      <td id=\"T_92f42_row9_col3\" class=\"data row9 col3\" >validmind.model_validation.sklearn.RobustnessDiagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row10_col0\" class=\"data row10 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row10_col1\" class=\"data row10 col1\" >SHAP Global Importance</td>\n",
       "      <td id=\"T_92f42_row10_col2\" class=\"data row10 col2\" >The Mean Importance plot below shows the significance of each feature based on its absolute Shapley values. As we are measuring global importance, the process involves computing the average of these absolute Shapley values for each feature throughout the data.\n",
       "\n",
       "The Summary Plot displayed further combines the importance of each feature with their respective effects. Every dot in this plot represents a Shapley value for a certain feature in a particular instance. The y-axis positioning is determined by the feature, while the x-axis positioning is decided by the Shapley value. The color gradation represents the feature's value, transitioning from low to high. Points that overlap are scattered slightly in the y-axis direction, giving us an idea of the Shapley values distribution for each feature. The features are then arranged based on their importance levels.</td>\n",
       "      <td id=\"T_92f42_row10_col3\" class=\"data row10 col3\" >validmind.model_validation.sklearn.SHAPGlobalImportance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row11_col0\" class=\"data row11 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row11_col1\" class=\"data row11 col1\" >Confusion Matrix</td>\n",
       "      <td id=\"T_92f42_row11_col2\" class=\"data row11 col2\" >A confusion matrix is a table that is used to describe the performance of a classification model. For metrics such as **True Positives (TP)** and **True Negatives (TN)**, the higher their values the better as the model is able to distinguish the correct class from the incorrect class more effectively. For **False Positives (FP)** and **False Negatives (FN)**, the lower their values the better.</td>\n",
       "      <td id=\"T_92f42_row11_col3\" class=\"data row11 col3\" >validmind.model_validation.sklearn.ConfusionMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row12_col0\" class=\"data row12 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row12_col1\" class=\"data row12 col1\" >Classifier In Sample Performance</td>\n",
       "      <td id=\"T_92f42_row12_col2\" class=\"data row12 col2\" >This section shows the performance of the model on the training data. Popular metrics such as the accuracy, precision, recall, F1 score, etc. are used to evaluate the model.</td>\n",
       "      <td id=\"T_92f42_row12_col3\" class=\"data row12 col3\" >validmind.model_validation.sklearn.ClassifierInSamplePerformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row13_col0\" class=\"data row13 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row13_col1\" class=\"data row13 col1\" >Overfit Diagnosis</td>\n",
       "      <td id=\"T_92f42_row13_col2\" class=\"data row13 col2\" >Test that identify overfitting regions based on the train-test performance gap, one can divide the feature space into regions and analyze the train-test performance gap for each region. Regions with a large train-test performance gap can be considered as overfitting regions, indicating that the model is overfitting in those regions.\n",
       "\n",
       "Once overfitting regions have been identified, one can use various techniques to address the overfitting. For example, one could use regularization techniques such as L1 or L2 regularization, dropout, or early stopping to prevent the model from overfitting. Alternatively, one could use data augmentation techniques to increase the size of the training data and reduce overfitting.\n",
       "\n",
       "Overall, analyzing the train-test performance gap can provide valuable insights into the performance of a machine learning model and help identify overfitting regions that need to be addressed to improve the model's generalization performance.</td>\n",
       "      <td id=\"T_92f42_row13_col3\" class=\"data row13 col3\" >validmind.model_validation.sklearn.OverfitDiagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row14_col0\" class=\"data row14 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row14_col1\" class=\"data row14 col1\" >Permutation Feature Importance</td>\n",
       "      <td id=\"T_92f42_row14_col2\" class=\"data row14 col2\" >The Feature Importance plot below calculates a score representing the importance of each feature in the model. A higher score indicates that the specific input feature will have a larger effect on the predictive power of the model.\n",
       "\n",
       "The importance score is calculated using Permutation Feature Importance. Permutation feature importance measures the decrease of model performance after the feature's values have been permuted, which breaks the relationship between the feature and the true outcome. A feature is \"important\" if shuffling its values increases the model error, because in this case the model relied on the feature for the prediction. A feature is \"unimportant\" if shuffling its values leaves the model error unchanged, because in this case the model ignored the feature for the prediction.</td>\n",
       "      <td id=\"T_92f42_row14_col3\" class=\"data row14 col3\" >validmind.model_validation.sklearn.PermutationFeatureImportance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row15_col0\" class=\"data row15 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row15_col1\" class=\"data row15 col1\" >Minimum ROCAUC Score</td>\n",
       "      <td id=\"T_92f42_row15_col2\" class=\"data row15 col2\" >Test that the model's ROC AUC score on the validation dataset meets or exceeds a predefined threshold.</td>\n",
       "      <td id=\"T_92f42_row15_col3\" class=\"data row15 col3\" >validmind.model_validation.sklearn.MinimumROCAUCScore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row16_col0\" class=\"data row16 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row16_col1\" class=\"data row16 col1\" >Precision Recall Curve</td>\n",
       "      <td id=\"T_92f42_row16_col2\" class=\"data row16 col2\" >The precision-recall curve shows the trade-off between precision and recall for different thresholds. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</td>\n",
       "      <td id=\"T_92f42_row16_col3\" class=\"data row16 col3\" >validmind.model_validation.sklearn.PrecisionRecallCurve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row17_col0\" class=\"data row17 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row17_col1\" class=\"data row17 col1\" >Classifier Performance</td>\n",
       "      <td id=\"T_92f42_row17_col2\" class=\"data row17 col2\" >Test that outputs the performance of the model on the training or test data.</td>\n",
       "      <td id=\"T_92f42_row17_col3\" class=\"data row17 col3\" >validmind.model_validation.sklearn.ClassifierPerformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row18_col0\" class=\"data row18 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row18_col1\" class=\"data row18 col1\" >Minimum F1 Score</td>\n",
       "      <td id=\"T_92f42_row18_col2\" class=\"data row18 col2\" >Test that the model's F1 score on the validation dataset meets or exceeds a predefined threshold.</td>\n",
       "      <td id=\"T_92f42_row18_col3\" class=\"data row18 col3\" >validmind.model_validation.sklearn.MinimumF1Score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row19_col0\" class=\"data row19 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row19_col1\" class=\"data row19 col1\" >ROC Curve</td>\n",
       "      <td id=\"T_92f42_row19_col2\" class=\"data row19 col2\" >The ROC curve shows the trade-off between the true positive rate (TPR) and false positive rate (FPR) for different thresholds. The area under the curve (AUC) is a measure of how well a model can distinguish between two groups (e.g. default/non-default). The higher the AUC, the better the model is at distinguishing between positive and negative classes.</td>\n",
       "      <td id=\"T_92f42_row19_col3\" class=\"data row19 col3\" >validmind.model_validation.sklearn.ROCCurve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row20_col0\" class=\"data row20 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row20_col1\" class=\"data row20 col1\" >Training Test Degradation</td>\n",
       "      <td id=\"T_92f42_row20_col2\" class=\"data row20 col2\" >Test that the degradation in performance between the training and test datasets does not exceed a predefined threshold.</td>\n",
       "      <td id=\"T_92f42_row20_col3\" class=\"data row20 col3\" >validmind.model_validation.sklearn.TrainingTestDegradation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row21_col0\" class=\"data row21 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row21_col1\" class=\"data row21 col1\" >Models Performance Comparison</td>\n",
       "      <td id=\"T_92f42_row21_col2\" class=\"data row21 col2\" >This section shows the models performance comparison on the training data. Popular metrics such as the accuracy, precision, recall, F1 score, etc. are used to evaluate the models.</td>\n",
       "      <td id=\"T_92f42_row21_col3\" class=\"data row21 col3\" >validmind.model_validation.sklearn.ModelsPerformanceComparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row22_col0\" class=\"data row22 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row22_col1\" class=\"data row22 col1\" >Weakspots Diagnosis</td>\n",
       "      <td id=\"T_92f42_row22_col2\" class=\"data row22 col2\" >A weak spots test is a type of testing that is performed on a machine learning model to identify areas where the model may not perform well or may be vulnerable to errors. The purpose of this testing is to identify the limitations and weaknesses of the model so that appropriate measures can be taken to improve its performance. The weak spots test typically involves subjecting the model to different types of data that are different from the data used to train the model. For example, the test data may contain outliers, missing data, or noise that was not present in the training data. The model is then evaluated on this test data using appropriate metrics such as accuracy, precision, recall, F1 score, etc.</td>\n",
       "      <td id=\"T_92f42_row22_col3\" class=\"data row22 col3\" >validmind.model_validation.sklearn.WeakspotsDiagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row23_col0\" class=\"data row23 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row23_col1\" class=\"data row23 col1\" >Population Stability Index</td>\n",
       "      <td id=\"T_92f42_row23_col2\" class=\"data row23 col2\" >PSI is a widely-used metric to assess the stability of a predictive model's score distribution when comparing two separate samples (usually a development and a validation dataset or two separate time periods). It helps determine if a model's performance has changed significantly over time or if there is a major shift in the population characteristics.\n",
       "\n",
       "In this section, we compare the PSI between the training and test datasets.</td>\n",
       "      <td id=\"T_92f42_row23_col3\" class=\"data row23 col3\" >validmind.model_validation.sklearn.PopulationStabilityIndex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row24_col0\" class=\"data row24 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row24_col1\" class=\"data row24 col1\" >Minimum Accuracy</td>\n",
       "      <td id=\"T_92f42_row24_col2\" class=\"data row24 col2\" >Test that the model's prediction accuracy on a dataset meets or exceeds a predefined threshold.</td>\n",
       "      <td id=\"T_92f42_row24_col3\" class=\"data row24 col3\" >validmind.model_validation.sklearn.MinimumAccuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row25_col0\" class=\"data row25 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row25_col1\" class=\"data row25 col1\" >Regression Models Coeffs</td>\n",
       "      <td id=\"T_92f42_row25_col2\" class=\"data row25 col2\" >This section shows the coefficients of different regression models that were trained on the same dataset. This can be useful for comparing how different models weigh the importance of various features in the dataset.</td>\n",
       "      <td id=\"T_92f42_row25_col3\" class=\"data row25 col3\" >validmind.model_validation.statsmodels.RegressionModelsCoeffs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row26_col0\" class=\"data row26 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row26_col1\" class=\"data row26 col1\" >Box Pierce</td>\n",
       "      <td id=\"T_92f42_row26_col2\" class=\"data row26 col2\" >The Box-Pierce test is a statistical test used to determine whether a given set of data has autocorrelations that are different from zero.</td>\n",
       "      <td id=\"T_92f42_row26_col3\" class=\"data row26 col3\" >validmind.model_validation.statsmodels.BoxPierce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row27_col0\" class=\"data row27 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row27_col1\" class=\"data row27 col1\" >Regression Coeffs Plot</td>\n",
       "      <td id=\"T_92f42_row27_col2\" class=\"data row27 col2\" >Regression Coefficients with Confidence Intervals Plot\n",
       "\n",
       "This class is used to generate a visualization of the coefficients from a regression model, as well as their corresponding confidence intervals. It serves as a useful diagnostic tool for statistical analysis and model interpretation. The visualization displays each of the predictor variables on the x-axis, with their associated regression coefficients on the y-axis. Error bars are used to indicate the range of the confidence intervals, providing an understanding of the variability and uncertainty associated with the model's estimates.</td>\n",
       "      <td id=\"T_92f42_row27_col3\" class=\"data row27 col3\" >validmind.model_validation.statsmodels.RegressionCoeffsPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row28_col0\" class=\"data row28 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row28_col1\" class=\"data row28 col1\" >Regression Model Sensitivity Plot</td>\n",
       "      <td id=\"T_92f42_row28_col2\" class=\"data row28 col2\" >The sensitivity analysis metric applies various shocks or adjustments to one variable at a time while keeping all other variables constant. This allows for the examination of how changes in a specific variable affect the overall outcome or response of the system being analyzed.</td>\n",
       "      <td id=\"T_92f42_row28_col3\" class=\"data row28 col3\" >validmind.model_validation.statsmodels.RegressionModelSensitivityPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row29_col0\" class=\"data row29 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row29_col1\" class=\"data row29 col1\" >Regression Models Performance</td>\n",
       "      <td id=\"T_92f42_row29_col2\" class=\"data row29 col2\" >This section shows the in-sample and out-of-sample comparison of regression models. In-sample comparison involves comparing the performance of different regression models on the same dataset that was used to train the models. Out-of-sample comparison evaluates the performance of the models on unseen data. This is typically done by calculating goodness-of-fit statistics such as R-squared and mean squared error (MSE) for each model, and then comparing these statistics to determine which model has the best fit to the data.</td>\n",
       "      <td id=\"T_92f42_row29_col3\" class=\"data row29 col3\" >validmind.model_validation.statsmodels.RegressionModelsPerformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row30_col0\" class=\"data row30 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row30_col1\" class=\"data row30 col1\" >Zivot Andrews Arch</td>\n",
       "      <td id=\"T_92f42_row30_col2\" class=\"data row30 col2\" >Zivot-Andrews unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_92f42_row30_col3\" class=\"data row30 col3\" >validmind.model_validation.statsmodels.ZivotAndrewsArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row31_col0\" class=\"data row31 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row31_col1\" class=\"data row31 col1\" >Regression Model Outsample Comparison</td>\n",
       "      <td id=\"T_92f42_row31_col2\" class=\"data row31 col2\" >This section shows Out-of-sample comparison of regression models involves evaluating the performance of different regression models on a separate test dataset that was not used to train the models. This is typically done by calculating a goodness-of-fit statistic such as the R-squared or mean squared error (MSE) for each model, and then comparing these statistics to determine which model has the best fit to the test data.</td>\n",
       "      <td id=\"T_92f42_row31_col3\" class=\"data row31 col3\" >validmind.model_validation.statsmodels.RegressionModelOutsampleComparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row32_col0\" class=\"data row32 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row32_col1\" class=\"data row32 col1\" >Regression Model Forecast Plot Levels</td>\n",
       "      <td id=\"T_92f42_row32_col2\" class=\"data row32 col2\" >This section shows plots of training and test datasets vs forecast training and test.</td>\n",
       "      <td id=\"T_92f42_row32_col3\" class=\"data row32 col3\" >validmind.model_validation.statsmodels.RegressionModelForecastPlotLevels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row33_col0\" class=\"data row33 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row33_col1\" class=\"data row33 col1\" >Log Regression Confusion Matrix</td>\n",
       "      <td id=\"T_92f42_row33_col2\" class=\"data row33 col2\" >A confusion matrix is a table that is used to describe the performance of a classification model. For metrics such as **True Positives (TP)** and **True Negatives (TN)**, the higher their values the better as the model is able to distinguish the correct class from the incorrect class more effectively. For **False Positives (FP)** and **False Negatives (FN)**, the lower their values the better. In logistic regression models, predictions are often generated by thresholding probabilities, typically at a value like 0.5, to determine class assignments. On the other hand, some other classification models might provide direct class predictions without the need for thresholding.</td>\n",
       "      <td id=\"T_92f42_row33_col3\" class=\"data row33 col3\" >validmind.model_validation.statsmodels.LogRegressionConfusionMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row34_col0\" class=\"data row34 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row34_col1\" class=\"data row34 col1\" >PD Rating Class Plot</td>\n",
       "      <td id=\"T_92f42_row34_col2\" class=\"data row34 col2\" >Probability of Default (PD) Rating Class Plot</td>\n",
       "      <td id=\"T_92f42_row34_col3\" class=\"data row34 col3\" >validmind.model_validation.statsmodels.PDRatingClassPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row35_col0\" class=\"data row35 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row35_col1\" class=\"data row35 col1\" >Scorecard Histogram</td>\n",
       "      <td id=\"T_92f42_row35_col2\" class=\"data row35 col2\" >This metric calculates the credit score for each instance in the training and test datasets, and creates histograms to visualize the distributions of scores for the positive and negative classes.</td>\n",
       "      <td id=\"T_92f42_row35_col3\" class=\"data row35 col3\" >validmind.model_validation.statsmodels.ScorecardHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row36_col0\" class=\"data row36 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row36_col1\" class=\"data row36 col1\" >Feature Importance And Significance</td>\n",
       "      <td id=\"T_92f42_row36_col2\" class=\"data row36 col2\" >This metric class computes and visualizes the feature importance and statistical significance within a model's context. It compares the p-values from a regression model with the feature importances from a decision tree model. The significance filter can be turned on or off, allowing for flexibility in feature selection. The p-values and feature importances are normalized for comparison and visualization.</td>\n",
       "      <td id=\"T_92f42_row36_col3\" class=\"data row36 col3\" >validmind.model_validation.statsmodels.FeatureImportanceAndSignificance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row37_col0\" class=\"data row37 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row37_col1\" class=\"data row37 col1\" >L Jung Box</td>\n",
       "      <td id=\"T_92f42_row37_col2\" class=\"data row37 col2\" >The Ljung-Box test is a statistical test used to determine whether a given set of data has autocorrelations that are different from zero.</td>\n",
       "      <td id=\"T_92f42_row37_col3\" class=\"data row37 col3\" >validmind.model_validation.statsmodels.LJungBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row38_col0\" class=\"data row38 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row38_col1\" class=\"data row38 col1\" >Logistic Reg Prediction Histogram</td>\n",
       "      <td id=\"T_92f42_row38_col2\" class=\"data row38 col2\" >This metric calculates the probability of default (PD) for each instance in the training and test datasets, and creates histograms to visualize the distributions of PD for the positive and negative classes.</td>\n",
       "      <td id=\"T_92f42_row38_col3\" class=\"data row38 col3\" >validmind.model_validation.statsmodels.LogisticRegPredictionHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row39_col0\" class=\"data row39 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row39_col1\" class=\"data row39 col1\" >Jarque Bera</td>\n",
       "      <td id=\"T_92f42_row39_col2\" class=\"data row39 col2\" >The Jarque-Bera test is a statistical test used to determine whether a given set of data follows a normal distribution.</td>\n",
       "      <td id=\"T_92f42_row39_col3\" class=\"data row39 col3\" >validmind.model_validation.statsmodels.JarqueBera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row40_col0\" class=\"data row40 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row40_col1\" class=\"data row40 col1\" >Phillips Perron Arch</td>\n",
       "      <td id=\"T_92f42_row40_col2\" class=\"data row40 col2\" >Phillips-Perron (PP) unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_92f42_row40_col3\" class=\"data row40 col3\" >validmind.model_validation.statsmodels.PhillipsPerronArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row41_col0\" class=\"data row41 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row41_col1\" class=\"data row41 col1\" >Kolmogorov Smirnov</td>\n",
       "      <td id=\"T_92f42_row41_col2\" class=\"data row41 col2\" >The Kolmogorov-Smirnov metric is a statistical test used to determine whether a given set of data follows a normal distribution.</td>\n",
       "      <td id=\"T_92f42_row41_col3\" class=\"data row41 col3\" >validmind.model_validation.statsmodels.KolmogorovSmirnov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row42_col0\" class=\"data row42 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row42_col1\" class=\"data row42 col1\" >Residuals Visual Inspection</td>\n",
       "      <td id=\"T_92f42_row42_col2\" class=\"data row42 col2\" >Log plots for visual inspection of residuals</td>\n",
       "      <td id=\"T_92f42_row42_col3\" class=\"data row42 col3\" >validmind.model_validation.statsmodels.ResidualsVisualInspection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row43_col0\" class=\"data row43 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row43_col1\" class=\"data row43 col1\" >Shapiro Wilk</td>\n",
       "      <td id=\"T_92f42_row43_col2\" class=\"data row43 col2\" >The Shapiro-Wilk test is a statistical test used to determine whether a given set of data follows a normal distribution.</td>\n",
       "      <td id=\"T_92f42_row43_col3\" class=\"data row43 col3\" >validmind.model_validation.statsmodels.ShapiroWilk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row44_col0\" class=\"data row44 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row44_col1\" class=\"data row44 col1\" >Scorecard Bucket Histogram</td>\n",
       "      <td id=\"T_92f42_row44_col2\" class=\"data row44 col2\" >Scorecard Bucket Probability of Default</td>\n",
       "      <td id=\"T_92f42_row44_col3\" class=\"data row44 col3\" >validmind.model_validation.statsmodels.ScorecardBucketHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row45_col0\" class=\"data row45 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row45_col1\" class=\"data row45 col1\" >Regression Model Insample Comparison</td>\n",
       "      <td id=\"T_92f42_row45_col2\" class=\"data row45 col2\" >This section shows In-sample comparison of regression models involves comparing the performance of different regression models on the same dataset that was used to train the models. This is typically done by calculating a goodness-of-fit statistic such as the R-squared or mean squared error (MSE) for each model, and then comparing these statistics to determine which model has the best fit to the data.</td>\n",
       "      <td id=\"T_92f42_row45_col3\" class=\"data row45 col3\" >validmind.model_validation.statsmodels.RegressionModelInsampleComparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row46_col0\" class=\"data row46 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row46_col1\" class=\"data row46 col1\" >Regression Feature Significance</td>\n",
       "      <td id=\"T_92f42_row46_col2\" class=\"data row46 col2\" >This section shows plots of feature p-values for each model.</td>\n",
       "      <td id=\"T_92f42_row46_col3\" class=\"data row46 col3\" >validmind.model_validation.statsmodels.RegressionFeatureSignificance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row47_col0\" class=\"data row47 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row47_col1\" class=\"data row47 col1\" >Regression Model Summary</td>\n",
       "      <td id=\"T_92f42_row47_col2\" class=\"data row47 col2\" >Test that output the summary of regression models of statsmodel library.</td>\n",
       "      <td id=\"T_92f42_row47_col3\" class=\"data row47 col3\" >validmind.model_validation.statsmodels.RegressionModelSummary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row48_col0\" class=\"data row48 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row48_col1\" class=\"data row48 col1\" >KPSS</td>\n",
       "      <td id=\"T_92f42_row48_col2\" class=\"data row48 col2\" >Kwiatkowski-Phillips-Schmidt-Shin (KPSS) unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_92f42_row48_col3\" class=\"data row48 col3\" >validmind.model_validation.statsmodels.KPSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row49_col0\" class=\"data row49 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row49_col1\" class=\"data row49 col1\" >Lilliefors</td>\n",
       "      <td id=\"T_92f42_row49_col2\" class=\"data row49 col2\" >The Lilliefors test is a statistical test used to determine whether a given set of data follows a normal distribution.</td>\n",
       "      <td id=\"T_92f42_row49_col3\" class=\"data row49 col3\" >validmind.model_validation.statsmodels.Lilliefors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row50_col0\" class=\"data row50 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row50_col1\" class=\"data row50 col1\" >Logistic Reg Cumulative Prob</td>\n",
       "      <td id=\"T_92f42_row50_col2\" class=\"data row50 col2\" >This metric calculates the cumulative probabilities for each instance in the training and test datasets, and creates a plot to visualize the distributions of probabilities for the positive and negative classes.</td>\n",
       "      <td id=\"T_92f42_row50_col3\" class=\"data row50 col3\" >validmind.model_validation.statsmodels.LogisticRegCumulativeProb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row51_col0\" class=\"data row51 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row51_col1\" class=\"data row51 col1\" >Runs Test</td>\n",
       "      <td id=\"T_92f42_row51_col2\" class=\"data row51 col2\" >The runs test is a statistical test used to determine whether a given set of data has runs of positive and negative values that are longer than expected under the null hypothesis of randomness.</td>\n",
       "      <td id=\"T_92f42_row51_col3\" class=\"data row51 col3\" >validmind.model_validation.statsmodels.RunsTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row52_col0\" class=\"data row52 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row52_col1\" class=\"data row52 col1\" >Scorecard Probabilities Histogram</td>\n",
       "      <td id=\"T_92f42_row52_col2\" class=\"data row52 col2\" >Scorecard Bucket Probability of Default Histogram</td>\n",
       "      <td id=\"T_92f42_row52_col3\" class=\"data row52 col3\" >validmind.model_validation.statsmodels.ScorecardProbabilitiesHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row53_col0\" class=\"data row53 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row53_col1\" class=\"data row53 col1\" >DFGLS Arch</td>\n",
       "      <td id=\"T_92f42_row53_col2\" class=\"data row53 col2\" >Dickey-Fuller GLS unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_92f42_row53_col3\" class=\"data row53 col3\" >validmind.model_validation.statsmodels.DFGLSArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row54_col0\" class=\"data row54 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row54_col1\" class=\"data row54 col1\" >Auto ARIMA</td>\n",
       "      <td id=\"T_92f42_row54_col2\" class=\"data row54 col2\" >Automatically fits multiple ARIMA models for each variable and ranks them by BIC and AIC.</td>\n",
       "      <td id=\"T_92f42_row54_col3\" class=\"data row54 col3\" >validmind.model_validation.statsmodels.AutoARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row55_col0\" class=\"data row55 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row55_col1\" class=\"data row55 col1\" >ADF Test</td>\n",
       "      <td id=\"T_92f42_row55_col2\" class=\"data row55 col2\" >Augmented Dickey-Fuller Metric for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_92f42_row55_col3\" class=\"data row55 col3\" >validmind.model_validation.statsmodels.ADFTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row56_col0\" class=\"data row56 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row56_col1\" class=\"data row56 col1\" >GINI Table</td>\n",
       "      <td id=\"T_92f42_row56_col2\" class=\"data row56 col2\" >Compute and display the AUC, GINI, and KS for train and test sets.</td>\n",
       "      <td id=\"T_92f42_row56_col3\" class=\"data row56 col3\" >validmind.model_validation.statsmodels.GINITable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row57_col0\" class=\"data row57 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row57_col1\" class=\"data row57 col1\" >Regression Model Forecast Plot</td>\n",
       "      <td id=\"T_92f42_row57_col2\" class=\"data row57 col2\" >This section shows plots of training and test datasets vs forecast trainining and forecast test.</td>\n",
       "      <td id=\"T_92f42_row57_col3\" class=\"data row57 col3\" >validmind.model_validation.statsmodels.RegressionModelForecastPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row58_col0\" class=\"data row58 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row58_col1\" class=\"data row58 col1\" >ADF</td>\n",
       "      <td id=\"T_92f42_row58_col2\" class=\"data row58 col2\" >Augmented Dickey-Fuller unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_92f42_row58_col3\" class=\"data row58 col3\" >validmind.model_validation.statsmodels.ADF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row59_col0\" class=\"data row59 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row59_col1\" class=\"data row59 col1\" >Durbin Watson Test</td>\n",
       "      <td id=\"T_92f42_row59_col2\" class=\"data row59 col2\" >The Durbin-Watson Metric is a statistical test that can be used to detect autocorrelation in a time series.</td>\n",
       "      <td id=\"T_92f42_row59_col3\" class=\"data row59 col3\" >validmind.model_validation.statsmodels.DurbinWatsonTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row60_col0\" class=\"data row60 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row60_col1\" class=\"data row60 col1\" >Missing Values Risk</td>\n",
       "      <td id=\"T_92f42_row60_col2\" class=\"data row60 col2\" >This section provides an analysis of the risk associated with missing values in the dataset, providing two risk measures: 1) Percentage of missing values in the dataset 2) Percentage of variables with missing values.</td>\n",
       "      <td id=\"T_92f42_row60_col3\" class=\"data row60 col3\" >validmind.data_validation.MissingValuesRisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row61_col0\" class=\"data row61 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row61_col1\" class=\"data row61 col1\" >IQR Outliers Table</td>\n",
       "      <td id=\"T_92f42_row61_col2\" class=\"data row61 col2\" >Analyzes the distribution of outliers in numerical features using the Interquartile Range (IQR) method. The input dataset is required.</td>\n",
       "      <td id=\"T_92f42_row61_col3\" class=\"data row61 col3\" >validmind.data_validation.IQROutliersTable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row62_col0\" class=\"data row62 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row62_col1\" class=\"data row62 col1\" >Bivariate Features Bar Plots</td>\n",
       "      <td id=\"T_92f42_row62_col2\" class=\"data row62 col2\" >Generates a visual analysis of categorical data by plotting bivariate feautres bar plots. The input dataset and features_pairs are required.</td>\n",
       "      <td id=\"T_92f42_row62_col3\" class=\"data row62 col3\" >validmind.data_validation.BivariateFeaturesBarPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row63_col0\" class=\"data row63 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row63_col1\" class=\"data row63 col1\" >Skewness</td>\n",
       "      <td id=\"T_92f42_row63_col2\" class=\"data row63 col2\" >The skewness test measures the extent to which a distribution of values differs from a normal distribution. A positive skew describes a longer tail of values in the right and a negative skew describes a longer tail of values in the left.</td>\n",
       "      <td id=\"T_92f42_row63_col3\" class=\"data row63 col3\" >validmind.data_validation.Skewness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row64_col0\" class=\"data row64 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row64_col1\" class=\"data row64 col1\" >Duplicates</td>\n",
       "      <td id=\"T_92f42_row64_col2\" class=\"data row64 col2\" >The duplicates test measures the number of duplicate entries found in the dataset.\n",
       "- If the dataset has a `text_column` property then the test will check for duplicate entries in that column.\n",
       "- If a primary key column is specified, the dataset is checked for duplicate primary keys as well.</td>\n",
       "      <td id=\"T_92f42_row64_col3\" class=\"data row64 col3\" >validmind.data_validation.Duplicates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row65_col0\" class=\"data row65 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row65_col1\" class=\"data row65 col1\" >Missing Values Bar Plot</td>\n",
       "      <td id=\"T_92f42_row65_col2\" class=\"data row65 col2\" >Generates a visual analysis of missing values by plotting horizontal bar plots with colored bars and a threshold line. The input dataset is required.</td>\n",
       "      <td id=\"T_92f42_row65_col3\" class=\"data row65 col3\" >validmind.data_validation.MissingValuesBarPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row66_col0\" class=\"data row66 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row66_col1\" class=\"data row66 col1\" >Dataset Description</td>\n",
       "      <td id=\"T_92f42_row66_col2\" class=\"data row66 col2\" >Collects a set of descriptive statistics for a dataset</td>\n",
       "      <td id=\"T_92f42_row66_col3\" class=\"data row66 col3\" >validmind.data_validation.DatasetDescription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row67_col0\" class=\"data row67 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row67_col1\" class=\"data row67 col1\" >Scatter Plot</td>\n",
       "      <td id=\"T_92f42_row67_col2\" class=\"data row67 col2\" >Generates a visual analysis of data by plotting a scatter plot matrix for all columns in the dataset. The input dataset can have multiple columns (features) if necessary.</td>\n",
       "      <td id=\"T_92f42_row67_col3\" class=\"data row67 col3\" >validmind.data_validation.ScatterPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row68_col0\" class=\"data row68 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row68_col1\" class=\"data row68 col1\" >Time Series Outliers</td>\n",
       "      <td id=\"T_92f42_row68_col2\" class=\"data row68 col2\" >Test that find outliers for time series data using the z-score method</td>\n",
       "      <td id=\"T_92f42_row68_col3\" class=\"data row68 col3\" >validmind.data_validation.TimeSeriesOutliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row69_col0\" class=\"data row69 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row69_col1\" class=\"data row69 col1\" >Tabular Categorical Bar Plots</td>\n",
       "      <td id=\"T_92f42_row69_col2\" class=\"data row69 col2\" >Generates a visual analysis of categorical data by plotting bar plots. The input dataset can have multiple categorical variables if necessary. In this case, we produce a separate plot for each categorical variable.</td>\n",
       "      <td id=\"T_92f42_row69_col3\" class=\"data row69 col3\" >validmind.data_validation.TabularCategoricalBarPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row70_col0\" class=\"data row70 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row70_col1\" class=\"data row70 col1\" >Auto Stationarity</td>\n",
       "      <td id=\"T_92f42_row70_col2\" class=\"data row70 col2\" >Automatically detects stationarity for each time series in a DataFrame using the Augmented Dickey-Fuller (ADF) test.</td>\n",
       "      <td id=\"T_92f42_row70_col3\" class=\"data row70 col3\" >validmind.data_validation.AutoStationarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row71_col0\" class=\"data row71 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row71_col1\" class=\"data row71 col1\" >Descriptive Statistics</td>\n",
       "      <td id=\"T_92f42_row71_col2\" class=\"data row71 col2\" >This section provides descriptive statistics for numerical and categorical variables found in the dataset.</td>\n",
       "      <td id=\"T_92f42_row71_col3\" class=\"data row71 col3\" >validmind.data_validation.DescriptiveStatistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row72_col0\" class=\"data row72 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row72_col1\" class=\"data row72 col1\" >ANOVA One Way Table</td>\n",
       "      <td id=\"T_92f42_row72_col2\" class=\"data row72 col2\" >Perform an ANOVA F-test for each numerical variable with the target. The input dataset and target column are required.</td>\n",
       "      <td id=\"T_92f42_row72_col3\" class=\"data row72 col3\" >validmind.data_validation.ANOVAOneWayTable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row73_col0\" class=\"data row73 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row73_col1\" class=\"data row73 col1\" >Target Rate Bar Plots</td>\n",
       "      <td id=\"T_92f42_row73_col2\" class=\"data row73 col2\" >Generates a visual analysis of target ratios by plotting bar plots. The input dataset can have multiple categorical variables if necessary. In this case, we produce a separate row of plots for each categorical variable.</td>\n",
       "      <td id=\"T_92f42_row73_col3\" class=\"data row73 col3\" >validmind.data_validation.TargetRateBarPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row74_col0\" class=\"data row74 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row74_col1\" class=\"data row74 col1\" >Pearson Correlation Matrix</td>\n",
       "      <td id=\"T_92f42_row74_col2\" class=\"data row74 col2\" >Extracts the Pearson correlation coefficient for all pairs of numerical variables in the dataset. This metric is useful to identify highly correlated variables that can be removed from the dataset to reduce dimensionality.</td>\n",
       "      <td id=\"T_92f42_row74_col3\" class=\"data row74 col3\" >validmind.data_validation.PearsonCorrelationMatrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row75_col0\" class=\"data row75 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row75_col1\" class=\"data row75 col1\" >Feature Target Correlation Plot</td>\n",
       "      <td id=\"T_92f42_row75_col2\" class=\"data row75 col2\" >Generates a visual analysis of correlations between features and target by plotting a bar plot. The input dataset is required.</td>\n",
       "      <td id=\"T_92f42_row75_col3\" class=\"data row75 col3\" >validmind.data_validation.FeatureTargetCorrelationPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row76_col0\" class=\"data row76 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row76_col1\" class=\"data row76 col1\" >Tabular Numerical Histograms</td>\n",
       "      <td id=\"T_92f42_row76_col2\" class=\"data row76 col2\" >Generates a visual analysis of numerical data by plotting the histogram. The input dataset can have multiple numerical variables if necessary. In this case, we produce a separate plot for each numerical variable.</td>\n",
       "      <td id=\"T_92f42_row76_col3\" class=\"data row76 col3\" >validmind.data_validation.TabularNumericalHistograms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row77_col0\" class=\"data row77 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row77_col1\" class=\"data row77 col1\" >Isolation Forest Outliers</td>\n",
       "      <td id=\"T_92f42_row77_col2\" class=\"data row77 col2\" >The Isolation Forest test is an algorithm used for anomaly detection in datasets. It is based on the concept of isolating anomalies rather than identifying normal data points. The test builds an ensemble of isolation trees, which are binary trees created by randomly selecting features and splitting the data based on random thresholds.\n",
       "\n",
       "The main idea behind the Isolation Forest test is that anomalies are likely to be isolated quickly in these trees compared to normal instances. Anomalies are expected to have shorter average path lengths in the trees, as they are different from the majority of the data points.\n",
       "\n",
       "It's important to note that the Isolation Forest test assumes anomalies are less frequent and have different properties compared to normal instances. However, it may not be as effective in detecting anomalies that are close to each other or in datasets where anomalies are more prevalent.</td>\n",
       "      <td id=\"T_92f42_row77_col3\" class=\"data row77 col3\" >validmind.data_validation.IsolationForestOutliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row78_col0\" class=\"data row78 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row78_col1\" class=\"data row78 col1\" >Chi Squared Features Table</td>\n",
       "      <td id=\"T_92f42_row78_col2\" class=\"data row78 col2\" >Perform a Chi-Squared test of independence for each categorical variable with the target. The input dataset and target column are required.</td>\n",
       "      <td id=\"T_92f42_row78_col3\" class=\"data row78 col3\" >validmind.data_validation.ChiSquaredFeaturesTable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row79_col0\" class=\"data row79 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row79_col1\" class=\"data row79 col1\" >High Cardinality</td>\n",
       "      <td id=\"T_92f42_row79_col2\" class=\"data row79 col2\" >The high cardinality test measures the number of unique values found in categorical columns.</td>\n",
       "      <td id=\"T_92f42_row79_col3\" class=\"data row79 col3\" >validmind.data_validation.HighCardinality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row80_col0\" class=\"data row80 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row80_col1\" class=\"data row80 col1\" >Missing Values</td>\n",
       "      <td id=\"T_92f42_row80_col2\" class=\"data row80 col2\" >Test that the number of missing values in the dataset across all features is less than a threshold</td>\n",
       "      <td id=\"T_92f42_row80_col3\" class=\"data row80 col3\" >validmind.data_validation.MissingValues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row81_col0\" class=\"data row81 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row81_col1\" class=\"data row81 col1\" >Default Ratesby Risk Band Plot</td>\n",
       "      <td id=\"T_92f42_row81_col2\" class=\"data row81 col2\" >This metric calculates the default rates for each risk band in the data, and creates a bar plot to visualize these rates. The bar plot offers a straightforward view of default rates across different risk bands, which can help with evaluating and comparing the performance of credit risk models.</td>\n",
       "      <td id=\"T_92f42_row81_col3\" class=\"data row81 col3\" >validmind.data_validation.DefaultRatesbyRiskBandPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row82_col0\" class=\"data row82 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row82_col1\" class=\"data row82 col1\" >Rolling Stats Plot</td>\n",
       "      <td id=\"T_92f42_row82_col2\" class=\"data row82 col2\" >This class provides a metric to visualize the stationarity of a given time series dataset by plotting the rolling mean and rolling standard deviation. The rolling mean represents the average of the time series data over a fixed-size sliding window, which helps in identifying trends in the data. The rolling standard deviation measures the variability of the data within the sliding window, showing any changes in volatility over time. By analyzing these plots, users can gain insights into the stationarity of the time series data and determine if any transformations or differencing operations are required before applying time series models.</td>\n",
       "      <td id=\"T_92f42_row82_col3\" class=\"data row82 col3\" >validmind.data_validation.RollingStatsPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row83_col0\" class=\"data row83 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row83_col1\" class=\"data row83 col1\" >Dataset Correlations</td>\n",
       "      <td id=\"T_92f42_row83_col2\" class=\"data row83 col2\" >Extracts the correlation matrix for a dataset. The following coefficients are calculated:\n",
       "- Pearson's R for numerical variables\n",
       "- Cramer's V for categorical variables\n",
       "- Correlation ratios for categorical-numerical variables</td>\n",
       "      <td id=\"T_92f42_row83_col3\" class=\"data row83 col3\" >validmind.data_validation.DatasetCorrelations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row84_col0\" class=\"data row84 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row84_col1\" class=\"data row84 col1\" >Tabular Description Tables</td>\n",
       "      <td id=\"T_92f42_row84_col2\" class=\"data row84 col2\" >This section provides descriptive statistics for numerical, categorical and datetime variables found in the dataset.</td>\n",
       "      <td id=\"T_92f42_row84_col3\" class=\"data row84 col3\" >validmind.data_validation.TabularDescriptionTables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row85_col0\" class=\"data row85 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row85_col1\" class=\"data row85 col1\" >Auto MA</td>\n",
       "      <td id=\"T_92f42_row85_col2\" class=\"data row85 col2\" >Automatically detects the MA order of a time series using both BIC and AIC.</td>\n",
       "      <td id=\"T_92f42_row85_col3\" class=\"data row85 col3\" >validmind.data_validation.AutoMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row86_col0\" class=\"data row86 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row86_col1\" class=\"data row86 col1\" >Unique Rows</td>\n",
       "      <td id=\"T_92f42_row86_col2\" class=\"data row86 col2\" >Test that the number of unique rows is greater than a threshold</td>\n",
       "      <td id=\"T_92f42_row86_col3\" class=\"data row86 col3\" >validmind.data_validation.UniqueRows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row87_col0\" class=\"data row87 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row87_col1\" class=\"data row87 col1\" >Too Many Zero Values</td>\n",
       "      <td id=\"T_92f42_row87_col2\" class=\"data row87 col2\" >The zeros test finds columns that have too many zero values.</td>\n",
       "      <td id=\"T_92f42_row87_col3\" class=\"data row87 col3\" >validmind.data_validation.TooManyZeroValues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row88_col0\" class=\"data row88 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row88_col1\" class=\"data row88 col1\" >High Pearson Correlation</td>\n",
       "      <td id=\"T_92f42_row88_col2\" class=\"data row88 col2\" >Test that the pairwise Pearson correlation coefficients between the features in the dataset do not exceed a specified threshold.</td>\n",
       "      <td id=\"T_92f42_row88_col3\" class=\"data row88 col3\" >validmind.data_validation.HighPearsonCorrelation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row89_col0\" class=\"data row89 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row89_col1\" class=\"data row89 col1\" >AC Fand PACF Plot</td>\n",
       "      <td id=\"T_92f42_row89_col2\" class=\"data row89 col2\" >Plots ACF and PACF for a given time series dataset.</td>\n",
       "      <td id=\"T_92f42_row89_col3\" class=\"data row89 col3\" >validmind.data_validation.ACFandPACFPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row90_col0\" class=\"data row90 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row90_col1\" class=\"data row90 col1\" >Bivariate Histograms</td>\n",
       "      <td id=\"T_92f42_row90_col2\" class=\"data row90 col2\" >Generates a visual analysis of categorical data by plotting bivariate histograms. The input dataset and variable_pairs are required.</td>\n",
       "      <td id=\"T_92f42_row90_col3\" class=\"data row90 col3\" >validmind.data_validation.BivariateHistograms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row91_col0\" class=\"data row91 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row91_col1\" class=\"data row91 col1\" >WOE Bin Table</td>\n",
       "      <td id=\"T_92f42_row91_col2\" class=\"data row91 col2\" >Implements WoE-based automatic binning for features in a dataset and calculates their Information Value (IV). Utilizes the 'scorecardpy' library for the binning process.</td>\n",
       "      <td id=\"T_92f42_row91_col3\" class=\"data row91 col3\" >validmind.data_validation.WOEBinTable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row92_col0\" class=\"data row92 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row92_col1\" class=\"data row92 col1\" >Heatmap Feature Correlations</td>\n",
       "      <td id=\"T_92f42_row92_col2\" class=\"data row92 col2\" >Generates a visual analysis of correlations by plotting a heatmap. The input dataset is required.</td>\n",
       "      <td id=\"T_92f42_row92_col3\" class=\"data row92 col3\" >validmind.data_validation.HeatmapFeatureCorrelations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row93_col0\" class=\"data row93 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row93_col1\" class=\"data row93 col1\" >Time Series Frequency</td>\n",
       "      <td id=\"T_92f42_row93_col2\" class=\"data row93 col2\" >Test that detects frequencies in the data</td>\n",
       "      <td id=\"T_92f42_row93_col3\" class=\"data row93 col3\" >validmind.data_validation.TimeSeriesFrequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row94_col0\" class=\"data row94 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row94_col1\" class=\"data row94 col1\" >Dataset Split</td>\n",
       "      <td id=\"T_92f42_row94_col2\" class=\"data row94 col2\" >This section shows the size of the dataset split into training, test (and validation) sets where applicable. The size of each dataset is shown in absolute terms and as a proportion of the total dataset size.\n",
       "\n",
       "The dataset split is important to understand because it can affect the performance of the model. For example, if the training set is too small, the model may not be able to learn the patterns in the data and will perform poorly on the test set. On the other hand, if the test set is too small, the model may not be able to generalize well to unseen data and will perform poorly on the validation set.</td>\n",
       "      <td id=\"T_92f42_row94_col3\" class=\"data row94 col3\" >validmind.data_validation.DatasetSplit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row95_col0\" class=\"data row95 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row95_col1\" class=\"data row95 col1\" >Spread Plot</td>\n",
       "      <td id=\"T_92f42_row95_col2\" class=\"data row95 col2\" >This class provides a metric to visualize the spread between pairs of time series variables in a given dataset. By plotting the spread of each pair of variables in separate figures, users can assess the relationship between the variables and determine if any cointegration or other time series relationships exist between them.</td>\n",
       "      <td id=\"T_92f42_row95_col3\" class=\"data row95 col3\" >validmind.data_validation.SpreadPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row96_col0\" class=\"data row96 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row96_col1\" class=\"data row96 col1\" >Time Series Line Plot</td>\n",
       "      <td id=\"T_92f42_row96_col2\" class=\"data row96 col2\" >Generates a visual analysis of time series data by plotting the raw time series. The input dataset can have multiple time series if necessary. In this case we produce a separate plot for each time series.</td>\n",
       "      <td id=\"T_92f42_row96_col3\" class=\"data row96 col3\" >validmind.data_validation.TimeSeriesLinePlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row97_col0\" class=\"data row97 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row97_col1\" class=\"data row97 col1\" >Pi T Credit Scores Histogram</td>\n",
       "      <td id=\"T_92f42_row97_col2\" class=\"data row97 col2\" >This metric calculates the scores for each instance in the training and test datasets, and creates histograms to visualize the distributions of scores for the positive and negative classes.</td>\n",
       "      <td id=\"T_92f42_row97_col3\" class=\"data row97 col3\" >validmind.data_validation.PiTCreditScoresHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row98_col0\" class=\"data row98 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row98_col1\" class=\"data row98 col1\" >Auto Seasonality</td>\n",
       "      <td id=\"T_92f42_row98_col2\" class=\"data row98 col2\" >Automatically detects the optimal seasonal order for a time series dataset using the seasonal_decompose method.</td>\n",
       "      <td id=\"T_92f42_row98_col3\" class=\"data row98 col3\" >validmind.data_validation.AutoSeasonality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row99_col0\" class=\"data row99 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row99_col1\" class=\"data row99 col1\" >Bivariate Scatter Plots</td>\n",
       "      <td id=\"T_92f42_row99_col2\" class=\"data row99 col2\" >Generates a visual analysis of categorical data by plotting bivariate scatter plots. The input dataset and variable_pairs are required.</td>\n",
       "      <td id=\"T_92f42_row99_col3\" class=\"data row99 col3\" >validmind.data_validation.BivariateScatterPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row100_col0\" class=\"data row100 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row100_col1\" class=\"data row100 col1\" >Engle Granger Coint</td>\n",
       "      <td id=\"T_92f42_row100_col2\" class=\"data row100 col2\" >Test for cointegration between pairs of time series variables in a given dataset using the Engle-Granger test.</td>\n",
       "      <td id=\"T_92f42_row100_col3\" class=\"data row100 col3\" >validmind.data_validation.EngleGrangerCoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row101_col0\" class=\"data row101 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row101_col1\" class=\"data row101 col1\" >Time Series Missing Values</td>\n",
       "      <td id=\"T_92f42_row101_col2\" class=\"data row101 col2\" >Test that the number of missing values is less than a threshold</td>\n",
       "      <td id=\"T_92f42_row101_col3\" class=\"data row101 col3\" >validmind.data_validation.TimeSeriesMissingValues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row102_col0\" class=\"data row102 col0\" >DatasetMetadata</td>\n",
       "      <td id=\"T_92f42_row102_col1\" class=\"data row102 col1\" >Dataset Metadata</td>\n",
       "      <td id=\"T_92f42_row102_col2\" class=\"data row102 col2\" >Custom class to collect a set of descriptive statistics for a dataset. This class will log dataset metadata via `log_dataset` instead of a metric. Dataset metadata is necessary to initialize dataset object that can be related to different metrics and test results</td>\n",
       "      <td id=\"T_92f42_row102_col3\" class=\"data row102 col3\" >validmind.data_validation.DatasetMetadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row103_col0\" class=\"data row103 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row103_col1\" class=\"data row103 col1\" >Time Series Histogram</td>\n",
       "      <td id=\"T_92f42_row103_col2\" class=\"data row103 col2\" >Generates a visual analysis of time series data by plotting the histogram. The input dataset can have multiple time series if necessary. In this case we produce a separate plot for each time series.</td>\n",
       "      <td id=\"T_92f42_row103_col3\" class=\"data row103 col3\" >validmind.data_validation.TimeSeriesHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row104_col0\" class=\"data row104 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row104_col1\" class=\"data row104 col1\" >Lagged Correlation Heatmap</td>\n",
       "      <td id=\"T_92f42_row104_col2\" class=\"data row104 col2\" >Generates a heatmap of correlations between the target variable and the lags of independent variables in the dataset.</td>\n",
       "      <td id=\"T_92f42_row104_col3\" class=\"data row104 col3\" >validmind.data_validation.LaggedCorrelationHeatmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row105_col0\" class=\"data row105 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row105_col1\" class=\"data row105 col1\" >Seasonal Decompose</td>\n",
       "      <td id=\"T_92f42_row105_col2\" class=\"data row105 col2\" >Calculates seasonal_decompose metric for each of the dataset features</td>\n",
       "      <td id=\"T_92f42_row105_col3\" class=\"data row105 col3\" >validmind.data_validation.SeasonalDecompose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row106_col0\" class=\"data row106 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row106_col1\" class=\"data row106 col1\" >WOE Bin Plots</td>\n",
       "      <td id=\"T_92f42_row106_col2\" class=\"data row106 col2\" >Generates a visual analysis of the WoE and IV values distribution for categorical variables. The input dataset is required.</td>\n",
       "      <td id=\"T_92f42_row106_col3\" class=\"data row106 col3\" >validmind.data_validation.WOEBinPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row107_col0\" class=\"data row107 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row107_col1\" class=\"data row107 col1\" >Class Imbalance</td>\n",
       "      <td id=\"T_92f42_row107_col2\" class=\"data row107 col2\" >The class imbalance test measures the disparity between the majority class and the minority class in the target column.</td>\n",
       "      <td id=\"T_92f42_row107_col3\" class=\"data row107 col3\" >validmind.data_validation.ClassImbalance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row108_col0\" class=\"data row108 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row108_col1\" class=\"data row108 col1\" >IQR Outliers Bar Plot</td>\n",
       "      <td id=\"T_92f42_row108_col2\" class=\"data row108 col2\" >Generates a visual analysis of the outliers for numeric variables based on percentiles. The input dataset is required.</td>\n",
       "      <td id=\"T_92f42_row108_col3\" class=\"data row108 col3\" >validmind.data_validation.IQROutliersBarPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row109_col0\" class=\"data row109 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row109_col1\" class=\"data row109 col1\" >Pi TPD Histogram</td>\n",
       "      <td id=\"T_92f42_row109_col2\" class=\"data row109 col2\" >This metric calculates the probability of default (PD) for each instance in the training and test datasets, and creates histograms to visualize the distributions of PD for the positive and negative classes.</td>\n",
       "      <td id=\"T_92f42_row109_col3\" class=\"data row109 col3\" >validmind.data_validation.PiTPDHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row110_col0\" class=\"data row110 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row110_col1\" class=\"data row110 col1\" >Auto AR</td>\n",
       "      <td id=\"T_92f42_row110_col2\" class=\"data row110 col2\" >Automatically detects the AR order of a time series using both BIC and AIC.</td>\n",
       "      <td id=\"T_92f42_row110_col3\" class=\"data row110 col3\" >validmind.data_validation.AutoAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row111_col0\" class=\"data row111 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row111_col1\" class=\"data row111 col1\" >Tabular Date Time Histograms</td>\n",
       "      <td id=\"T_92f42_row111_col2\" class=\"data row111 col2\" >Generates a visual analysis of datetime data by plotting histograms of differences between consecutive dates. The input dataset can have multiple datetime variables if necessary. In this case, we produce a separate plot for each datetime variable.</td>\n",
       "      <td id=\"T_92f42_row111_col3\" class=\"data row111 col3\" >validmind.data_validation.TabularDateTimeHistograms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row112_col0\" class=\"data row112 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row112_col1\" class=\"data row112 col1\" >Punctuations</td>\n",
       "      <td id=\"T_92f42_row112_col2\" class=\"data row112 col2\" >Metric that analyses the frequencies of punctuations in a given text dataset</td>\n",
       "      <td id=\"T_92f42_row112_col3\" class=\"data row112 col3\" >validmind.data_validation.nlp.Punctuations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row113_col0\" class=\"data row113 col0\" >Metric</td>\n",
       "      <td id=\"T_92f42_row113_col1\" class=\"data row113 col1\" >Common Words</td>\n",
       "      <td id=\"T_92f42_row113_col2\" class=\"data row113 col2\" >The purpose of the common words test is to analyze a dataset and identify the most common words within a specified text column. This test allows users to understand the prevalent words within the dataset's text column and gain insights into the dataset's language patterns.</td>\n",
       "      <td id=\"T_92f42_row113_col3\" class=\"data row113 col3\" >validmind.data_validation.nlp.CommonWords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row114_col0\" class=\"data row114 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row114_col1\" class=\"data row114 col1\" >Hashtags</td>\n",
       "      <td id=\"T_92f42_row114_col2\" class=\"data row114 col2\" >The Hashtags test analyzes the dataset by extracting the text column and applying a regular expression pattern to identify hashtags within the text. It then counts the occurrences of each hashtag and selects the top hashtags based on a specified parameter or the default value. The results are visualized using a bar plot, where the x-axis represents the hashtags and the y-axis represents their frequency counts. It aims to identify the most commonly used hashtags in a given text column and provide visual representation of their frequencies.</td>\n",
       "      <td id=\"T_92f42_row114_col3\" class=\"data row114 col3\" >validmind.data_validation.nlp.Hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row115_col0\" class=\"data row115 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row115_col1\" class=\"data row115 col1\" >Mentions</td>\n",
       "      <td id=\"T_92f42_row115_col2\" class=\"data row115 col2\" >The purpose of the Mentions test is to perform a data quality test focused on analyzing mentions within a dataset. It aims to identify the most frequently mentioned entities or usernames in a given text column and provides a visual representation of the results using a treemap. The Mentions test analyzes the dataset by extracting the text column and applying a regular expression pattern to identify mentions (text preceded by '@') within the text. It then counts the occurrences of each mention and selects the top mentions based on a specified parameter or the default value. The results are visualized using a treemap plot, where the size of each rectangle represents the frequency of the mention.</td>\n",
       "      <td id=\"T_92f42_row115_col3\" class=\"data row115 col3\" >validmind.data_validation.nlp.Mentions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_92f42_row116_col0\" class=\"data row116 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_92f42_row116_col1\" class=\"data row116 col1\" >Stop Words</td>\n",
       "      <td id=\"T_92f42_row116_col2\" class=\"data row116 col2\" >The purpose of the StopWords test is to perform a data quality test focused on identifying and analyzing the usage of stop words within a dataset. Stop words are commonly used words in a language (e.g., \"the\", \"and\", \"is\") that are often considered insignificant for analysis. The StopWords test analyzes the dataset by creating a corpus of words from the specified text column. It then determines the frequency of each stop word in the corpus and calculates the percentage of each stop word in relation to the total number of words. The test results focus on identifying the top stop words based on their percentage in the corpus.</td>\n",
       "      <td id=\"T_92f42_row116_col3\" class=\"data row116 col3\" >validmind.data_validation.nlp.StopWords</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1231acfd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from validmind.tests import list_tests, load_test, describe_test\n",
    "\n",
    "list_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validmind.tests.model_validation.sklearn.ClassifierPerformance.ClassifierPerformance"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_test(\"classifier_performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a30fe th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a30fe_row0_col0, #T_a30fe_row0_col1, #T_a30fe_row0_col2, #T_a30fe_row0_col3, #T_a30fe_row1_col0, #T_a30fe_row1_col1, #T_a30fe_row1_col2, #T_a30fe_row1_col3, #T_a30fe_row2_col0, #T_a30fe_row2_col1, #T_a30fe_row2_col2, #T_a30fe_row2_col3, #T_a30fe_row3_col0, #T_a30fe_row3_col1, #T_a30fe_row3_col2, #T_a30fe_row3_col3, #T_a30fe_row4_col0, #T_a30fe_row4_col1, #T_a30fe_row4_col2, #T_a30fe_row4_col3, #T_a30fe_row5_col0, #T_a30fe_row5_col1, #T_a30fe_row5_col2, #T_a30fe_row5_col3, #T_a30fe_row6_col0, #T_a30fe_row6_col1, #T_a30fe_row6_col2, #T_a30fe_row6_col3, #T_a30fe_row7_col0, #T_a30fe_row7_col1, #T_a30fe_row7_col2, #T_a30fe_row7_col3, #T_a30fe_row8_col0, #T_a30fe_row8_col1, #T_a30fe_row8_col2, #T_a30fe_row8_col3, #T_a30fe_row9_col0, #T_a30fe_row9_col1, #T_a30fe_row9_col2, #T_a30fe_row9_col3, #T_a30fe_row10_col0, #T_a30fe_row10_col1, #T_a30fe_row10_col2, #T_a30fe_row10_col3, #T_a30fe_row11_col0, #T_a30fe_row11_col1, #T_a30fe_row11_col2, #T_a30fe_row11_col3, #T_a30fe_row12_col0, #T_a30fe_row12_col1, #T_a30fe_row12_col2, #T_a30fe_row12_col3, #T_a30fe_row13_col0, #T_a30fe_row13_col1, #T_a30fe_row13_col2, #T_a30fe_row13_col3, #T_a30fe_row14_col0, #T_a30fe_row14_col1, #T_a30fe_row14_col2, #T_a30fe_row14_col3, #T_a30fe_row15_col0, #T_a30fe_row15_col1, #T_a30fe_row15_col2, #T_a30fe_row15_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a30fe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_a30fe_level0_col0\" class=\"col_heading level0 col0\" >Test Type</th>\n",
       "      <th id=\"T_a30fe_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_a30fe_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_a30fe_level0_col3\" class=\"col_heading level0 col3\" >ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row0_col0\" class=\"data row0 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_a30fe_row0_col1\" class=\"data row0 col1\" >Bias</td>\n",
       "      <td id=\"T_a30fe_row0_col2\" class=\"data row0 col2\" >**Purpose:** Bias Evaluation is aimed at assessing if and how the distribution and order of exemplars (examples) within a few-shot learning prompt affect the Language Learning Model's (LLM) output, potentially introducing biases. By examining these influences, we can optimize the model's performance and mitigate unintended biases in its responses.\n",
       "\n",
       "**Test Mechanism:**\n",
       "\n",
       "1. **Distribution of Exemplars:** Check how varying the number of positive vs. negative examples in a prompt impacts the LLM's classification of a neutral or ambiguous statement. 2. **Order of Exemplars:** Examine if the sequence in which positive and negative examples are presented can sway the LLM's response.\n",
       "\n",
       "For each test case, an LLM is used to grade the input prompt on a scale from 1 to 10, based on whether the examples in the prompt may lead to biased responses. A minimum threshold must be met in order for the test to pass. By default, this threshold is set to 7, but it can be adjusted as needed via the test parameters.</td>\n",
       "      <td id=\"T_a30fe_row0_col3\" class=\"data row0 col3\" >validmind.prompt_validation.Bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row1_col0\" class=\"data row1 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_a30fe_row1_col1\" class=\"data row1 col1\" >Clarity</td>\n",
       "      <td id=\"T_a30fe_row1_col2\" class=\"data row1 col2\" >**Purpose:** The Clarity Evaluation is designed to assess whether prompts provided to a Language Learning Model (LLM) are unmistakably clear in their instructions. With clear prompts, the LLM is better suited to more accurately and effectively interpret and respond to instructions in the prompt\n",
       "\n",
       "**Test Mechanism:** Using an LLM, prompts are scrutinized for clarity, considering aspects like detail inclusion, persona adoption, step-by-step instructions, use of examples, and desired output length. Each prompt is graded on a scale from 1 to 10 based on its clarity. Prompts scoring at or above a predetermined threshold (default is 7) are marked as clear. This threshold can be adjusted via the test parameters.\n",
       "\n",
       "**Why Clarity Matters:** Clear prompts minimize the room for misinterpretation, allowing the LLM to generate more relevant and accurate responses. Ambiguous or vague instructions might leave the model guessing, leading to suboptimal outputs.\n",
       "\n",
       "**Tactics for Ensuring Clarity that will be referenced during evaluation:** 1. **Detail Inclusion:** Provide essential details or context to prevent the LLM from making assumptions. 2. **Adopt a Persona:** Use system messages to specify the desired persona for the LLM's responses. 3. **Specify Steps:** For certain tasks, delineate the required steps explicitly, helping the model in sequential understanding. 4. **Provide Examples:** While general instructions are efficient, in some scenarios, \"few-shot\" prompting or style examples can guide the LLM more effectively. 5. **Determine Output Length:** Define the targeted length of the response, whether in terms of paragraphs, bullet points, or other units. While word counts aren't always precise, specifying formats like paragraphs can offer more predictable results.</td>\n",
       "      <td id=\"T_a30fe_row1_col3\" class=\"data row1 col3\" >validmind.prompt_validation.Clarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row2_col0\" class=\"data row2 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_a30fe_row2_col1\" class=\"data row2 col1\" >Specificity</td>\n",
       "      <td id=\"T_a30fe_row2_col2\" class=\"data row2 col2\" >**Purpose:** The Specificity Test aims to assess the clarity, precision, and effectiveness of prompts provided to a Language Learning Model (LLM). Ensuring specificity in the prompts given to an LLM can significantly influence the accuracy and relevance of its outputs. The goal of this test is to ascertain that the instructions in a prompt are unmistakably clear and relevant, eliminating ambiguity and steering the LLM toward desired outcomes.\n",
       "\n",
       "**Test Mechanism:** Utilizing an LLM, each prompt is graded on a specificity scale ranging from 1 to 10. The grade reflects how well the prompt adheres to principles of clarity, detail, and relevancy without being overly verbose. Prompts that achieve a grade equal to or exceeding a predefined threshold (default set to 7) are deemed to pass the evaluation, while those falling below are marked as failing. This threshold can be adjusted as needed.\n",
       "\n",
       "**Why Specificity Matters:** Prompts that are detailed and descriptive often yield better and more accurate results from an LLM. Rather than relying on specific keywords or tokens, it's crucial to have a well-structured and descriptive prompt. Including relevant examples within the prompt can be particularly effective, guiding the LLM to produce outputs in desired formats. However, it's essential to strike a balance. While prompts need to be detailed, they shouldn't be overloaded with unnecessary information. The emphasis should always be on relevancy and conciseness, considering there are limitations to how long a prompt can be.\n",
       "\n",
       "**Example:** Imagine wanting an LLM to extract specific details from a given text. A vague prompt might yield varied results. However, with a prompt like, \"Extract the names of all characters and the cities they visited from the text\", the LLM is guided more precisely towards the desired information extraction.</td>\n",
       "      <td id=\"T_a30fe_row2_col3\" class=\"data row2 col3\" >validmind.prompt_validation.Specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row3_col0\" class=\"data row3 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_a30fe_row3_col1\" class=\"data row3 col1\" >Robustness</td>\n",
       "      <td id=\"T_a30fe_row3_col2\" class=\"data row3 col2\" >**Purpose:** The Robustness Integrity Assessment evaluates the resilience and reliability of prompts provided to a Language Learning Model (LLM). The primary objective is to ensure that prompts consistently produce accurate and desired outputs, even in diverse or challenging scenarios.\n",
       "\n",
       "**Test Mechanism:** Prompts are subjected to various conditions, alterations, and contexts to check their stability in eliciting consistent responses from the LLM. Factors such as different phrasings, inclusion of potential distractors, and varied input complexities are introduced to test the robustness of the prompt. By default, the test generates 10 inputs for the prompt but this can be adjusted via the test parameters.\n",
       "\n",
       "**Why Robustness Matters:** A robust prompt ensures consistent performance and reduces the likelihood of unexpected or off-tangent outputs. This consistency is vital for applications where predictability and reliability of the LLM's response are paramount.</td>\n",
       "      <td id=\"T_a30fe_row3_col3\" class=\"data row3 col3\" >validmind.prompt_validation.Robustness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row4_col0\" class=\"data row4 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_a30fe_row4_col1\" class=\"data row4 col1\" >Negative Instruction</td>\n",
       "      <td id=\"T_a30fe_row4_col2\" class=\"data row4 col2\" >**Purpose:** The Positive Instructional Assessment evaluates prompts provided to a Language Learning Model (LLM) to ensure they are framed using affirmative and proactive language. By focusing on what should be done rather than what should be avoided, prompts can guide the LLM more effectively towards generating appropriate and desired outputs.\n",
       "\n",
       "**Test Mechanism:** Employing an LLM as an evaluator, each prompt is meticulously analyzed and graded on use of positive instructions on a scale from 1 to 10. The grade indicates how well the prompt employs affirmative language while avoiding negative or prohibitive instructions. Prompts that achieve a grade equal to or exceeding a predetermined threshold (default set to 7) are recognized as adhering to positive instruction best practices. This threshold can be adjusted via the test parameters.\n",
       "\n",
       "**Why Positive Instructions Matter:** Prompts that are phrased in the affirmative, emphasizing what to do, tend to direct the LLM more clearly than those that focus on what not to do. Negative instructions can lead to ambiguities and undesired model responses. By emphasizing clarity and proactive guidance, we optimize the chances of obtaining relevant and targeted responses from the LLM.\n",
       "\n",
       "**Example:** Consider a scenario involving a chatbot designed to recommend movies. An instruction framed as, \"Don't recommend movies that are horror or thriller\" might cause the LLM to fixate on the genres mentioned, inadvertently producing undesired results. On the other hand, a positively-framed prompt like, \"Recommend family-friendly movies or romantic comedies\" provides clear guidance on the desired output.</td>\n",
       "      <td id=\"T_a30fe_row4_col3\" class=\"data row4 col3\" >validmind.prompt_validation.NegativeInstruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row5_col0\" class=\"data row5 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_a30fe_row5_col1\" class=\"data row5 col1\" >Conciseness</td>\n",
       "      <td id=\"T_a30fe_row5_col2\" class=\"data row5 col2\" >**Purpose:** The Conciseness Assessment is designed to evaluate the brevity and succinctness of prompts provided to a Language Learning Model (LLM). A concise prompt strikes a balance between offering clear instructions and eliminating redundant or unnecessary information, ensuring that the LLM receives relevant input without being overwhelmed.\n",
       "\n",
       "**Test Mechanism:** Using an LLM, this test puts input prompts through a conciseness analysis where it's graded on a scale from 1 to 10. The grade reflects how well the prompt maintains clarity while avoiding verbosity. Prompts that achieve a grade equal to or surpassing a predefined threshold (default set to 7) are considered successful in being concise. This threshold can be adjusted based on specific requirements.\n",
       "\n",
       "**Why Conciseness Matters:** While detailed prompts can guide an LLM towards accurate results, excessive details can clutter the instruction and potentially lead to undesired outputs. Concise prompts are straightforward, reducing ambiguity and focusing the LLM's attention on the primary task. This is especially important considering there are limitations to the length of prompts that can be fed to an LLM.\n",
       "\n",
       "**Example:** For an LLM tasked with summarizing a document, a verbose prompt might introduce unnecessary constraints or biases. A concise, effective prompt like, \"Provide a brief summary highlighting the main points of the document\" ensures that the LLM captures the essence of the content without being sidetracked.</td>\n",
       "      <td id=\"T_a30fe_row5_col3\" class=\"data row5 col3\" >validmind.prompt_validation.Conciseness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row6_col0\" class=\"data row6 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_a30fe_row6_col1\" class=\"data row6 col1\" >Delimitation</td>\n",
       "      <td id=\"T_a30fe_row6_col2\" class=\"data row6 col2\" >**Purpose:** The Delimitation Test ensures that prompts provided to the Language Learning Model (LLM) use delimiters correctly to distinctly mark sections of the input. Properly delimited prompts simplify the LLM's interpretation process, ensuring accurate and precise responses.\n",
       "\n",
       "**Test Mechanism:** Using an LLM, prompts are checked for their appropriate use of delimiters such as triple quotation marks, XML tags, and section titles. Each prompt receives a score from 1 to 10 based on its delimitation integrity. Prompts scoring at or above a set threshold (default is 7) pass the check. This threshold can be modified as needed.\n",
       "\n",
       "**Why Proper Delimitation Matters:** Delimiters play a crucial role in segmenting and organizing prompts, especially when diverse data or multiple tasks are involved. They help in clearly distinguishing between different parts of the input, reducing ambiguity for the LLM. As task complexity increases, the correct use of delimiters becomes even more critical to ensure the LLM understands the prompt's intent.\n",
       "\n",
       "**Example:** When given a prompt like:\n",
       "\n",
       "```USER: Summarize the text delimited by triple quotes. '''insert text here'''```\n",
       "\n",
       "or:\n",
       "\n",
       "```USER: <article> insert first article here </article> <article> insert second article here </article>```\n",
       "\n",
       "The LLM can more accurately discern sections of the text to be treated differently, thanks to the clear delimitation.</td>\n",
       "      <td id=\"T_a30fe_row6_col3\" class=\"data row6 col3\" >validmind.prompt_validation.Delimitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row7_col0\" class=\"data row7 col0\" >Metric</td>\n",
       "      <td id=\"T_a30fe_row7_col1\" class=\"data row7 col1\" >Model Metadata</td>\n",
       "      <td id=\"T_a30fe_row7_col2\" class=\"data row7 col2\" >This section describes attributes of the selected model such as its modeling technique, training parameters, and task type. This helps understand the model's capabilities and limitations in the context of a modeling framework.</td>\n",
       "      <td id=\"T_a30fe_row7_col3\" class=\"data row7 col3\" >validmind.model_validation.ModelMetadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row8_col0\" class=\"data row8 col0\" >Metric</td>\n",
       "      <td id=\"T_a30fe_row8_col1\" class=\"data row8 col1\" >Dataset Description</td>\n",
       "      <td id=\"T_a30fe_row8_col2\" class=\"data row8 col2\" >Collects a set of descriptive statistics for a dataset</td>\n",
       "      <td id=\"T_a30fe_row8_col3\" class=\"data row8 col3\" >validmind.data_validation.DatasetDescription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row9_col0\" class=\"data row9 col0\" >Metric</td>\n",
       "      <td id=\"T_a30fe_row9_col1\" class=\"data row9 col1\" >Dataset Split</td>\n",
       "      <td id=\"T_a30fe_row9_col2\" class=\"data row9 col2\" >This section shows the size of the dataset split into training, test (and validation) sets where applicable. The size of each dataset is shown in absolute terms and as a proportion of the total dataset size.\n",
       "\n",
       "The dataset split is important to understand because it can affect the performance of the model. For example, if the training set is too small, the model may not be able to learn the patterns in the data and will perform poorly on the test set. On the other hand, if the test set is too small, the model may not be able to generalize well to unseen data and will perform poorly on the validation set.</td>\n",
       "      <td id=\"T_a30fe_row9_col3\" class=\"data row9 col3\" >validmind.data_validation.DatasetSplit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row10_col0\" class=\"data row10 col0\" >DatasetMetadata</td>\n",
       "      <td id=\"T_a30fe_row10_col1\" class=\"data row10 col1\" >Dataset Metadata</td>\n",
       "      <td id=\"T_a30fe_row10_col2\" class=\"data row10 col2\" >Custom class to collect a set of descriptive statistics for a dataset. This class will log dataset metadata via `log_dataset` instead of a metric. Dataset metadata is necessary to initialize dataset object that can be related to different metrics and test results</td>\n",
       "      <td id=\"T_a30fe_row10_col3\" class=\"data row10 col3\" >validmind.data_validation.DatasetMetadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row11_col0\" class=\"data row11 col0\" >Metric</td>\n",
       "      <td id=\"T_a30fe_row11_col1\" class=\"data row11 col1\" >Punctuations</td>\n",
       "      <td id=\"T_a30fe_row11_col2\" class=\"data row11 col2\" >Metric that analyses the frequencies of punctuations in a given text dataset</td>\n",
       "      <td id=\"T_a30fe_row11_col3\" class=\"data row11 col3\" >validmind.data_validation.nlp.Punctuations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row12_col0\" class=\"data row12 col0\" >Metric</td>\n",
       "      <td id=\"T_a30fe_row12_col1\" class=\"data row12 col1\" >Common Words</td>\n",
       "      <td id=\"T_a30fe_row12_col2\" class=\"data row12 col2\" >The purpose of the common words test is to analyze a dataset and identify the most common words within a specified text column. This test allows users to understand the prevalent words within the dataset's text column and gain insights into the dataset's language patterns.</td>\n",
       "      <td id=\"T_a30fe_row12_col3\" class=\"data row12 col3\" >validmind.data_validation.nlp.CommonWords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row13_col0\" class=\"data row13 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_a30fe_row13_col1\" class=\"data row13 col1\" >Hashtags</td>\n",
       "      <td id=\"T_a30fe_row13_col2\" class=\"data row13 col2\" >The Hashtags test analyzes the dataset by extracting the text column and applying a regular expression pattern to identify hashtags within the text. It then counts the occurrences of each hashtag and selects the top hashtags based on a specified parameter or the default value. The results are visualized using a bar plot, where the x-axis represents the hashtags and the y-axis represents their frequency counts. It aims to identify the most commonly used hashtags in a given text column and provide visual representation of their frequencies.</td>\n",
       "      <td id=\"T_a30fe_row13_col3\" class=\"data row13 col3\" >validmind.data_validation.nlp.Hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row14_col0\" class=\"data row14 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_a30fe_row14_col1\" class=\"data row14 col1\" >Mentions</td>\n",
       "      <td id=\"T_a30fe_row14_col2\" class=\"data row14 col2\" >The purpose of the Mentions test is to perform a data quality test focused on analyzing mentions within a dataset. It aims to identify the most frequently mentioned entities or usernames in a given text column and provides a visual representation of the results using a treemap. The Mentions test analyzes the dataset by extracting the text column and applying a regular expression pattern to identify mentions (text preceded by '@') within the text. It then counts the occurrences of each mention and selects the top mentions based on a specified parameter or the default value. The results are visualized using a treemap plot, where the size of each rectangle represents the frequency of the mention.</td>\n",
       "      <td id=\"T_a30fe_row14_col3\" class=\"data row14 col3\" >validmind.data_validation.nlp.Mentions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a30fe_row15_col0\" class=\"data row15 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_a30fe_row15_col1\" class=\"data row15 col1\" >Stop Words</td>\n",
       "      <td id=\"T_a30fe_row15_col2\" class=\"data row15 col2\" >The purpose of the StopWords test is to perform a data quality test focused on identifying and analyzing the usage of stop words within a dataset. Stop words are commonly used words in a language (e.g., \"the\", \"and\", \"is\") that are often considered insignificant for analysis. The StopWords test analyzes the dataset by creating a corpus of words from the specified text column. It then determines the frequency of each stop word in the corpus and calculates the percentage of each stop word in relation to the total number of words. The test results focus on identifying the top stop words based on their percentage in the corpus.</td>\n",
       "      <td id=\"T_a30fe_row15_col3\" class=\"data row15 col3\" >validmind.data_validation.nlp.StopWords</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c5cda9a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tests(task=\"text_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9df6d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9df6d_row0_col0, #T_9df6d_row0_col1, #T_9df6d_row0_col2, #T_9df6d_row0_col3, #T_9df6d_row1_col0, #T_9df6d_row1_col1, #T_9df6d_row1_col2, #T_9df6d_row1_col3, #T_9df6d_row2_col0, #T_9df6d_row2_col1, #T_9df6d_row2_col2, #T_9df6d_row2_col3, #T_9df6d_row3_col0, #T_9df6d_row3_col1, #T_9df6d_row3_col2, #T_9df6d_row3_col3, #T_9df6d_row4_col0, #T_9df6d_row4_col1, #T_9df6d_row4_col2, #T_9df6d_row4_col3, #T_9df6d_row5_col0, #T_9df6d_row5_col1, #T_9df6d_row5_col2, #T_9df6d_row5_col3, #T_9df6d_row6_col0, #T_9df6d_row6_col1, #T_9df6d_row6_col2, #T_9df6d_row6_col3, #T_9df6d_row7_col0, #T_9df6d_row7_col1, #T_9df6d_row7_col2, #T_9df6d_row7_col3, #T_9df6d_row8_col0, #T_9df6d_row8_col1, #T_9df6d_row8_col2, #T_9df6d_row8_col3, #T_9df6d_row9_col0, #T_9df6d_row9_col1, #T_9df6d_row9_col2, #T_9df6d_row9_col3, #T_9df6d_row10_col0, #T_9df6d_row10_col1, #T_9df6d_row10_col2, #T_9df6d_row10_col3, #T_9df6d_row11_col0, #T_9df6d_row11_col1, #T_9df6d_row11_col2, #T_9df6d_row11_col3, #T_9df6d_row12_col0, #T_9df6d_row12_col1, #T_9df6d_row12_col2, #T_9df6d_row12_col3, #T_9df6d_row13_col0, #T_9df6d_row13_col1, #T_9df6d_row13_col2, #T_9df6d_row13_col3, #T_9df6d_row14_col0, #T_9df6d_row14_col1, #T_9df6d_row14_col2, #T_9df6d_row14_col3, #T_9df6d_row15_col0, #T_9df6d_row15_col1, #T_9df6d_row15_col2, #T_9df6d_row15_col3, #T_9df6d_row16_col0, #T_9df6d_row16_col1, #T_9df6d_row16_col2, #T_9df6d_row16_col3, #T_9df6d_row17_col0, #T_9df6d_row17_col1, #T_9df6d_row17_col2, #T_9df6d_row17_col3, #T_9df6d_row18_col0, #T_9df6d_row18_col1, #T_9df6d_row18_col2, #T_9df6d_row18_col3, #T_9df6d_row19_col0, #T_9df6d_row19_col1, #T_9df6d_row19_col2, #T_9df6d_row19_col3, #T_9df6d_row20_col0, #T_9df6d_row20_col1, #T_9df6d_row20_col2, #T_9df6d_row20_col3, #T_9df6d_row21_col0, #T_9df6d_row21_col1, #T_9df6d_row21_col2, #T_9df6d_row21_col3, #T_9df6d_row22_col0, #T_9df6d_row22_col1, #T_9df6d_row22_col2, #T_9df6d_row22_col3, #T_9df6d_row23_col0, #T_9df6d_row23_col1, #T_9df6d_row23_col2, #T_9df6d_row23_col3, #T_9df6d_row24_col0, #T_9df6d_row24_col1, #T_9df6d_row24_col2, #T_9df6d_row24_col3, #T_9df6d_row25_col0, #T_9df6d_row25_col1, #T_9df6d_row25_col2, #T_9df6d_row25_col3, #T_9df6d_row26_col0, #T_9df6d_row26_col1, #T_9df6d_row26_col2, #T_9df6d_row26_col3, #T_9df6d_row27_col0, #T_9df6d_row27_col1, #T_9df6d_row27_col2, #T_9df6d_row27_col3, #T_9df6d_row28_col0, #T_9df6d_row28_col1, #T_9df6d_row28_col2, #T_9df6d_row28_col3, #T_9df6d_row29_col0, #T_9df6d_row29_col1, #T_9df6d_row29_col2, #T_9df6d_row29_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9df6d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_9df6d_level0_col0\" class=\"col_heading level0 col0\" >Test Type</th>\n",
       "      <th id=\"T_9df6d_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_9df6d_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_9df6d_level0_col3\" class=\"col_heading level0 col3\" >ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row0_col0\" class=\"data row0 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row0_col1\" class=\"data row0 col1\" >Zivot Andrews Arch</td>\n",
       "      <td id=\"T_9df6d_row0_col2\" class=\"data row0 col2\" >Zivot-Andrews unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_9df6d_row0_col3\" class=\"data row0 col3\" >validmind.model_validation.statsmodels.ZivotAndrewsArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row1_col0\" class=\"data row1 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row1_col1\" class=\"data row1 col1\" >Rolling Stats Plot</td>\n",
       "      <td id=\"T_9df6d_row1_col2\" class=\"data row1 col2\" >This class provides a metric to visualize the stationarity of a given time series dataset by plotting the rolling mean and rolling standard deviation. The rolling mean represents the average of the time series data over a fixed-size sliding window, which helps in identifying trends in the data. The rolling standard deviation measures the variability of the data within the sliding window, showing any changes in volatility over time. By analyzing these plots, users can gain insights into the stationarity of the time series data and determine if any transformations or differencing operations are required before applying time series models.</td>\n",
       "      <td id=\"T_9df6d_row1_col3\" class=\"data row1 col3\" >validmind.data_validation.RollingStatsPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row2_col0\" class=\"data row2 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_9df6d_row2_col1\" class=\"data row2 col1\" >Time Series Outliers</td>\n",
       "      <td id=\"T_9df6d_row2_col2\" class=\"data row2 col2\" >Test that find outliers for time series data using the z-score method</td>\n",
       "      <td id=\"T_9df6d_row2_col3\" class=\"data row2 col3\" >validmind.data_validation.TimeSeriesOutliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row3_col0\" class=\"data row3 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row3_col1\" class=\"data row3 col1\" >Engle Granger Coint</td>\n",
       "      <td id=\"T_9df6d_row3_col2\" class=\"data row3 col2\" >Test for cointegration between pairs of time series variables in a given dataset using the Engle-Granger test.</td>\n",
       "      <td id=\"T_9df6d_row3_col3\" class=\"data row3 col3\" >validmind.data_validation.EngleGrangerCoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row4_col0\" class=\"data row4 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row4_col1\" class=\"data row4 col1\" >Seasonal Decompose</td>\n",
       "      <td id=\"T_9df6d_row4_col2\" class=\"data row4 col2\" >Calculates seasonal_decompose metric for each of the dataset features</td>\n",
       "      <td id=\"T_9df6d_row4_col3\" class=\"data row4 col3\" >validmind.data_validation.SeasonalDecompose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row5_col0\" class=\"data row5 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row5_col1\" class=\"data row5 col1\" >Time Series Histogram</td>\n",
       "      <td id=\"T_9df6d_row5_col2\" class=\"data row5 col2\" >Generates a visual analysis of time series data by plotting the histogram. The input dataset can have multiple time series if necessary. In this case we produce a separate plot for each time series.</td>\n",
       "      <td id=\"T_9df6d_row5_col3\" class=\"data row5 col3\" >validmind.data_validation.TimeSeriesHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row6_col0\" class=\"data row6 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_9df6d_row6_col1\" class=\"data row6 col1\" >Time Series Frequency</td>\n",
       "      <td id=\"T_9df6d_row6_col2\" class=\"data row6 col2\" >Test that detects frequencies in the data</td>\n",
       "      <td id=\"T_9df6d_row6_col3\" class=\"data row6 col3\" >validmind.data_validation.TimeSeriesFrequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row7_col0\" class=\"data row7 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row7_col1\" class=\"data row7 col1\" >AC Fand PACF Plot</td>\n",
       "      <td id=\"T_9df6d_row7_col2\" class=\"data row7 col2\" >Plots ACF and PACF for a given time series dataset.</td>\n",
       "      <td id=\"T_9df6d_row7_col3\" class=\"data row7 col3\" >validmind.data_validation.ACFandPACFPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row8_col0\" class=\"data row8 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row8_col1\" class=\"data row8 col1\" >Auto Stationarity</td>\n",
       "      <td id=\"T_9df6d_row8_col2\" class=\"data row8 col2\" >Automatically detects stationarity for each time series in a DataFrame using the Augmented Dickey-Fuller (ADF) test.</td>\n",
       "      <td id=\"T_9df6d_row8_col3\" class=\"data row8 col3\" >validmind.data_validation.AutoStationarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row9_col0\" class=\"data row9 col0\" >DatasetMetadata</td>\n",
       "      <td id=\"T_9df6d_row9_col1\" class=\"data row9 col1\" >Dataset Metadata</td>\n",
       "      <td id=\"T_9df6d_row9_col2\" class=\"data row9 col2\" >Custom class to collect a set of descriptive statistics for a dataset. This class will log dataset metadata via `log_dataset` instead of a metric. Dataset metadata is necessary to initialize dataset object that can be related to different metrics and test results</td>\n",
       "      <td id=\"T_9df6d_row9_col3\" class=\"data row9 col3\" >validmind.data_validation.DatasetMetadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row10_col0\" class=\"data row10 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row10_col1\" class=\"data row10 col1\" >Auto MA</td>\n",
       "      <td id=\"T_9df6d_row10_col2\" class=\"data row10 col2\" >Automatically detects the MA order of a time series using both BIC and AIC.</td>\n",
       "      <td id=\"T_9df6d_row10_col3\" class=\"data row10 col3\" >validmind.data_validation.AutoMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row11_col0\" class=\"data row11 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row11_col1\" class=\"data row11 col1\" >Auto Seasonality</td>\n",
       "      <td id=\"T_9df6d_row11_col2\" class=\"data row11 col2\" >Automatically detects the optimal seasonal order for a time series dataset using the seasonal_decompose method.</td>\n",
       "      <td id=\"T_9df6d_row11_col3\" class=\"data row11 col3\" >validmind.data_validation.AutoSeasonality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row12_col0\" class=\"data row12 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row12_col1\" class=\"data row12 col1\" >Phillips Perron Arch</td>\n",
       "      <td id=\"T_9df6d_row12_col2\" class=\"data row12 col2\" >Phillips-Perron (PP) unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_9df6d_row12_col3\" class=\"data row12 col3\" >validmind.model_validation.statsmodels.PhillipsPerronArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row13_col0\" class=\"data row13 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row13_col1\" class=\"data row13 col1\" >Descriptive Statistics</td>\n",
       "      <td id=\"T_9df6d_row13_col2\" class=\"data row13 col2\" >This section provides descriptive statistics for numerical and categorical variables found in the dataset.</td>\n",
       "      <td id=\"T_9df6d_row13_col3\" class=\"data row13 col3\" >validmind.data_validation.DescriptiveStatistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row14_col0\" class=\"data row14 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_9df6d_row14_col1\" class=\"data row14 col1\" >Time Series Missing Values</td>\n",
       "      <td id=\"T_9df6d_row14_col2\" class=\"data row14 col2\" >Test that the number of missing values is less than a threshold</td>\n",
       "      <td id=\"T_9df6d_row14_col3\" class=\"data row14 col3\" >validmind.data_validation.TimeSeriesMissingValues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row15_col0\" class=\"data row15 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_9df6d_row15_col1\" class=\"data row15 col1\" >ADF Test</td>\n",
       "      <td id=\"T_9df6d_row15_col2\" class=\"data row15 col2\" >Augmented Dickey-Fuller Metric for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_9df6d_row15_col3\" class=\"data row15 col3\" >validmind.model_validation.statsmodels.ADFTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row16_col0\" class=\"data row16 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row16_col1\" class=\"data row16 col1\" >L Jung Box</td>\n",
       "      <td id=\"T_9df6d_row16_col2\" class=\"data row16 col2\" >The Ljung-Box test is a statistical test used to determine whether a given set of data has autocorrelations that are different from zero.</td>\n",
       "      <td id=\"T_9df6d_row16_col3\" class=\"data row16 col3\" >validmind.model_validation.statsmodels.LJungBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row17_col0\" class=\"data row17 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row17_col1\" class=\"data row17 col1\" >KPSS</td>\n",
       "      <td id=\"T_9df6d_row17_col2\" class=\"data row17 col2\" >Kwiatkowski-Phillips-Schmidt-Shin (KPSS) unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_9df6d_row17_col3\" class=\"data row17 col3\" >validmind.model_validation.statsmodels.KPSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row18_col0\" class=\"data row18 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row18_col1\" class=\"data row18 col1\" >Box Pierce</td>\n",
       "      <td id=\"T_9df6d_row18_col2\" class=\"data row18 col2\" >The Box-Pierce test is a statistical test used to determine whether a given set of data has autocorrelations that are different from zero.</td>\n",
       "      <td id=\"T_9df6d_row18_col3\" class=\"data row18 col3\" >validmind.model_validation.statsmodels.BoxPierce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row19_col0\" class=\"data row19 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row19_col1\" class=\"data row19 col1\" >Spread Plot</td>\n",
       "      <td id=\"T_9df6d_row19_col2\" class=\"data row19 col2\" >This class provides a metric to visualize the spread between pairs of time series variables in a given dataset. By plotting the spread of each pair of variables in separate figures, users can assess the relationship between the variables and determine if any cointegration or other time series relationships exist between them.</td>\n",
       "      <td id=\"T_9df6d_row19_col3\" class=\"data row19 col3\" >validmind.data_validation.SpreadPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row20_col0\" class=\"data row20 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row20_col1\" class=\"data row20 col1\" >Dataset Description</td>\n",
       "      <td id=\"T_9df6d_row20_col2\" class=\"data row20 col2\" >Collects a set of descriptive statistics for a dataset</td>\n",
       "      <td id=\"T_9df6d_row20_col3\" class=\"data row20 col3\" >validmind.data_validation.DatasetDescription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row21_col0\" class=\"data row21 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row21_col1\" class=\"data row21 col1\" >Auto AR</td>\n",
       "      <td id=\"T_9df6d_row21_col2\" class=\"data row21 col2\" >Automatically detects the AR order of a time series using both BIC and AIC.</td>\n",
       "      <td id=\"T_9df6d_row21_col3\" class=\"data row21 col3\" >validmind.data_validation.AutoAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row22_col0\" class=\"data row22 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row22_col1\" class=\"data row22 col1\" >Time Series Line Plot</td>\n",
       "      <td id=\"T_9df6d_row22_col2\" class=\"data row22 col2\" >Generates a visual analysis of time series data by plotting the raw time series. The input dataset can have multiple time series if necessary. In this case we produce a separate plot for each time series.</td>\n",
       "      <td id=\"T_9df6d_row22_col3\" class=\"data row22 col3\" >validmind.data_validation.TimeSeriesLinePlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row23_col0\" class=\"data row23 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row23_col1\" class=\"data row23 col1\" >DFGLS Arch</td>\n",
       "      <td id=\"T_9df6d_row23_col2\" class=\"data row23 col2\" >Dickey-Fuller GLS unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_9df6d_row23_col3\" class=\"data row23 col3\" >validmind.model_validation.statsmodels.DFGLSArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row24_col0\" class=\"data row24 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row24_col1\" class=\"data row24 col1\" >Dataset Split</td>\n",
       "      <td id=\"T_9df6d_row24_col2\" class=\"data row24 col2\" >This section shows the size of the dataset split into training, test (and validation) sets where applicable. The size of each dataset is shown in absolute terms and as a proportion of the total dataset size.\n",
       "\n",
       "The dataset split is important to understand because it can affect the performance of the model. For example, if the training set is too small, the model may not be able to learn the patterns in the data and will perform poorly on the test set. On the other hand, if the test set is too small, the model may not be able to generalize well to unseen data and will perform poorly on the validation set.</td>\n",
       "      <td id=\"T_9df6d_row24_col3\" class=\"data row24 col3\" >validmind.data_validation.DatasetSplit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row25_col0\" class=\"data row25 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row25_col1\" class=\"data row25 col1\" >Durbin Watson Test</td>\n",
       "      <td id=\"T_9df6d_row25_col2\" class=\"data row25 col2\" >The Durbin-Watson Metric is a statistical test that can be used to detect autocorrelation in a time series.</td>\n",
       "      <td id=\"T_9df6d_row25_col3\" class=\"data row25 col3\" >validmind.model_validation.statsmodels.DurbinWatsonTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row26_col0\" class=\"data row26 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row26_col1\" class=\"data row26 col1\" >Dataset Correlations</td>\n",
       "      <td id=\"T_9df6d_row26_col2\" class=\"data row26 col2\" >Extracts the correlation matrix for a dataset. The following coefficients are calculated:\n",
       "- Pearson's R for numerical variables\n",
       "- Cramer's V for categorical variables\n",
       "- Correlation ratios for categorical-numerical variables</td>\n",
       "      <td id=\"T_9df6d_row26_col3\" class=\"data row26 col3\" >validmind.data_validation.DatasetCorrelations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row27_col0\" class=\"data row27 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row27_col1\" class=\"data row27 col1\" >ADF</td>\n",
       "      <td id=\"T_9df6d_row27_col2\" class=\"data row27 col2\" >Augmented Dickey-Fuller unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_9df6d_row27_col3\" class=\"data row27 col3\" >validmind.model_validation.statsmodels.ADF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row28_col0\" class=\"data row28 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row28_col1\" class=\"data row28 col1\" >Lagged Correlation Heatmap</td>\n",
       "      <td id=\"T_9df6d_row28_col2\" class=\"data row28 col2\" >Generates a heatmap of correlations between the target variable and the lags of independent variables in the dataset.</td>\n",
       "      <td id=\"T_9df6d_row28_col3\" class=\"data row28 col3\" >validmind.data_validation.LaggedCorrelationHeatmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_9df6d_row29_col0\" class=\"data row29 col0\" >Metric</td>\n",
       "      <td id=\"T_9df6d_row29_col1\" class=\"data row29 col1\" >Auto ARIMA</td>\n",
       "      <td id=\"T_9df6d_row29_col2\" class=\"data row29 col2\" >Automatically fits multiple ARIMA models for each variable and ranks them by BIC and AIC.</td>\n",
       "      <td id=\"T_9df6d_row29_col3\" class=\"data row29 col3\" >validmind.model_validation.statsmodels.AutoARIMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c5ca7820>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tests(filter=\"timeseries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_664ed th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_664ed_row0_col0, #T_664ed_row0_col1, #T_664ed_row0_col2, #T_664ed_row0_col3, #T_664ed_row1_col0, #T_664ed_row1_col1, #T_664ed_row1_col2, #T_664ed_row1_col3, #T_664ed_row2_col0, #T_664ed_row2_col1, #T_664ed_row2_col2, #T_664ed_row2_col3, #T_664ed_row3_col0, #T_664ed_row3_col1, #T_664ed_row3_col2, #T_664ed_row3_col3, #T_664ed_row4_col0, #T_664ed_row4_col1, #T_664ed_row4_col2, #T_664ed_row4_col3, #T_664ed_row5_col0, #T_664ed_row5_col1, #T_664ed_row5_col2, #T_664ed_row5_col3, #T_664ed_row6_col0, #T_664ed_row6_col1, #T_664ed_row6_col2, #T_664ed_row6_col3, #T_664ed_row7_col0, #T_664ed_row7_col1, #T_664ed_row7_col2, #T_664ed_row7_col3, #T_664ed_row8_col0, #T_664ed_row8_col1, #T_664ed_row8_col2, #T_664ed_row8_col3, #T_664ed_row9_col0, #T_664ed_row9_col1, #T_664ed_row9_col2, #T_664ed_row9_col3, #T_664ed_row10_col0, #T_664ed_row10_col1, #T_664ed_row10_col2, #T_664ed_row10_col3, #T_664ed_row11_col0, #T_664ed_row11_col1, #T_664ed_row11_col2, #T_664ed_row11_col3, #T_664ed_row12_col0, #T_664ed_row12_col1, #T_664ed_row12_col2, #T_664ed_row12_col3, #T_664ed_row13_col0, #T_664ed_row13_col1, #T_664ed_row13_col2, #T_664ed_row13_col3, #T_664ed_row14_col0, #T_664ed_row14_col1, #T_664ed_row14_col2, #T_664ed_row14_col3, #T_664ed_row15_col0, #T_664ed_row15_col1, #T_664ed_row15_col2, #T_664ed_row15_col3, #T_664ed_row16_col0, #T_664ed_row16_col1, #T_664ed_row16_col2, #T_664ed_row16_col3, #T_664ed_row17_col0, #T_664ed_row17_col1, #T_664ed_row17_col2, #T_664ed_row17_col3, #T_664ed_row18_col0, #T_664ed_row18_col1, #T_664ed_row18_col2, #T_664ed_row18_col3, #T_664ed_row19_col0, #T_664ed_row19_col1, #T_664ed_row19_col2, #T_664ed_row19_col3, #T_664ed_row20_col0, #T_664ed_row20_col1, #T_664ed_row20_col2, #T_664ed_row20_col3, #T_664ed_row21_col0, #T_664ed_row21_col1, #T_664ed_row21_col2, #T_664ed_row21_col3, #T_664ed_row22_col0, #T_664ed_row22_col1, #T_664ed_row22_col2, #T_664ed_row22_col3, #T_664ed_row23_col0, #T_664ed_row23_col1, #T_664ed_row23_col2, #T_664ed_row23_col3, #T_664ed_row24_col0, #T_664ed_row24_col1, #T_664ed_row24_col2, #T_664ed_row24_col3, #T_664ed_row25_col0, #T_664ed_row25_col1, #T_664ed_row25_col2, #T_664ed_row25_col3, #T_664ed_row26_col0, #T_664ed_row26_col1, #T_664ed_row26_col2, #T_664ed_row26_col3, #T_664ed_row27_col0, #T_664ed_row27_col1, #T_664ed_row27_col2, #T_664ed_row27_col3, #T_664ed_row28_col0, #T_664ed_row28_col1, #T_664ed_row28_col2, #T_664ed_row28_col3, #T_664ed_row29_col0, #T_664ed_row29_col1, #T_664ed_row29_col2, #T_664ed_row29_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_664ed\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_664ed_level0_col0\" class=\"col_heading level0 col0\" >Test Type</th>\n",
       "      <th id=\"T_664ed_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_664ed_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_664ed_level0_col3\" class=\"col_heading level0 col3\" >ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row0_col0\" class=\"data row0 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row0_col1\" class=\"data row0 col1\" >Zivot Andrews Arch</td>\n",
       "      <td id=\"T_664ed_row0_col2\" class=\"data row0 col2\" >Zivot-Andrews unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_664ed_row0_col3\" class=\"data row0 col3\" >validmind.model_validation.statsmodels.ZivotAndrewsArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row1_col0\" class=\"data row1 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row1_col1\" class=\"data row1 col1\" >Rolling Stats Plot</td>\n",
       "      <td id=\"T_664ed_row1_col2\" class=\"data row1 col2\" >This class provides a metric to visualize the stationarity of a given time series dataset by plotting the rolling mean and rolling standard deviation. The rolling mean represents the average of the time series data over a fixed-size sliding window, which helps in identifying trends in the data. The rolling standard deviation measures the variability of the data within the sliding window, showing any changes in volatility over time. By analyzing these plots, users can gain insights into the stationarity of the time series data and determine if any transformations or differencing operations are required before applying time series models.</td>\n",
       "      <td id=\"T_664ed_row1_col3\" class=\"data row1 col3\" >validmind.data_validation.RollingStatsPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row2_col0\" class=\"data row2 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_664ed_row2_col1\" class=\"data row2 col1\" >Time Series Outliers</td>\n",
       "      <td id=\"T_664ed_row2_col2\" class=\"data row2 col2\" >Test that find outliers for time series data using the z-score method</td>\n",
       "      <td id=\"T_664ed_row2_col3\" class=\"data row2 col3\" >validmind.data_validation.TimeSeriesOutliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row3_col0\" class=\"data row3 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row3_col1\" class=\"data row3 col1\" >Engle Granger Coint</td>\n",
       "      <td id=\"T_664ed_row3_col2\" class=\"data row3 col2\" >Test for cointegration between pairs of time series variables in a given dataset using the Engle-Granger test.</td>\n",
       "      <td id=\"T_664ed_row3_col3\" class=\"data row3 col3\" >validmind.data_validation.EngleGrangerCoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row4_col0\" class=\"data row4 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row4_col1\" class=\"data row4 col1\" >Seasonal Decompose</td>\n",
       "      <td id=\"T_664ed_row4_col2\" class=\"data row4 col2\" >Calculates seasonal_decompose metric for each of the dataset features</td>\n",
       "      <td id=\"T_664ed_row4_col3\" class=\"data row4 col3\" >validmind.data_validation.SeasonalDecompose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row5_col0\" class=\"data row5 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row5_col1\" class=\"data row5 col1\" >Time Series Histogram</td>\n",
       "      <td id=\"T_664ed_row5_col2\" class=\"data row5 col2\" >Generates a visual analysis of time series data by plotting the histogram. The input dataset can have multiple time series if necessary. In this case we produce a separate plot for each time series.</td>\n",
       "      <td id=\"T_664ed_row5_col3\" class=\"data row5 col3\" >validmind.data_validation.TimeSeriesHistogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row6_col0\" class=\"data row6 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_664ed_row6_col1\" class=\"data row6 col1\" >Time Series Frequency</td>\n",
       "      <td id=\"T_664ed_row6_col2\" class=\"data row6 col2\" >Test that detects frequencies in the data</td>\n",
       "      <td id=\"T_664ed_row6_col3\" class=\"data row6 col3\" >validmind.data_validation.TimeSeriesFrequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row7_col0\" class=\"data row7 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row7_col1\" class=\"data row7 col1\" >AC Fand PACF Plot</td>\n",
       "      <td id=\"T_664ed_row7_col2\" class=\"data row7 col2\" >Plots ACF and PACF for a given time series dataset.</td>\n",
       "      <td id=\"T_664ed_row7_col3\" class=\"data row7 col3\" >validmind.data_validation.ACFandPACFPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row8_col0\" class=\"data row8 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row8_col1\" class=\"data row8 col1\" >Auto Stationarity</td>\n",
       "      <td id=\"T_664ed_row8_col2\" class=\"data row8 col2\" >Automatically detects stationarity for each time series in a DataFrame using the Augmented Dickey-Fuller (ADF) test.</td>\n",
       "      <td id=\"T_664ed_row8_col3\" class=\"data row8 col3\" >validmind.data_validation.AutoStationarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row9_col0\" class=\"data row9 col0\" >DatasetMetadata</td>\n",
       "      <td id=\"T_664ed_row9_col1\" class=\"data row9 col1\" >Dataset Metadata</td>\n",
       "      <td id=\"T_664ed_row9_col2\" class=\"data row9 col2\" >Custom class to collect a set of descriptive statistics for a dataset. This class will log dataset metadata via `log_dataset` instead of a metric. Dataset metadata is necessary to initialize dataset object that can be related to different metrics and test results</td>\n",
       "      <td id=\"T_664ed_row9_col3\" class=\"data row9 col3\" >validmind.data_validation.DatasetMetadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row10_col0\" class=\"data row10 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row10_col1\" class=\"data row10 col1\" >Auto MA</td>\n",
       "      <td id=\"T_664ed_row10_col2\" class=\"data row10 col2\" >Automatically detects the MA order of a time series using both BIC and AIC.</td>\n",
       "      <td id=\"T_664ed_row10_col3\" class=\"data row10 col3\" >validmind.data_validation.AutoMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row11_col0\" class=\"data row11 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row11_col1\" class=\"data row11 col1\" >Auto Seasonality</td>\n",
       "      <td id=\"T_664ed_row11_col2\" class=\"data row11 col2\" >Automatically detects the optimal seasonal order for a time series dataset using the seasonal_decompose method.</td>\n",
       "      <td id=\"T_664ed_row11_col3\" class=\"data row11 col3\" >validmind.data_validation.AutoSeasonality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row12_col0\" class=\"data row12 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row12_col1\" class=\"data row12 col1\" >Phillips Perron Arch</td>\n",
       "      <td id=\"T_664ed_row12_col2\" class=\"data row12 col2\" >Phillips-Perron (PP) unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_664ed_row12_col3\" class=\"data row12 col3\" >validmind.model_validation.statsmodels.PhillipsPerronArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row13_col0\" class=\"data row13 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row13_col1\" class=\"data row13 col1\" >Descriptive Statistics</td>\n",
       "      <td id=\"T_664ed_row13_col2\" class=\"data row13 col2\" >This section provides descriptive statistics for numerical and categorical variables found in the dataset.</td>\n",
       "      <td id=\"T_664ed_row13_col3\" class=\"data row13 col3\" >validmind.data_validation.DescriptiveStatistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row14_col0\" class=\"data row14 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_664ed_row14_col1\" class=\"data row14 col1\" >Time Series Missing Values</td>\n",
       "      <td id=\"T_664ed_row14_col2\" class=\"data row14 col2\" >Test that the number of missing values is less than a threshold</td>\n",
       "      <td id=\"T_664ed_row14_col3\" class=\"data row14 col3\" >validmind.data_validation.TimeSeriesMissingValues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row15_col0\" class=\"data row15 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_664ed_row15_col1\" class=\"data row15 col1\" >ADF Test</td>\n",
       "      <td id=\"T_664ed_row15_col2\" class=\"data row15 col2\" >Augmented Dickey-Fuller Metric for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_664ed_row15_col3\" class=\"data row15 col3\" >validmind.model_validation.statsmodels.ADFTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row16_col0\" class=\"data row16 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row16_col1\" class=\"data row16 col1\" >L Jung Box</td>\n",
       "      <td id=\"T_664ed_row16_col2\" class=\"data row16 col2\" >The Ljung-Box test is a statistical test used to determine whether a given set of data has autocorrelations that are different from zero.</td>\n",
       "      <td id=\"T_664ed_row16_col3\" class=\"data row16 col3\" >validmind.model_validation.statsmodels.LJungBox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row17_col0\" class=\"data row17 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row17_col1\" class=\"data row17 col1\" >KPSS</td>\n",
       "      <td id=\"T_664ed_row17_col2\" class=\"data row17 col2\" >Kwiatkowski-Phillips-Schmidt-Shin (KPSS) unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_664ed_row17_col3\" class=\"data row17 col3\" >validmind.model_validation.statsmodels.KPSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row18_col0\" class=\"data row18 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row18_col1\" class=\"data row18 col1\" >Box Pierce</td>\n",
       "      <td id=\"T_664ed_row18_col2\" class=\"data row18 col2\" >The Box-Pierce test is a statistical test used to determine whether a given set of data has autocorrelations that are different from zero.</td>\n",
       "      <td id=\"T_664ed_row18_col3\" class=\"data row18 col3\" >validmind.model_validation.statsmodels.BoxPierce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row19_col0\" class=\"data row19 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row19_col1\" class=\"data row19 col1\" >Spread Plot</td>\n",
       "      <td id=\"T_664ed_row19_col2\" class=\"data row19 col2\" >This class provides a metric to visualize the spread between pairs of time series variables in a given dataset. By plotting the spread of each pair of variables in separate figures, users can assess the relationship between the variables and determine if any cointegration or other time series relationships exist between them.</td>\n",
       "      <td id=\"T_664ed_row19_col3\" class=\"data row19 col3\" >validmind.data_validation.SpreadPlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row20_col0\" class=\"data row20 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row20_col1\" class=\"data row20 col1\" >Dataset Description</td>\n",
       "      <td id=\"T_664ed_row20_col2\" class=\"data row20 col2\" >Collects a set of descriptive statistics for a dataset</td>\n",
       "      <td id=\"T_664ed_row20_col3\" class=\"data row20 col3\" >validmind.data_validation.DatasetDescription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row21_col0\" class=\"data row21 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row21_col1\" class=\"data row21 col1\" >Auto AR</td>\n",
       "      <td id=\"T_664ed_row21_col2\" class=\"data row21 col2\" >Automatically detects the AR order of a time series using both BIC and AIC.</td>\n",
       "      <td id=\"T_664ed_row21_col3\" class=\"data row21 col3\" >validmind.data_validation.AutoAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row22_col0\" class=\"data row22 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row22_col1\" class=\"data row22 col1\" >Time Series Line Plot</td>\n",
       "      <td id=\"T_664ed_row22_col2\" class=\"data row22 col2\" >Generates a visual analysis of time series data by plotting the raw time series. The input dataset can have multiple time series if necessary. In this case we produce a separate plot for each time series.</td>\n",
       "      <td id=\"T_664ed_row22_col3\" class=\"data row22 col3\" >validmind.data_validation.TimeSeriesLinePlot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row23_col0\" class=\"data row23 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row23_col1\" class=\"data row23 col1\" >DFGLS Arch</td>\n",
       "      <td id=\"T_664ed_row23_col2\" class=\"data row23 col2\" >Dickey-Fuller GLS unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_664ed_row23_col3\" class=\"data row23 col3\" >validmind.model_validation.statsmodels.DFGLSArch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row24_col0\" class=\"data row24 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row24_col1\" class=\"data row24 col1\" >Dataset Split</td>\n",
       "      <td id=\"T_664ed_row24_col2\" class=\"data row24 col2\" >This section shows the size of the dataset split into training, test (and validation) sets where applicable. The size of each dataset is shown in absolute terms and as a proportion of the total dataset size.\n",
       "\n",
       "The dataset split is important to understand because it can affect the performance of the model. For example, if the training set is too small, the model may not be able to learn the patterns in the data and will perform poorly on the test set. On the other hand, if the test set is too small, the model may not be able to generalize well to unseen data and will perform poorly on the validation set.</td>\n",
       "      <td id=\"T_664ed_row24_col3\" class=\"data row24 col3\" >validmind.data_validation.DatasetSplit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row25_col0\" class=\"data row25 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row25_col1\" class=\"data row25 col1\" >Durbin Watson Test</td>\n",
       "      <td id=\"T_664ed_row25_col2\" class=\"data row25 col2\" >The Durbin-Watson Metric is a statistical test that can be used to detect autocorrelation in a time series.</td>\n",
       "      <td id=\"T_664ed_row25_col3\" class=\"data row25 col3\" >validmind.model_validation.statsmodels.DurbinWatsonTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row26_col0\" class=\"data row26 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row26_col1\" class=\"data row26 col1\" >Dataset Correlations</td>\n",
       "      <td id=\"T_664ed_row26_col2\" class=\"data row26 col2\" >Extracts the correlation matrix for a dataset. The following coefficients are calculated:\n",
       "- Pearson's R for numerical variables\n",
       "- Cramer's V for categorical variables\n",
       "- Correlation ratios for categorical-numerical variables</td>\n",
       "      <td id=\"T_664ed_row26_col3\" class=\"data row26 col3\" >validmind.data_validation.DatasetCorrelations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row27_col0\" class=\"data row27 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row27_col1\" class=\"data row27 col1\" >ADF</td>\n",
       "      <td id=\"T_664ed_row27_col2\" class=\"data row27 col2\" >Augmented Dickey-Fuller unit root test for establishing the order of integration of time series</td>\n",
       "      <td id=\"T_664ed_row27_col3\" class=\"data row27 col3\" >validmind.model_validation.statsmodels.ADF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row28_col0\" class=\"data row28 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row28_col1\" class=\"data row28 col1\" >Lagged Correlation Heatmap</td>\n",
       "      <td id=\"T_664ed_row28_col2\" class=\"data row28 col2\" >Generates a heatmap of correlations between the target variable and the lags of independent variables in the dataset.</td>\n",
       "      <td id=\"T_664ed_row28_col3\" class=\"data row28 col3\" >validmind.data_validation.LaggedCorrelationHeatmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_664ed_row29_col0\" class=\"data row29 col0\" >Metric</td>\n",
       "      <td id=\"T_664ed_row29_col1\" class=\"data row29 col1\" >Auto ARIMA</td>\n",
       "      <td id=\"T_664ed_row29_col2\" class=\"data row29 col2\" >Automatically fits multiple ARIMA models for each variable and ranks them by BIC and AIC.</td>\n",
       "      <td id=\"T_664ed_row29_col3\" class=\"data row29 col3\" >validmind.model_validation.statsmodels.AutoARIMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c5cda850>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tests(filter=\"regression\", tags=[\"time_series_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['validmind.prompt_validation.Bias',\n",
       " 'validmind.prompt_validation.Clarity',\n",
       " 'validmind.prompt_validation.Specificity',\n",
       " 'validmind.prompt_validation.Robustness',\n",
       " 'validmind.prompt_validation.NegativeInstruction',\n",
       " 'validmind.prompt_validation.Conciseness',\n",
       " 'validmind.prompt_validation.Delimitation',\n",
       " 'validmind.model_validation.ModelMetadata',\n",
       " 'validmind.model_validation.sklearn.ClassifierOutOfSamplePerformance',\n",
       " 'validmind.model_validation.sklearn.RobustnessDiagnosis',\n",
       " 'validmind.model_validation.sklearn.SHAPGlobalImportance',\n",
       " 'validmind.model_validation.sklearn.ConfusionMatrix',\n",
       " 'validmind.model_validation.sklearn.ClassifierInSamplePerformance',\n",
       " 'validmind.model_validation.sklearn.OverfitDiagnosis',\n",
       " 'validmind.model_validation.sklearn.PermutationFeatureImportance',\n",
       " 'validmind.model_validation.sklearn.MinimumROCAUCScore',\n",
       " 'validmind.model_validation.sklearn.PrecisionRecallCurve',\n",
       " 'validmind.model_validation.sklearn.ClassifierPerformance',\n",
       " 'validmind.model_validation.sklearn.MinimumF1Score',\n",
       " 'validmind.model_validation.sklearn.ROCCurve',\n",
       " 'validmind.model_validation.sklearn.TrainingTestDegradation',\n",
       " 'validmind.model_validation.sklearn.ModelsPerformanceComparison',\n",
       " 'validmind.model_validation.sklearn.WeakspotsDiagnosis',\n",
       " 'validmind.model_validation.sklearn.PopulationStabilityIndex',\n",
       " 'validmind.model_validation.sklearn.MinimumAccuracy',\n",
       " 'validmind.model_validation.statsmodels.RegressionModelsCoeffs',\n",
       " 'validmind.model_validation.statsmodels.BoxPierce',\n",
       " 'validmind.model_validation.statsmodels.RegressionCoeffsPlot',\n",
       " 'validmind.model_validation.statsmodels.RegressionModelSensitivityPlot',\n",
       " 'validmind.model_validation.statsmodels.RegressionModelsPerformance',\n",
       " 'validmind.model_validation.statsmodels.ZivotAndrewsArch',\n",
       " 'validmind.model_validation.statsmodels.RegressionModelOutsampleComparison',\n",
       " 'validmind.model_validation.statsmodels.RegressionModelForecastPlotLevels',\n",
       " 'validmind.model_validation.statsmodels.LogRegressionConfusionMatrix',\n",
       " 'validmind.model_validation.statsmodels.PDRatingClassPlot',\n",
       " 'validmind.model_validation.statsmodels.ScorecardHistogram',\n",
       " 'validmind.model_validation.statsmodels.FeatureImportanceAndSignificance',\n",
       " 'validmind.model_validation.statsmodels.LJungBox',\n",
       " 'validmind.model_validation.statsmodels.LogisticRegPredictionHistogram',\n",
       " 'validmind.model_validation.statsmodels.JarqueBera',\n",
       " 'validmind.model_validation.statsmodels.PhillipsPerronArch',\n",
       " 'validmind.model_validation.statsmodels.KolmogorovSmirnov',\n",
       " 'validmind.model_validation.statsmodels.ResidualsVisualInspection',\n",
       " 'validmind.model_validation.statsmodels.ShapiroWilk',\n",
       " 'validmind.model_validation.statsmodels.ScorecardBucketHistogram',\n",
       " 'validmind.model_validation.statsmodels.RegressionModelInsampleComparison',\n",
       " 'validmind.model_validation.statsmodels.RegressionFeatureSignificance',\n",
       " 'validmind.model_validation.statsmodels.RegressionModelSummary',\n",
       " 'validmind.model_validation.statsmodels.KPSS',\n",
       " 'validmind.model_validation.statsmodels.Lilliefors',\n",
       " 'validmind.model_validation.statsmodels.LogisticRegCumulativeProb',\n",
       " 'validmind.model_validation.statsmodels.RunsTest',\n",
       " 'validmind.model_validation.statsmodels.ScorecardProbabilitiesHistogram',\n",
       " 'validmind.model_validation.statsmodels.DFGLSArch',\n",
       " 'validmind.model_validation.statsmodels.AutoARIMA',\n",
       " 'validmind.model_validation.statsmodels.ADFTest',\n",
       " 'validmind.model_validation.statsmodels.GINITable',\n",
       " 'validmind.model_validation.statsmodels.RegressionModelForecastPlot',\n",
       " 'validmind.model_validation.statsmodels.ADF',\n",
       " 'validmind.model_validation.statsmodels.DurbinWatsonTest',\n",
       " 'validmind.data_validation.MissingValuesRisk',\n",
       " 'validmind.data_validation.IQROutliersTable',\n",
       " 'validmind.data_validation.BivariateFeaturesBarPlots',\n",
       " 'validmind.data_validation.Skewness',\n",
       " 'validmind.data_validation.Duplicates',\n",
       " 'validmind.data_validation.MissingValuesBarPlot',\n",
       " 'validmind.data_validation.DatasetDescription',\n",
       " 'validmind.data_validation.ScatterPlot',\n",
       " 'validmind.data_validation.TimeSeriesOutliers',\n",
       " 'validmind.data_validation.TabularCategoricalBarPlots',\n",
       " 'validmind.data_validation.AutoStationarity',\n",
       " 'validmind.data_validation.DescriptiveStatistics',\n",
       " 'validmind.data_validation.ANOVAOneWayTable',\n",
       " 'validmind.data_validation.TargetRateBarPlots',\n",
       " 'validmind.data_validation.PearsonCorrelationMatrix',\n",
       " 'validmind.data_validation.FeatureTargetCorrelationPlot',\n",
       " 'validmind.data_validation.TabularNumericalHistograms',\n",
       " 'validmind.data_validation.IsolationForestOutliers',\n",
       " 'validmind.data_validation.ChiSquaredFeaturesTable',\n",
       " 'validmind.data_validation.HighCardinality',\n",
       " 'validmind.data_validation.MissingValues',\n",
       " 'validmind.data_validation.DefaultRatesbyRiskBandPlot',\n",
       " 'validmind.data_validation.RollingStatsPlot',\n",
       " 'validmind.data_validation.DatasetCorrelations',\n",
       " 'validmind.data_validation.TabularDescriptionTables',\n",
       " 'validmind.data_validation.AutoMA',\n",
       " 'validmind.data_validation.UniqueRows',\n",
       " 'validmind.data_validation.TooManyZeroValues',\n",
       " 'validmind.data_validation.HighPearsonCorrelation',\n",
       " 'validmind.data_validation.ACFandPACFPlot',\n",
       " 'validmind.data_validation.BivariateHistograms',\n",
       " 'validmind.data_validation.WOEBinTable',\n",
       " 'validmind.data_validation.HeatmapFeatureCorrelations',\n",
       " 'validmind.data_validation.TimeSeriesFrequency',\n",
       " 'validmind.data_validation.DatasetSplit',\n",
       " 'validmind.data_validation.SpreadPlot',\n",
       " 'validmind.data_validation.TimeSeriesLinePlot',\n",
       " 'validmind.data_validation.PiTCreditScoresHistogram',\n",
       " 'validmind.data_validation.AutoSeasonality',\n",
       " 'validmind.data_validation.BivariateScatterPlots',\n",
       " 'validmind.data_validation.EngleGrangerCoint',\n",
       " 'validmind.data_validation.TimeSeriesMissingValues',\n",
       " 'validmind.data_validation.DatasetMetadata',\n",
       " 'validmind.data_validation.TimeSeriesHistogram',\n",
       " 'validmind.data_validation.LaggedCorrelationHeatmap',\n",
       " 'validmind.data_validation.SeasonalDecompose',\n",
       " 'validmind.data_validation.WOEBinPlots',\n",
       " 'validmind.data_validation.ClassImbalance',\n",
       " 'validmind.data_validation.IQROutliersBarPlot',\n",
       " 'validmind.data_validation.PiTPDHistogram',\n",
       " 'validmind.data_validation.AutoAR',\n",
       " 'validmind.data_validation.TabularDateTimeHistograms',\n",
       " 'validmind.data_validation.nlp.Punctuations',\n",
       " 'validmind.data_validation.nlp.CommonWords',\n",
       " 'validmind.data_validation.nlp.Hashtags',\n",
       " 'validmind.data_validation.nlp.Mentions',\n",
       " 'validmind.data_validation.nlp.StopWords']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tests(pretty=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b3375 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b3375_row0_col0, #T_b3375_row0_col1, #T_b3375_row1_col0, #T_b3375_row1_col1, #T_b3375_row2_col0, #T_b3375_row2_col1, #T_b3375_row3_col0, #T_b3375_row3_col1, #T_b3375_row4_col0, #T_b3375_row4_col1, #T_b3375_row5_col0, #T_b3375_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b3375\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b3375_level0_col0\" class=\"col_heading level0 col0\" ></th>\n",
       "      <th id=\"T_b3375_level0_col1\" class=\"col_heading level0 col1\" > </th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b3375_row0_col0\" class=\"data row0 col0\" >ID:</td>\n",
       "      <td id=\"T_b3375_row0_col1\" class=\"data row0 col1\" >validmind.model_validation.ModelMetadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b3375_row1_col0\" class=\"data row1 col0\" >Name:</td>\n",
       "      <td id=\"T_b3375_row1_col1\" class=\"data row1 col1\" >Model Metadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b3375_row2_col0\" class=\"data row2 col0\" >Description:</td>\n",
       "      <td id=\"T_b3375_row2_col1\" class=\"data row2 col1\" >This section describes attributes of the selected model such as its modeling technique, training parameters, and task type. This helps understand the model's capabilities and limitations in the context of a modeling framework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b3375_row3_col0\" class=\"data row3 col0\" >Test Type:</td>\n",
       "      <td id=\"T_b3375_row3_col1\" class=\"data row3 col1\" >Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b3375_row4_col0\" class=\"data row4 col0\" >Required Inputs:</td>\n",
       "      <td id=\"T_b3375_row4_col1\" class=\"data row4 col1\" >['model']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b3375_row5_col0\" class=\"data row5 col0\" >Params:</td>\n",
       "      <td id=\"T_b3375_row5_col1\" class=\"data row5 col1\" >{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c5ca7b50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_test(\"validmind.model_validation.ModelMetadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e7cf6 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e7cf6_row0_col0, #T_e7cf6_row0_col1, #T_e7cf6_row1_col0, #T_e7cf6_row1_col1, #T_e7cf6_row2_col0, #T_e7cf6_row2_col1, #T_e7cf6_row3_col0, #T_e7cf6_row3_col1, #T_e7cf6_row4_col0, #T_e7cf6_row4_col1, #T_e7cf6_row5_col0, #T_e7cf6_row5_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e7cf6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_e7cf6_level0_col0\" class=\"col_heading level0 col0\" ></th>\n",
       "      <th id=\"T_e7cf6_level0_col1\" class=\"col_heading level0 col1\" > </th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_e7cf6_row0_col0\" class=\"data row0 col0\" >ID:</td>\n",
       "      <td id=\"T_e7cf6_row0_col1\" class=\"data row0 col1\" >validmind.model_validation.ModelMetadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e7cf6_row1_col0\" class=\"data row1 col0\" >Name:</td>\n",
       "      <td id=\"T_e7cf6_row1_col1\" class=\"data row1 col1\" >Model Metadata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e7cf6_row2_col0\" class=\"data row2 col0\" >Description:</td>\n",
       "      <td id=\"T_e7cf6_row2_col1\" class=\"data row2 col1\" >This section describes attributes of the selected model such as its modeling technique, training parameters, and task type. This helps understand the model's capabilities and limitations in the context of a modeling framework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e7cf6_row3_col0\" class=\"data row3 col0\" >Test Type:</td>\n",
       "      <td id=\"T_e7cf6_row3_col1\" class=\"data row3 col1\" >Metric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e7cf6_row4_col0\" class=\"data row4 col0\" >Required Inputs:</td>\n",
       "      <td id=\"T_e7cf6_row4_col1\" class=\"data row4 col1\" >['model']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e7cf6_row5_col0\" class=\"data row5 col0\" >Params:</td>\n",
       "      <td id=\"T_e7cf6_row5_col1\" class=\"data row5 col1\" >{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c5c94ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_test(\"ModelMetadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'validmind.tests.model_validation.ModelMetadata.ModelMetadata'>\n",
      "Test name is: model_metadata\n",
      "\n",
      "    Custom class to collect the following metadata for a model:\n",
      "    - Model architecture\n",
      "    \n",
      "['model']\n"
     ]
    }
   ],
   "source": [
    "test = load_test(\"validmind.model_validation.ModelMetadata\")\n",
    "print(test)\n",
    "print(f\"Test name is: {test.name}\")\n",
    "print(test.__doc__)\n",
    "print(test.required_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validmind.tests.model_validation.sklearn.ConfusionMatrix.ConfusionMatrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_test(\"validmind.model_validation.sklearn.ConfusionMatrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validmind.tests.data_validation.ClassImbalance.ClassImbalance"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_test(\"validmind.data_validation.ClassImbalance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'validmind.tests.model_validation.statsmodels.ZivotAndrewsArch.ZivotAndrewsArch'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RegressionModelForecastPlot.RegressionModelForecastPlot'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RegressionModelOutsampleComparison.RegressionModelOutsampleComparison'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.KolmogorovSmirnov.KolmogorovSmirnov'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.ScorecardProbabilitiesHistogram.ScorecardProbabilitiesHistogram'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RegressionModelsPerformance.RegressionModelsPerformance'>\n",
      "<class 'validmind.tests.model_validation.sklearn.SHAPGlobalImportance.SHAPGlobalImportance'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.ScorecardBucketHistogram.ScorecardBucketHistogram'>\n",
      "<class 'validmind.tests.model_validation.sklearn.ClassifierInSamplePerformance.ClassifierInSamplePerformance'>\n",
      "<class 'validmind.tests.model_validation.ModelMetadata.ModelMetadata'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RegressionModelForecastPlotLevels.RegressionModelForecastPlotLevels'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RegressionModelSummary.RegressionModelSummary'>\n",
      "<class 'validmind.tests.model_validation.sklearn.OverfitDiagnosis.OverfitDiagnosis'>\n",
      "<class 'validmind.tests.model_validation.sklearn.MinimumROCAUCScore.MinimumROCAUCScore'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.LogisticRegPredictionHistogram.LogisticRegPredictionHistogram'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.Lilliefors.Lilliefors'>\n",
      "<class 'validmind.tests.model_validation.sklearn.WeakspotsDiagnosis.WeakspotsDiagnosis'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RegressionFeatureSignificance.RegressionFeatureSignificance'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RunsTest.RunsTest'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.PhillipsPerronArch.PhillipsPerronArch'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RegressionModelInsampleComparison.RegressionModelInsampleComparison'>\n",
      "<class 'validmind.tests.model_validation.sklearn.ClassifierPerformance.ClassifierPerformance'>\n",
      "<class 'validmind.tests.model_validation.sklearn.PopulationStabilityIndex.PopulationStabilityIndex'>\n",
      "<class 'validmind.tests.model_validation.sklearn.ROCCurve.ROCCurve'>\n",
      "<class 'validmind.tests.model_validation.sklearn.ModelsPerformanceComparison.ModelsPerformanceComparison'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RegressionCoeffsPlot.RegressionCoeffsPlot'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.ADFTest.ADFTest'>\n",
      "<class 'validmind.tests.model_validation.sklearn.PrecisionRecallCurve.PrecisionRecallCurve'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.FeatureImportanceAndSignificance.FeatureImportanceAndSignificance'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RegressionModelsCoeffs.RegressionModelsCoeffs'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.RegressionModelSensitivityPlot.RegressionModelSensitivityPlot'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.LJungBox.LJungBox'>\n",
      "<class 'validmind.tests.model_validation.sklearn.MinimumF1Score.MinimumF1Score'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.KPSS.KPSS'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.LogRegressionConfusionMatrix.LogRegressionConfusionMatrix'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.BoxPierce.BoxPierce'>\n",
      "<class 'validmind.tests.model_validation.sklearn.MinimumAccuracy.MinimumAccuracy'>\n",
      "<class 'validmind.tests.model_validation.sklearn.TrainingTestDegradation.TrainingTestDegradation'>\n",
      "<class 'validmind.tests.model_validation.sklearn.PermutationFeatureImportance.PermutationFeatureImportance'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.JarqueBera.JarqueBera'>\n",
      "<class 'validmind.tests.model_validation.sklearn.RobustnessDiagnosis.RobustnessDiagnosis'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.GINITable.GINITable'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.ScorecardHistogram.ScorecardHistogram'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.LogisticRegCumulativeProb.LogisticRegCumulativeProb'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.DFGLSArch.DFGLSArch'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.PDRatingClassPlot.PDRatingClassPlot'>\n",
      "<class 'validmind.tests.model_validation.sklearn.ClassifierOutOfSamplePerformance.ClassifierOutOfSamplePerformance'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.ResidualsVisualInspection.ResidualsVisualInspection'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.ShapiroWilk.ShapiroWilk'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.DurbinWatsonTest.DurbinWatsonTest'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.ADF.ADF'>\n",
      "<class 'validmind.tests.model_validation.statsmodels.AutoARIMA.AutoARIMA'>\n",
      "<class 'validmind.tests.model_validation.sklearn.ConfusionMatrix.ConfusionMatrix'>\n"
     ]
    }
   ],
   "source": [
    "for test in list_tests(pretty=False, filter=\"validmind.model_validation\"):\n",
    "    print(load_test(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validmind.tests.data_validation.ClassImbalance.ClassImbalance"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from validmind.tests.data_validation.ClassImbalance import ClassImbalance\n",
    "ClassImbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validmind.tests.model_validation.sklearn.ConfusionMatrix.ConfusionMatrix"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from validmind.tests.model_validation.sklearn.ConfusionMatrix import ConfusionMatrix\n",
    "ConfusionMatrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Run Dataset Based Tests\n",
    "\n",
    "The ValidMind developer framework provides a `run_test` function that allows you to run built-in or custom tests that take any dataset or model as input. These tests generate outputs in the form of text, tables and images that get populated in model documentation.\n",
    "\n",
    "In this notebook, we will take you through the process of learning how to find tests, understand how to initialize a ValidMind dataset and pass it to the `run_test` function, for any test that takes a `dataset` input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Requisites\n",
    "\n",
    "We recommended that you have gone through the [explore_tests.ipynb](../explore_tests.ipynb) notebook to understand the basics of how to find and describe all the available tests in the developer framework.\n",
    "\n",
    "## High-Level Steps\n",
    "\n",
    "- Listing and filtering available tests\n",
    "- Building a sample dataset\n",
    "- Understanding how to initialize a VM dataset\n",
    "- Running a test with the sample dataset\n",
    "- Running a test that accepts parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "::: {.callout-tip}\n",
    "\n",
    "### New to ValidMind?\n",
    "\n",
    "For access to all features available in this notebook, create a free ValidMind account.\n",
    "\n",
    "Signing up is FREE — [**Sign up now**](https://app.prod.validmind.ai)\n",
    ":::\n",
    "\n",
    "If you encounter errors due to missing modules in your Python environment, install the modules with `pip install`, and then re-run the notebook. For more help, refer to [Installing Python Modules](https://docs.python.org/3/installing/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the client library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Users/andres/code/validmind-sdk/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the client library\n",
    "\n",
    "ValidMind generates a unique _code snippet_ for each registered model to connect with your developer environment. You initialize the client library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.\n",
    "\n",
    "Get your code snippet:\n",
    "\n",
    "1. In a browser, log into the [Platform UI](https://app.prod.validmind.ai).\n",
    "\n",
    "2. In the left sidebar, navigate to **Model Inventory** and click **+ Register new model**.\n",
    "\n",
    "3. Enter the model details, making sure to select **Binary classification** as the template and **Marketing/Sales - Attrition/Churn Management** as the use case, and click **Continue**. ([Need more help?](https://docs.validmind.ai/guide/register-models-in-model-inventory.html))\n",
    "\n",
    "4. Go to **Getting Started** and click **Copy snippet to clipboard**.\n",
    "\n",
    "Next, replace this placeholder with your own code snippet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 11:24:31,131 - INFO(validmind.api_client): Connected to ValidMind. Project: [Test] Customer Churn - Initial Validation (cltdu833a00058e8hwiums2mj)\n"
     ]
    }
   ],
   "source": [
    "# Replace with your code snippet\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "    api_host=\"https://api.prod.validmind.ai/api/v1/tracking\",\n",
    "    api_key=\"...\",\n",
    "    api_secret=\"...\",\n",
    "    project=\"...\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing and filtering available tests\n",
    "\n",
    "Before we run a test, let's find a suitable metric for this demonstration. Let's assume you want to generate the pearson correlation matrix for a dataset. In the [explore_tests.ipynb](../explore_tests.ipynb) notebook we saw how to pass a `filter` to the `list_tests` function. Let's do the same here to find the test ID for the pearson correlation matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0804a th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0804a_row0_col0, #T_0804a_row0_col1, #T_0804a_row0_col2, #T_0804a_row0_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0804a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_0804a_level0_col0\" class=\"col_heading level0 col0\" >Test Type</th>\n",
       "      <th id=\"T_0804a_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_0804a_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_0804a_level0_col3\" class=\"col_heading level0 col3\" >ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_0804a_row0_col0\" class=\"data row0 col0\" >Metric</td>\n",
       "      <td id=\"T_0804a_row0_col1\" class=\"data row0 col1\" >Pearson Correlation Matrix</td>\n",
       "      <td id=\"T_0804a_row0_col2\" class=\"data row0 col2\" >Evaluates linear dependency between numerical variables in a dataset via a Pearson Correlation coefficient heat map....</td>\n",
       "      <td id=\"T_0804a_row0_col3\" class=\"data row0 col3\" >validmind.data_validation.PearsonCorrelationMatrix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16f59ffd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.tests.list_tests(filter=\"PearsonCorrelationMatrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, you can see that the test ID for the pearson correlation matrix is `validmind.data_validation.PearsonCorrelationMatrix`. The `describe_test` function gives you more information about the test, including its **Required Inputs**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b828b4a1719b44a3a53dbf49514df171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<div>\\n  <h2>Pearson Correlation Matrix</h2>\\n  <p>Evaluates linear dependency between numerical…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_id = \"validmind.data_validation.PearsonCorrelationMatrix\"\n",
    "vm.tests.describe_test(test_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this test requires a dataset, it should throw an error if you were to run it without passing a `dataset` input:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TestInput' object has no attribute 'dataset'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vm.tests.run_test(test_id)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a sample dataset\n",
    "\n",
    "Now, let's build a sample dataset so you can generate its pearson correlation matrix. The sklearn `make_classification` function can generate a random dataset for testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633563</td>\n",
       "      <td>0.357385</td>\n",
       "      <td>-0.503931</td>\n",
       "      <td>0.935066</td>\n",
       "      <td>0.647981</td>\n",
       "      <td>-0.050796</td>\n",
       "      <td>-1.933989</td>\n",
       "      <td>2.081684</td>\n",
       "      <td>0.041266</td>\n",
       "      <td>-0.258298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.283905</td>\n",
       "      <td>1.109459</td>\n",
       "      <td>-0.908953</td>\n",
       "      <td>1.006586</td>\n",
       "      <td>0.492219</td>\n",
       "      <td>1.107295</td>\n",
       "      <td>1.243526</td>\n",
       "      <td>-0.172200</td>\n",
       "      <td>1.150359</td>\n",
       "      <td>0.147744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.966476</td>\n",
       "      <td>-0.593314</td>\n",
       "      <td>0.458020</td>\n",
       "      <td>1.032323</td>\n",
       "      <td>1.283685</td>\n",
       "      <td>-0.317640</td>\n",
       "      <td>1.499045</td>\n",
       "      <td>0.434477</td>\n",
       "      <td>0.423678</td>\n",
       "      <td>1.251380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.429309</td>\n",
       "      <td>-1.306530</td>\n",
       "      <td>-1.869925</td>\n",
       "      <td>3.092164</td>\n",
       "      <td>2.028800</td>\n",
       "      <td>-0.879635</td>\n",
       "      <td>-0.393494</td>\n",
       "      <td>-0.101213</td>\n",
       "      <td>-1.624066</td>\n",
       "      <td>0.443553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.395628</td>\n",
       "      <td>0.078464</td>\n",
       "      <td>0.713983</td>\n",
       "      <td>1.074594</td>\n",
       "      <td>1.469148</td>\n",
       "      <td>1.534946</td>\n",
       "      <td>-0.302288</td>\n",
       "      <td>2.325055</td>\n",
       "      <td>0.495505</td>\n",
       "      <td>0.538133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.633563   0.357385  -0.503931   0.935066   0.647981  -0.050796   \n",
       "1   1.283905   1.109459  -0.908953   1.006586   0.492219   1.107295   \n",
       "2  -0.966476  -0.593314   0.458020   1.032323   1.283685  -0.317640   \n",
       "3   2.429309  -1.306530  -1.869925   3.092164   2.028800  -0.879635   \n",
       "4  -1.395628   0.078464   0.713983   1.074594   1.469148   1.534946   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  target  \n",
       "0  -1.933989   2.081684   0.041266  -0.258298       1  \n",
       "1   1.243526  -0.172200   1.150359   0.147744       1  \n",
       "2   1.499045   0.434477   0.423678   1.251380       1  \n",
       "3  -0.393494  -0.101213  -1.624066   0.443553       1  \n",
       "4  -0.302288   2.325055   0.495505   0.538133       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=10000,\n",
    "    n_features=10,\n",
    "    weights=[0.1],\n",
    "    random_state=42,\n",
    ")\n",
    "X.shape\n",
    "y.shape\n",
    "\n",
    "df = pd.DataFrame(X, columns=[f\"feature_{i}\" for i in range(X.shape[1])])\n",
    "df[\"target\"] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to initialize a ValidMind dataset\n",
    "\n",
    "ValidMind dataset objects provide a wrapper to any type of dataset (NumPy, Pandas, Polars, etc.) so that tests can run transparently regardles of the underlying library. A VM dataset object can be created using the [`init_dataset`](https://docs.validmind.ai/validmind/validmind.html#init_dataset) function from the ValidMind (`vm`) module.\n",
    "\n",
    "This function takes a number of arguments:\n",
    "\n",
    "- `dataset` — the raw dataset that you want to provide as input to tests\n",
    "- `input_id` - a unique identifier that allows tracking what inputs are used when running each individual test\n",
    "- `target_column` — a required argument if tests require access to true values. This is the name of the target column in the dataset\n",
    "\n",
    "Below you can see how to initialize a VM dataset for the sample `df` you created previously:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 11:24:33,415 - INFO(validmind.client): Pandas dataset detected. Initializing VM Dataset instance...\n"
     ]
    }
   ],
   "source": [
    "vm_dataset = vm.init_dataset(\n",
    "    df,\n",
    "    input_id=\"my_demo_dataset\",\n",
    "    target_column=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now call `run_test` with the new `vm_dataset` object as input:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12c9453b09a4cc79a6e255c71127208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h1>Pearson Correlation Matrix</h1>'), HTML(value=\"<p>Evaluates linear dependency b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = vm.tests.run_test(\n",
    "    test_id,\n",
    "    inputs={\"dataset\": vm_dataset},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset can also be used for any other test that requires a dataset input. Let's try to find a \"class imbalance\" to understand the distribution of the target column in the dataset.\n",
    "\n",
    "We'll use `list_tests` again to showcase how to filter tests for tabular data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anomaly_detection',\n",
       " 'binary_classification',\n",
       " 'categorical_data',\n",
       " 'correlation',\n",
       " 'credit_risk',\n",
       " 'data_distribution',\n",
       " 'data_quality',\n",
       " 'feature_importance',\n",
       " 'few_shot',\n",
       " 'forecasting',\n",
       " 'frequency_analysis',\n",
       " 'kmeans',\n",
       " 'llm',\n",
       " 'logistic_regression',\n",
       " 'model_comparison',\n",
       " 'model_diagnosis',\n",
       " 'model_interpretation',\n",
       " 'model_metadata',\n",
       " 'model_performance',\n",
       " 'model_selection',\n",
       " 'multiclass_classification',\n",
       " 'nlp',\n",
       " 'numerical_data',\n",
       " 'regard_histogram',\n",
       " 'regard_score',\n",
       " 'risk_analysis',\n",
       " 'seasonality',\n",
       " 'senstivity_analysis',\n",
       " 'sklearn',\n",
       " 'stationarity',\n",
       " 'statistical_test',\n",
       " 'statsmodels',\n",
       " 'tabular_data',\n",
       " 'text_data',\n",
       " 'text_embeddings',\n",
       " 'time_series_data',\n",
       " 'toxicity_histogram',\n",
       " 'toxicity_line_plot',\n",
       " 'unit_root_test',\n",
       " 'visualization',\n",
       " 'zero_shot']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vm.tests.list_tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_efc2d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_efc2d_row0_col0, #T_efc2d_row0_col1, #T_efc2d_row0_col2, #T_efc2d_row0_col3, #T_efc2d_row1_col0, #T_efc2d_row1_col1, #T_efc2d_row1_col2, #T_efc2d_row1_col3, #T_efc2d_row2_col0, #T_efc2d_row2_col1, #T_efc2d_row2_col2, #T_efc2d_row2_col3, #T_efc2d_row3_col0, #T_efc2d_row3_col1, #T_efc2d_row3_col2, #T_efc2d_row3_col3, #T_efc2d_row4_col0, #T_efc2d_row4_col1, #T_efc2d_row4_col2, #T_efc2d_row4_col3, #T_efc2d_row5_col0, #T_efc2d_row5_col1, #T_efc2d_row5_col2, #T_efc2d_row5_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_efc2d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_efc2d_level0_col0\" class=\"col_heading level0 col0\" >Test Type</th>\n",
       "      <th id=\"T_efc2d_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_efc2d_level0_col2\" class=\"col_heading level0 col2\" >Description</th>\n",
       "      <th id=\"T_efc2d_level0_col3\" class=\"col_heading level0 col3\" >ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_efc2d_row0_col0\" class=\"data row0 col0\" >Metric</td>\n",
       "      <td id=\"T_efc2d_row0_col1\" class=\"data row0 col1\" >Bivariate Features Bar Plots</td>\n",
       "      <td id=\"T_efc2d_row0_col2\" class=\"data row0 col2\" >Generates visual bar plots to analyze the relationship between paired features within categorical data in the model....</td>\n",
       "      <td id=\"T_efc2d_row0_col3\" class=\"data row0 col3\" >validmind.data_validation.BivariateFeaturesBarPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_efc2d_row1_col0\" class=\"data row1 col0\" >Metric</td>\n",
       "      <td id=\"T_efc2d_row1_col1\" class=\"data row1 col1\" >ANOVA One Way Table</td>\n",
       "      <td id=\"T_efc2d_row1_col2\" class=\"data row1 col2\" >Applies one-way ANOVA (Analysis of Variance) to identify statistically significant numerical features in the...</td>\n",
       "      <td id=\"T_efc2d_row1_col3\" class=\"data row1 col3\" >validmind.data_validation.ANOVAOneWayTable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_efc2d_row2_col0\" class=\"data row2 col0\" >Metric</td>\n",
       "      <td id=\"T_efc2d_row2_col1\" class=\"data row2 col1\" >Chi Squared Features Table</td>\n",
       "      <td id=\"T_efc2d_row2_col2\" class=\"data row2 col2\" >Executes Chi-Squared test for each categorical feature against a target column to assess significant association....</td>\n",
       "      <td id=\"T_efc2d_row2_col3\" class=\"data row2 col3\" >validmind.data_validation.ChiSquaredFeaturesTable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_efc2d_row3_col0\" class=\"data row3 col0\" >Metric</td>\n",
       "      <td id=\"T_efc2d_row3_col1\" class=\"data row3 col1\" >Bivariate Histograms</td>\n",
       "      <td id=\"T_efc2d_row3_col2\" class=\"data row3 col2\" >Generates bivariate histograms for paired features, aiding in visual inspection of categorical variables'...</td>\n",
       "      <td id=\"T_efc2d_row3_col3\" class=\"data row3 col3\" >validmind.data_validation.BivariateHistograms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_efc2d_row4_col0\" class=\"data row4 col0\" >Metric</td>\n",
       "      <td id=\"T_efc2d_row4_col1\" class=\"data row4 col1\" >Bivariate Scatter Plots</td>\n",
       "      <td id=\"T_efc2d_row4_col2\" class=\"data row4 col2\" >Generates bivariate scatterplots to visually inspect relationships between pairs of predictor variables in machine...</td>\n",
       "      <td id=\"T_efc2d_row4_col3\" class=\"data row4 col3\" >validmind.data_validation.BivariateScatterPlots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_efc2d_row5_col0\" class=\"data row5 col0\" >ThresholdTest</td>\n",
       "      <td id=\"T_efc2d_row5_col1\" class=\"data row5 col1\" >Class Imbalance</td>\n",
       "      <td id=\"T_efc2d_row5_col2\" class=\"data row5 col2\" >Evaluates and quantifies class distribution imbalance in a dataset used by a machine learning model....</td>\n",
       "      <td id=\"T_efc2d_row5_col3\" class=\"data row5 col3\" >validmind.data_validation.ClassImbalance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x38032ceb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.tests.list_tests(tags=[\"binary_classification\", \"tabular_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test ID for the class imbalance test is `validmind.data_validation.ClassImbalance`. If you describe this test you will find that it also accepts some parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6484f306aa544cf2bb375cd819a3d97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<div>\\n  <h2>Class Imbalance</h2>\\n  <p>Evaluates and quantifies class distribution imbalance in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vm.tests.describe_test(\"validmind.data_validation.ClassImbalance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `min_percent_threshold` will allow you configure the threshold for an acceptable class imbalance. Let's run the test without any parameters to see its output using a default value for the threshold. We also call the `log` method on the result to send the results of the tests to the ValidMind platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418b99f0b3ec4d9daeb1e9c20a6a2d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h1>Class Imbalance ✅</h1>\\n            <p>Evaluates and quantifies c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.ClassImbalance\",\n",
    "    inputs={\"dataset\": vm_dataset},\n",
    ")\n",
    "\n",
    "result.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test passes the pass-fail criteria with the default threshold of 10%. Let's try to run the test with a threshold of 20% to see if it fails. Notice the use of the \"custom_threshold\" `result_id` in the test ID. This allows you to submit individual results for the same test to the platform, as we'll see in the next section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8c9359e4ce47d99266dbf84ed1d028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <h1>Class Imbalance Custom Threshold ❌</h1>\\n            <p>Evaluates…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.ClassImbalance:custom_threshold\",\n",
    "    inputs={\"dataset\": vm_dataset},\n",
    "    params={\"min_percent_threshold\": 20},\n",
    ")\n",
    "\n",
    "result.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding test results to documentation\n",
    "\n",
    "The previous result shows that the test doesn't pass the threshold of 20% for class imbalance. With these results logged, you can now add them to your model documentation. To do this, go to the documentation page of the model you connected to above and navigate to Data Preparation -> Data Description section. Then hover between any existing content block to reveal the + button as shown in the screenshot below.\n",
    "\n",
    "![screenshot showing insert button for test-driven blocks](../../images/insert-test-driven-block.png)\n",
    "\n",
    "Now click on the + button and select the Test-Driven Block option. This will open a dialog where you can select `Threshold Test` as the type of test and the `Class Imbalance Custom Threshold Test` from the list of available metrics. You can preview the result and then click Insert Block to add it to the documentation.\n",
    "\n",
    "![screenshot showing custom class imbalance result](../../images/insert-test-driven-block-custom-class-imbalance.jpg)\n",
    "\n",
    "The test should match the result you see above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "In the next notebook, you will learn how to run tests that require a dataset and model as inputs. This will allow you to generate documentation for model evaluation metrics such as ROC-AUC, F1 score, etc. for your model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
